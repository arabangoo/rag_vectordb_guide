# Amazon OpenSearchë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ

> í•œêµ­ì–´ ê°œë°œìë¥¼ ìœ„í•œ Amazon OpenSearch ê¸°ë°˜ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œ ì™„ë²½ êµ¬ì¶• ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ì†Œê°œ](#-í”„ë¡œì íŠ¸-ì†Œê°œ)
- [ì™œ Amazon OpenSearchì¸ê°€?](#-ì™œ-amazon-opensearchì¸ê°€)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [í™˜ê²½ êµ¬ì¶•](#-í™˜ê²½-êµ¬ì¶•)
- [OpenSearch ì¸ë±ìŠ¤ ìƒì„±](#-opensearch-ì¸ë±ìŠ¤-ìƒì„±)
- [Lambda ê¸°ë°˜ RAG êµ¬í˜„](#-lambda-ê¸°ë°˜-rag-êµ¬í˜„)
- [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
- [ìƒì„¸ ê°€ì´ë“œ](#-ìƒì„¸-ê°€ì´ë“œ)
- [ì„±ëŠ¥ ìµœì í™”](#-ì„±ëŠ¥-ìµœì í™”)
- [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
- [ì°¸ê³  ìë£Œ](#-ì°¸ê³ -ìë£Œ)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì†Œê°œ

ì´ í”„ë¡œì íŠ¸ëŠ” **Amazon OpenSearch Service**ì™€ **Amazon Bedrock**ì„ í™œìš©í•˜ì—¬ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- âœ… **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ í™•ì¥ì„±**: ìµœëŒ€ 1000ê°œ ë…¸ë“œ, 25PBê¹Œì§€ ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥
- âœ… **ì™„ì „ ê´€ë¦¬í˜•**: AWSì˜ ì™„ì „ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ë¡œ ìš´ì˜ ë¶€ë‹´ ìµœì†Œí™”
- âœ… **ê³ ì„±ëŠ¥ ë²¡í„° ê²€ìƒ‰**: HNSW ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ë¹ ë¥´ê³  ì •í™•í•œ ê²€ìƒ‰
- âœ… **í•œêµ­ì–´ ìµœì í™”**: Nori ë¶„ì„ê¸° ê¸°ë°˜ í•œê¸€ í˜•íƒœì†Œ ë¶„ì„
- âœ… **ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ì‹**: Semantic Search, Lexical Search, Hybrid Search ì§€ì›
- âœ… **ë©€í‹°ëª¨ë‹¬ ì§€ì›**: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ í†µí•© ê²€ìƒ‰ ê°€ëŠ¥
- âœ… **ë¹„ìš© ìµœì í™”**: Serverless, OR1 ì¸ìŠ¤í„´ìŠ¤, Disk-based vector search ì˜µì…˜

### í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. Amazon OpenSearch Service í™˜ê²½ êµ¬ì¶• ë° ì¸ë±ìŠ¤ ì„¤ì •
2. í•œêµ­ì–´ Nori ë¶„ì„ê¸° ì„¤ì • ë° ìµœì í™”
3. Amazon Bedrockì„ í™œìš©í•œ ì„ë² ë”© ë° LLM ì—°ë™
4. Lambda ê¸°ë°˜ ì„œë²„ë¦¬ìŠ¤ RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
5. ë²¡í„° ê²€ìƒ‰ ì—”ì§„ êµ¬í˜„ (k-NN, HNSW ì•Œê³ ë¦¬ì¦˜)
6. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### ì‹¤ì œ í™œìš© ì‚¬ë¡€

OpenSearch ê¸°ë°˜ RAGëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ê³¼ì ì…ë‹ˆë‹¤:

- **ğŸ“š ê¸°ì—… ì§€ì‹ ê²€ìƒ‰ ì‹œìŠ¤í…œ**: ë¬¸ì„œ ì§ˆì˜ ì±—ë´‡ ì‚¬ë¡€ 
- **ğŸ­ ì œì¡°ì—… ë°ì´í„° ë¶„ì„**: ëŒ€ê·œëª¨ ê¸°ìˆ  ë¬¸ì„œ ê²€ìƒ‰ ë° ë¶„ì„
- **ğŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í†µí•© ê²€ìƒ‰ ì‹œìŠ¤í…œ (ì´ë¯¸ì§€ ê²€ìƒ‰ ì‚¬ë¡€)
- **ğŸ” ìƒí’ˆ ê²€ìƒ‰ ì±—ë´‡**: ëŒ€í™”í˜• ìƒí’ˆ ì¶”ì²œ ë° ê²€ìƒ‰ ì‹œìŠ¤í…œ
- **ğŸ“Š ë¡œê·¸ ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë¡œê·¸ ë¶„ì„ ë° ì´ìƒ íƒì§€

---

## ğŸ“‹ ì£¼ìš” ì‚¬ì–‘ (Specs)

### Amazon OpenSearch Service 2024 ì£¼ìš” ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¤ëª… | ë¹„ê³  |
|------|------|------|
| **JWT ì¸ì¦/ì¸ê°€** | JSON Web Token ê¸°ë°˜ ì¸ì¦ | API ë³´ì•ˆ ê°•í™” |
| **Zero-ETL í†µí•©** | DynamoDB, DocumentDB, Security Lake ì§ì ‘ ì—°ë™ | ETL íŒŒì´í”„ë¼ì¸ ë¶ˆí•„ìš” |
| **ë””ìŠ¤í¬ ìµœì í™” ë²¡í„° ì—”ì§„** | Binary quantization (32ë°° ì••ì¶•) | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëŒ€í­ ê°ì†Œ |
| **OR1 ì¸ìŠ¤í„´ìŠ¤** | ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ 30% í–¥ìƒ | S3 ê¸°ë°˜ 99.999999999% ë‚´êµ¬ì„± |
| **Coordinator Node** | ì „ìš© ì¡°ì • ë…¸ë“œ | í´ëŸ¬ìŠ¤í„° íš¨ìœ¨ì„± ê°œì„  |
| **ìµœëŒ€ 1000ê°œ ë…¸ë“œ** | ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° 25PBê¹Œì§€ í™•ì¥ | ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ í™•ì¥ì„± |
| **Custom Plugin** | ì‚¬ìš©ì ì •ì˜ í”ŒëŸ¬ê·¸ì¸ ì§€ì› | ê¸°ëŠ¥ í™•ì¥ ê°€ëŠ¥ |
| **Serverless ê°œì„ ** | 0.5 OCU (50% ë¹„ìš© ì ˆê°), Binary Vector, FP16 ì••ì¶• | ìµœëŒ€ 30TB í™•ì¥ |

### ì§€ì›í•˜ëŠ” Amazon Bedrock ëª¨ë¸

| ëª¨ë¸ëª… | íŠ¹ì§• | ê¶Œì¥ ì‚¬ìš©ì²˜ |
|--------|------|------------|
| **Claude 3.5 Sonnet** | ìµœê³  ì„±ëŠ¥, ê¸´ ì»¨í…ìŠ¤íŠ¸(200K) | ë³µì¡í•œ ë¬¸ì„œ ë¶„ì„, ì „ë¬¸ê°€ ìˆ˜ì¤€ ë‹µë³€ |
| **Claude 3 Haiku** | ë¹ ë¥¸ ì†ë„, ì €ë ´í•œ ë¹„ìš© | ì‹¤ì‹œê°„ ì±—ë´‡, ëŒ€ëŸ‰ ì²˜ë¦¬ |
| **Titan Embeddings G1** | í…ìŠ¤íŠ¸ ì„ë² ë”© (1024 ì°¨ì›) | í•œêµ­ì–´ í¬í•¨ ë‹¤êµ­ì–´ ì§€ì› |
| **Titan Multimodal Embeddings** | í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì„ë² ë”© (1024 ì°¨ì›) | ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ |
| **Llama 3.1** | ì˜¤í”ˆì†ŒìŠ¤, ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥ | ìì²´ í˜¸ìŠ¤íŒ…, ë¹„ìš© ìµœì í™” |

### ë²¡í„° ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ

| ì•Œê³ ë¦¬ì¦˜ | Response Time | Accuracy/Recall | ë¹„ìš© | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|---------|---------------|-----------------|------|--------------|
| **Exact kNN** | 100-300ms | 1.00 (100%) | $$$ | ìµœëŒ€ |
| **HNSW (Memory-optimized)** | 5-20ms | > 0.95 (95%+) | $$ | ì¤‘ê°„ |
| **Disk-optimized** | < 50-100ms | > 0.95 (95%+) | $ | 32ë°° ì ˆê° |

### ê²€ìƒ‰ ë°©ì‹ ë¹„êµ

| ê²€ìƒ‰ ë°©ì‹ | ì„¤ëª… | ì•Œê³ ë¦¬ì¦˜ | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|----------|------|----------|--------------|
| **Semantic Search** | ë²¡í„° ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ | k-NN, HNSW | ìì—°ì–´ ì§ˆë¬¸, ì˜ë„ íŒŒì•… |
| **Lexical Search** | í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ | BM25 | ì •í™•í•œ ìš©ì–´ ê²€ìƒ‰ |
| **Hybrid Search** | Semantic + Lexical ê²°í•© | k-NN + BM25 | ìµœê³ ì˜ ê²€ìƒ‰ ì •í™•ë„ |
| **Multi-Modal Search** | í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í†µí•© | Multimodal Embeddings | ì œí’ˆ ê²€ìƒ‰, ì´ë¯¸ì§€ ìœ ì‚¬ë„ |

### ì˜ˆìƒ ë¹„ìš© (2024ë…„ 12ì›” ê¸°ì¤€)

#### ì†Œê·œëª¨ í”„ë¡œì íŠ¸ (ê°œë°œ/í…ŒìŠ¤íŠ¸)
```
âœ… OpenSearch Serverless
- ë¹„ìš©: OCU ê¸°ë°˜ (0.5 OCU ~ ì‹œì‘)
- ì˜ˆìƒ: $50-100/ì›”
- ìš©ë„: ì†Œê·œëª¨ ë¬¸ì„œ (<10GB), ë‚®ì€ ì¿¼ë¦¬ëŸ‰

âœ… Amazon Bedrock
- Titan Embeddings: $0.0001/1000 í† í°
- Claude 3 Haiku: $0.25/1M ì…ë ¥ í† í°, $1.25/1M ì¶œë ¥ í† í°
- ì˜ˆìƒ (ì›” 1000 ì¿¼ë¦¬): $10-20/ì›”

ğŸ“Š ì´ ì˜ˆìƒ ë¹„ìš©: $60-120/ì›”
```

#### ì¤‘ê·œëª¨ í”„ë¡œì íŠ¸ (í”„ë¡œë•ì…˜)
```
âœ… OpenSearch (m6g.large.search 2ëŒ€)
- ì¸ìŠ¤í„´ìŠ¤: $0.114/ì‹œê°„ Ã— 2 = $0.228/ì‹œê°„
- ìŠ¤í† ë¦¬ì§€ (100GB): $0.135/GB = $13.5/ì›”
- ì›” ë¹„ìš©: ~$165 (ì¸ìŠ¤í„´ìŠ¤) + $14 (ìŠ¤í† ë¦¬ì§€) = $179/ì›”

âœ… Amazon Bedrock
- ì›” 10,000 ì¿¼ë¦¬ ì˜ˆìƒ
- Embeddings + LLM: ~$100/ì›”

ğŸ“Š ì´ ì˜ˆìƒ ë¹„ìš©: $279/ì›”
```

#### ëŒ€ê·œëª¨ ì—”í„°í”„ë¼ì´ì¦ˆ 
```
âœ… OpenSearch (r6g.xlarge.search 3 AZ Ã— 3ëŒ€)
- ì¸ìŠ¤í„´ìŠ¤: $0.312/ì‹œê°„ Ã— 3 = $0.936/ì‹œê°„
- ì›” ë¹„ìš©: ~$679/ì›”
- ìŠ¤í† ë¦¬ì§€ (1TB): $135/ì›”

âœ… Amazon Bedrock
- ì›” 100,000+ ì¿¼ë¦¬
- ë©€í‹° ë¦¬ì „ (us-east-1 + us-west-2)
- Provisioned Throughput ê³ ë ¤
- ì˜ˆìƒ: $1,000-2,000/ì›”

âœ… Lambda + S3 + CloudWatch: ~$50/ì›”

ğŸ“Š ì´ ì˜ˆìƒ ë¹„ìš©: $1,864-2,864/ì›”
```

**ë¹„ìš© ìµœì í™” íŒ:**
- **Disk-based Vector Search**: ë©”ëª¨ë¦¬ ë¹„ìš© 32ë°° ì ˆê°
- **OR1 ì¸ìŠ¤í„´ìŠ¤**: ê¸°ì¡´ ëŒ€ë¹„ 30% ê°€ê²© ì ˆê°
- **Serverless**: ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ìë™ ìŠ¤ì¼€ì¼ (ê°œë°œ í™˜ê²½ ì¶”ì²œ)
- **Reserved Instances**: 1ë…„ ì•½ì • ì‹œ ìµœëŒ€ 40% í• ì¸
- **Claude Haiku**: Sonnet ëŒ€ë¹„ 80% ë¹„ìš© ì ˆê°

---

## ğŸ¤” ì™œ Amazon OpenSearchì¸ê°€?

### ê¸°ì¡´ RAG ì†”ë£¨ì…˜ vs Amazon OpenSearch

| ê¸°ëŠ¥ | ì˜¤í”ˆì†ŒìŠ¤ (Self-managed) | Amazon OpenSearch |
|------|------------------------|-------------------|
| **ì¸í”„ë¼ ê´€ë¦¬** | ì§ì ‘ ì„¤ì¹˜, ìš´ì˜, íŒ¨ì¹˜ | **ì™„ì „ ê´€ë¦¬í˜•** |
| **í™•ì¥ì„±** | ìˆ˜ë™ ìŠ¤ì¼€ì¼ë§ | **ìë™ ìŠ¤ì¼€ì¼ë§ (ìµœëŒ€ 1000ë…¸ë“œ, 25PB)** |
| **ê°€ìš©ì„±** | ì§ì ‘ êµ¬ì„± í•„ìš” | **Multi-AZ ìë™ ë³µì œ, 99.99% SLA** |
| **ë³´ì•ˆ** | ì§ì ‘ ì„¤ì • | **VPC, IAM, ì•”í˜¸í™” ê¸°ë³¸ ì œê³µ** |
| **ë°±ì—…** | ì§ì ‘ ê´€ë¦¬ | **ìë™ ìŠ¤ëƒ…ìƒ·** |
| **ëª¨ë‹ˆí„°ë§** | ë³„ë„ ë„êµ¬ í•„ìš” | **CloudWatch í†µí•©** |
| **ë¹„ìš©** | ì¸í”„ë¼ + ìš´ì˜ ì¸ë ¥ | **ì‚¬ìš©ëŸ‰ ê¸°ë°˜** |
| **í•œêµ­ì–´ ì§€ì›** | ì§ì ‘ ì„¤ì • | **Nori ë¶„ì„ê¸° ë‚´ì¥** |

### RAGì— ìµœì ì¸ ì´ìœ 

1. **ê²€ì¦ëœ ì„±ëŠ¥**: ëŒ€ê¸°ì—…ì—ì„œ í”„ë¡œë•ì…˜ ì‚¬ìš© ì¤‘
2. **ë¹ ë¥¸ ê²€ìƒ‰ ì†ë„**: HNSW ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ 5-20ms ì‘ë‹µ
3. **í•œêµ­ì–´ ìµœì í™”**: Nori í˜•íƒœì†Œ ë¶„ì„ê¸° ë‚´ì¥
4. **ë‹¤ì–‘í•œ ê²€ìƒ‰ ì˜µì…˜**: Semantic, Lexical, Hybrid, Multi-modal
5. **AWS ìƒíƒœê³„ í†µí•©**: Bedrock, Lambda, SageMaker ì™„ë²½ ì—°ë™
6. **ì œë¡œ ETL**: DynamoDB, DocumentDB ì§ì ‘ ì—°ê²°
7. **ë¹„ìš© ìµœì í™”**: Disk-based vector searchë¡œ ë©”ëª¨ë¦¬ ë¹„ìš© 32ë°° ì ˆê°

---

## ğŸ— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### RAG ì›Œí¬í”Œë¡œìš°

```mermaid
graph TD
    User[ì‚¬ìš©ì ì§ˆë¬¸] --> Lambda[AWS Lambda]
    Lambda -->|1. ì§ˆë¬¸ ì„ë² ë”©| Bedrock_Embed[Amazon Bedrock<br/>Embedding Model]
    Bedrock_Embed -->|2. ë²¡í„° ìƒì„±| Lambda
    Lambda -->|3. ë²¡í„° ê²€ìƒ‰| OpenSearch[Amazon OpenSearch<br/>Vector DB]
    OpenSearch -->|4. ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜| Lambda
    Lambda -->|5. í”„ë¡¬í”„íŠ¸ êµ¬ì„±| Bedrock_LLM[Amazon Bedrock<br/>LLM Claude]
    Bedrock_LLM -->|6. ìµœì¢… ë‹µë³€| Lambda
    Lambda --> User
    
    S3[Amazon S3<br/>ì›ë³¸ ë¬¸ì„œ] -->|ë¬¸ì„œ ì—…ë¡œë“œ<br/>S3 Event| Lambda_Indexing[Lambda<br/>ì¸ë±ì‹± í•¨ìˆ˜]
    Lambda_Indexing -->|ì „ì²˜ë¦¬<br/>ì²­í¬ ë¶„í• | Bedrock_Embed
    Bedrock_Embed -->|ë²¡í„° ì €ì¥| OpenSearch
```

### Lambda ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰ ì•„í‚¤í…ì²˜ (ì‹¤ì „ ì‚¬ë¡€)

```mermaid
graph TD
    Client[Client Application<br/>Streamlit/Web Frontend]

    Client -->|ì´ë¯¸ì§€ ì—…ë¡œë“œ| S3[Amazon S3 Bucket<br/>ì´ë¯¸ì§€ ì €ì¥]
    Client -->|ê²€ìƒ‰ ìš”ì²­| Lambda2[Lambda í•¨ìˆ˜ 2<br/>QueryAndSearch]

    S3 -->|S3 Event Trigger| Lambda1[Lambda í•¨ìˆ˜ 1<br/>EmbeddingAndSave]
    Lambda2 -.->|ì°¸ì¡°| Lambda1

    Lambda1 -->|Bedrock í˜¸ì¶œ| Bedrock1[Amazon Bedrock<br/>Titan Multimodal Embeddings]
    Lambda2 -->|Bedrock í˜¸ì¶œ| Bedrock2[Amazon Bedrock<br/>Titan Multimodal Embeddings]

    Bedrock1 -->|ë²¡í„° ì €ì¥| OpenSearch[Amazon OpenSearch Serverless<br/>Vector Database<br/>FAISS, 1024ì°¨ì›, Euclidean]
    Bedrock2 -->|ë²¡í„° ê²€ìƒ‰| OpenSearch

    OpenSearch -->|ê²€ìƒ‰ ê²°ê³¼| Lambda2
    Lambda2 -->|ê²°ê³¼ ë°˜í™˜| Client
```

**ì›Œí¬í”Œë¡œìš° ì„¤ëª…:**

ğŸŸ© **Lambda í•¨ìˆ˜ 1: EmbeddingImageAndSaveToOpensearch**
1. S3ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ Lambda ìë™ íŠ¸ë¦¬ê±°
2. ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜
3. Bedrock Titan Multimodalë¡œ ì„ë² ë”© (1024ì°¨ì› ë²¡í„°)
4. OpenSearchì— ë²¡í„° + ë©”íƒ€ë°ì´í„° ì €ì¥

ğŸŸ¦ **Lambda í•¨ìˆ˜ 2: EmbeddingQueryAndQueryToOpensearch**
1. ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰ ìš”ì²­
2. ì¿¼ë¦¬ë¥¼ Bedrockìœ¼ë¡œ ì„ë² ë”©
3. OpenSearchì—ì„œ k-NN ìœ ì‚¬ë„ ê²€ìƒ‰
4. ìƒìœ„ Nê°œ ê²°ê³¼ ë°˜í™˜

### ì•„í‚¤í…ì²˜ ìƒì„¸ 

```mermaid
graph TB
    subgraph Seoul["Seoul Region (ap-northeast-2)"]
        Client[Client Application]
        API[API Server<br/>3-Tier]
        S3_Seoul[Amazon S3<br/>Document Store]
        SageMaker[SageMaker Studio<br/>Preprocessing]
        OpenSearch[Amazon OpenSearch<br/>Vector Database<br/>Nori Analyzer, HNSW Index]

        Client <-->|ìš”ì²­/ì‘ë‹µ| API
        API --> S3_Seoul
        S3_Seoul --> SageMaker
        SageMaker --> OpenSearch
    end

    subgraph Virginia["N.Virginia Region (us-east-1)"]
        Bedrock_VA[Amazon Bedrock<br/>Claude 3.5 Sonnet<br/>Titan Embeddings<br/>VPC Endpoint]
    end

    subgraph Oregon["Oregon (us-west-2)"]
        Bedrock_OR[Amazon Bedrock<br/>Claude 3 Haiku<br/>Failover<br/>VPC Endpoint]
    end

    OpenSearch -->|VPC Peering| Bedrock_VA
    OpenSearch -.->|Failover| Bedrock_OR
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

#### 1. ë°ì´í„° ì „ì²˜ë¦¬
- **PDF/HWP íŒŒì‹±**: PyPDF, PyMuPDF, HWP ë¼ì´ë¸ŒëŸ¬ë¦¬
- **OCR ì²˜ë¦¬**: Upstage Document OCR ë˜ëŠ” Claude Vision
- **ì²­í‚¹ ì „ëµ**: ì˜ë¯¸ ë‹¨ìœ„ ë¶„í•  (1000-1500 í† í°)
- **ë©”íƒ€ë°ì´í„° ì¶”ì¶œ**: ë¬¸ì„œ ì œëª©, í˜ì´ì§€, ì¹´í…Œê³ ë¦¬ ë“±

#### 2. ì„ë² ë”©
- **ëª¨ë¸**: Titan Embeddings G1 (1024ì°¨ì›) ë˜ëŠ” Cohere Embed
- **ë°°ì¹˜ ì²˜ë¦¬**: Lambda ë˜ëŠ” SageMaker Endpoint
- **ë¹„ìš© ìµœì í™”**: ìºì‹± ë° ì¤‘ë³µ ì œê±°

#### 3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- **ì¸ë±ìŠ¤ ì„¤ì •**: k-NN, HNSW ì•Œê³ ë¦¬ì¦˜
- **í•œêµ­ì–´ ë¶„ì„ê¸°**: Nori Tokenizer (í˜•íƒœì†Œ ë¶„ì„)
- **ìƒ¤ë“œ êµ¬ì„±**: ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ìµœì í™”
- **ë ˆí”Œë¦¬ì¹´**: Multi-AZ ê°€ìš©ì„± í™•ë³´

#### 4. LLM
- **ëª¨ë¸ ì„ íƒ**: Claude 3.5 Sonnet (ê³ í’ˆì§ˆ), Haiku (ì†ë„)
- **ë©€í‹° ë¦¬ì „**: us-east-1 (ì£¼), us-west-2 (ë°±ì—…)
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: RAG ìµœì í™” í…œí”Œë¦¿

---

## ğŸš€ í™˜ê²½ êµ¬ì¶•

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **AWS ê³„ì •**: í™œì„±í™”ëœ AWS ê³„ì •
- **ê¶Œí•œ**: OpenSearch, Bedrock, S3, Lambda, IAM ì ‘ê·¼ ê¶Œí•œ
- **Python**: 3.8 ì´ìƒ
- **ë¦¬ì „**: us-east-1 (Bedrock ì§€ì› ë¦¬ì „)

### 1. AWS CLI ì„¤ì •

```bash
# AWS CLI ì„¤ì¹˜
pip install awscli

# AWS ì¸ì¦ ì •ë³´ ì„¤ì •
aws configure
# AWS Access Key ID: YOUR_ACCESS_KEY
# AWS Secret Access Key: YOUR_SECRET_KEY
# Default region name: us-east-1
# Default output format: json

# ì„¤ì¹˜ í™•ì¸
aws sts get-caller-identity
```

### 2. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install boto3 opensearch-py python-dotenv
pip install PyPDF2 python-docx pandas numpy
pip install requests-aws4auth  # OpenSearch ì¸ì¦ìš©

# ì„ íƒ íŒ¨í‚¤ì§€ (ë©€í‹°ëª¨ë‹¬)
pip install Pillow
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:

```env
# AWS ì„¤ì •
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key

# OpenSearch ì„¤ì •
OPENSEARCH_ENDPOINT=your-domain.us-east-1.es.amazonaws.com
OPENSEARCH_INDEX=mi_content_rag_dev_index
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=your_password

# Bedrock ì„¤ì •
BEDROCK_EMBED_MODEL=amazon.titan-embed-text-v1
BEDROCK_LLM_MODEL=anthropic.claude-3-5-sonnet-20240620-v1:0
```

### 4. ì„¤ì¹˜ í™•ì¸

í™˜ê²½ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:

```python
# test_setup.py
import sys

def check_dependencies():
    """í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸"""
    print("ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì¤‘...\n")

    required_packages = {
        'boto3': 'AWS SDK',
        'opensearchpy': 'OpenSearch í´ë¼ì´ì–¸íŠ¸',
        'requests_aws4auth': 'AWS ì¸ì¦',
        'dotenv': 'í™˜ê²½ ë³€ìˆ˜'
    }

    missing_packages = []

    for package, description in required_packages.items():
        try:
            __import__(package.replace('-', '_'))
            print(f"âœ… {description} ({package})")
        except ImportError:
            print(f"âŒ {description} ({package}) - ì„¤ì¹˜ í•„ìš”")
            missing_packages.append(package)

    if missing_packages:
        print(f"\nâš ï¸  ë‹¤ìŒ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print(f"pip install {' '.join(missing_packages)}")
        return False

    print("\nâœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ")
    return True

def check_aws_credentials():
    """AWS ì¸ì¦ ì •ë³´ í™•ì¸"""
    import boto3
    print("\nğŸ”‘ AWS ì¸ì¦ ì •ë³´ í™•ì¸ ì¤‘...\n")

    try:
        sts = boto3.client('sts')
        identity = sts.get_caller_identity()
        print(f"âœ… AWS ê³„ì • ID: {identity['Account']}")
        print(f"âœ… User ARN: {identity['Arn']}")
        return True
    except Exception as e:
        print(f"âŒ AWS ì¸ì¦ ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ aws configure ëª…ë ¹ì–´ë¡œ ì¸ì¦ ì •ë³´ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        return False

def check_bedrock_access():
    """Bedrock ì ‘ê·¼ í™•ì¸"""
    import boto3
    import json
    print("\nğŸ¤– Bedrock ì ‘ê·¼ í™•ì¸ ì¤‘...\n")

    try:
        bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')

        # ê°„ë‹¨í•œ ì„ë² ë”© í…ŒìŠ¤íŠ¸
        response = bedrock.invoke_model(
            modelId='amazon.titan-embed-text-v1',
            body=json.dumps({"inputText": "test"})
        )

        result = json.loads(response['body'].read())
        print(f"âœ… Bedrock ì—°ê²° ì„±ê³µ")
        print(f"âœ… Titan Embeddings ì‚¬ìš© ê°€ëŠ¥ ({len(result['embedding'])}ì°¨ì›)")
        return True
    except Exception as e:
        print(f"âŒ Bedrock ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ us-east-1 ë¦¬ì „ì—ì„œ Bedrock ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”")
        return False

def check_opensearch_connection():
    """OpenSearch ì—°ê²° í™•ì¸"""
    import boto3
    import os
    from dotenv import load_dotenv
    from opensearchpy import OpenSearch, RequestsHttpConnection
    from requests_aws4auth import AWS4Auth

    print("\nğŸ” OpenSearch ì—°ê²° í™•ì¸ ì¤‘...\n")

    load_dotenv()

    endpoint = os.getenv('OPENSEARCH_ENDPOINT')
    if not endpoint:
        print("âŒ OPENSEARCH_ENDPOINT í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print("ğŸ’¡ .env íŒŒì¼ì„ ìƒì„±í•˜ê³  OpenSearch ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        return False

    try:
        region = os.getenv('AWS_REGION', 'us-east-1')
        service = 'es'
        credentials = boto3.Session().get_credentials()
        awsauth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            region,
            service,
            session_token=credentials.token
        )

        client = OpenSearch(
            hosts=[{'host': endpoint, 'port': 443}],
            http_auth=awsauth,
            use_ssl=True,
            verify_certs=True,
            connection_class=RequestsHttpConnection,
            timeout=10
        )

        info = client.info()
        print(f"âœ… OpenSearch ì—°ê²° ì„±ê³µ")
        print(f"âœ… ë²„ì „: {info['version']['number']}")
        print(f"âœ… í´ëŸ¬ìŠ¤í„°: {info['cluster_name']}")

        # ì¸ë±ìŠ¤ í™•ì¸
        index_name = os.getenv('OPENSEARCH_INDEX')
        if index_name:
            if client.indices.exists(index=index_name):
                print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ì¡´ì¬")
            else:
                print(f"âš ï¸  ì¸ë±ìŠ¤ '{index_name}'ê°€ ì—†ìŠµë‹ˆë‹¤ (ìƒì„± í•„ìš”)")

        return True
    except Exception as e:
        print(f"âŒ OpenSearch ì—°ê²° ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ OpenSearch ì—”ë“œí¬ì¸íŠ¸ì™€ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”")
        return False

def main():
    print("=" * 60)
    print("  Amazon OpenSearch RAG í™˜ê²½ ì„¤ì • í™•ì¸")
    print("=" * 60)

    checks = [
        check_dependencies(),
        check_aws_credentials(),
        check_bedrock_access(),
        check_opensearch_connection()
    ]

    print("\n" + "=" * 60)
    if all(checks):
        print("ğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("   ì´ì œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  ì¼ë¶€ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”.")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

**ì‹¤í–‰:**
```bash
python test_setup.py
```

**ì˜ˆìƒ ì¶œë ¥:**
```
============================================================
  Amazon OpenSearch RAG í™˜ê²½ ì„¤ì • í™•ì¸
============================================================
ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì¤‘...

âœ… AWS SDK (boto3)
âœ… OpenSearch í´ë¼ì´ì–¸íŠ¸ (opensearchpy)
âœ… AWS ì¸ì¦ (requests_aws4auth)
âœ… í™˜ê²½ ë³€ìˆ˜ (dotenv)

âœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ

ğŸ”‘ AWS ì¸ì¦ ì •ë³´ í™•ì¸ ì¤‘...

âœ… AWS ê³„ì • ID: 123456789012
âœ… User ARN: arn:aws:iam::123456789012:user/your-user

ğŸ¤– Bedrock ì ‘ê·¼ í™•ì¸ ì¤‘...

âœ… Bedrock ì—°ê²° ì„±ê³µ
âœ… Titan Embeddings ì‚¬ìš© ê°€ëŠ¥ (1024ì°¨ì›)

ğŸ” OpenSearch ì—°ê²° í™•ì¸ ì¤‘...

âœ… OpenSearch ì—°ê²° ì„±ê³µ
âœ… ë²„ì „: 2.17.0
âœ… í´ëŸ¬ìŠ¤í„°: your-cluster-name
âœ… ì¸ë±ìŠ¤ 'mi_content_rag_dev_index' ì¡´ì¬

============================================================
ğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!
   ì´ì œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.
============================================================
```

---

## ğŸ“ OpenSearch ì¸ë±ìŠ¤ ìƒì„±

### ì‹¤ì „ ì¸ë±ìŠ¤ ì„¤ì • (í•œêµ­ì–´ ìµœì í™”)

ì´ ì„¤ì •ì€ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¸ë±ìŠ¤ êµ¬ì„±ì…ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•:**
- âœ… **Nori í˜•íƒœì†Œ ë¶„ì„ê¸°**: í•œêµ­ì–´ í† í°í™” ë° ê²€ìƒ‰ ìµœì í™”
- âœ… **HNSW ë²¡í„° ê²€ìƒ‰**: 1024ì°¨ì› ë²¡í„°, cosine ìœ ì‚¬ë„
- âœ… **ë‹¤ì¸µ ë©”íƒ€ë°ì´í„°**: ì¹´í…Œê³ ë¦¬, íŒŒì¼ëª…, í˜ì´ì§€ ë²ˆí˜¸ ë“±
- âœ… **Hybrid Search ì§€ì›**: í…ìŠ¤íŠ¸ + ë²¡í„° ë™ì‹œ ê²€ìƒ‰


#### ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (opensearch_create_index.py)

```python
"""
OpenSearch ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
- Nori í•œêµ­ì–´ ë¶„ì„ê¸° ì„¤ì •
- HNSW ë²¡í„° ê²€ìƒ‰ ì„¤ì •
- ë‹¤ì¸µ ë©”íƒ€ë°ì´í„° êµ¬ì¡°
"""
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
import boto3
import os
from dotenv import load_dotenv

load_dotenv()

# AWS ì¸ì¦
region = os.getenv('AWS_REGION')
service = 'es'
credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(
    credentials.access_key, 
    credentials.secret_key,
    region, 
    service,
    session_token=credentials.token
)

# OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenSearch(
    hosts=[{'host': os.getenv('OPENSEARCH_ENDPOINT'), 'port': 443}],
    http_auth=awsauth,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection
)

# ì‹¤ì „ ì¸ë±ìŠ¤ ë§¤í•‘ (í”„ë¡œë•ì…˜ ë ˆë²¨)
index_body = {
    "mappings": {
        "properties": {
            "metadata": {
                "properties": {
                    "content_category1_id": {"type": "long"},
                    "content_category1_name": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_category2_id": {"type": "long"},
                    "content_category2_name": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_category3_id": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_category3_name": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_file_name": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_id": {"type": "long"},
                    "content_page_no": {"type": "long"},
                    "content_total_pages": {"type": "long"},
                    "content_subject": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_type": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    },
                    "content_url": {
                        "type": "text",
                        "fields": {
                            "keyword": {
                                "type": "keyword",
                                "ignore_above": 256
                            }
                        }
                    }
                }
            },
            # í…ìŠ¤íŠ¸ í•„ë“œ (Nori ë¶„ì„ê¸° ì ìš©)
            "text": {
                "type": "text",
                "fields": {
                    "keyword": {
                        "type": "keyword",
                        "ignore_above": 256
                    }
                },
                "analyzer": "nori_custom_analyzer"
            },
            # ë²¡í„° í•„ë“œ (HNSW ê²€ìƒ‰)
            "vector_field": {
                "type": "knn_vector",
                "dimension": 1024,  # Titan Embeddings ì°¨ì›
                "method": {
                    "engine": "nmslib",
                    "space_type": "l2",  # ìœ í´ë¦¬ë“œ ê±°ë¦¬
                    "name": "hnsw",
                    "parameters": {
                        "ef_construction": 1024,  # ì¸ë±ìŠ¤ êµ¬ì¶• í’ˆì§ˆ
                        "m": 32  # ê·¸ë˜í”„ ì—°ê²° ìˆ˜
                    }
                }
            }
        }
    },
    "settings": {
        "index": {
            "replication": {
                "type": "DOCUMENT"
            },
            "number_of_shards": "5",
            "number_of_replicas": "1",
            "knn.algo_param": {
                "ef_search": "1024"  # ê²€ìƒ‰ ì‹œ ì •í™•ë„
            },
            "knn": "true",
            # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì„¤ì •
            "analysis": {
                "analyzer": {
                    "nori_custom_analyzer": {
                        "filter": [
                            "nori_number",
                            "nori_readingform",
                            "lowercase"
                        ],
                        "char_filter": [
                            "html_strip"
                        ],
                        "type": "custom",
                        "tokenizer": "nori"
                    }
                },
                "tokenizer": {
                    "nori": {
                        "type": "nori_tokenizer",
                        "decompound_mode": "mixed",  # ë³µí•©ì–´ ë¶„í•´ ëª¨ë“œ
                        "discard_punctuation": "true"
                    }
                }
            }
        }
    }
}

# ì¸ë±ìŠ¤ ìƒì„±
index_name = os.getenv('OPENSEARCH_INDEX')

try:
    if client.indices.exists(index=index_name):
        print(f"âš ï¸ ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {index_name}")
        response = input("ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() == 'y':
            client.indices.delete(index=index_name)
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ")
    
    client.indices.create(index=index_name, body=index_body)
    print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_name}")
    
    # ì¸ë±ìŠ¤ ì •ë³´ í™•ì¸
    info = client.indices.get(index=index_name)
    print(f"\nğŸ“Š ì¸ë±ìŠ¤ ì„¤ì •:")
    print(f"  - Shards: {info[index_name]['settings']['index']['number_of_shards']}")
    print(f"  - Replicas: {info[index_name]['settings']['index']['number_of_replicas']}")
    print(f"  - Vector Dimension: 1024")
    print(f"  - Analyzer: nori_custom_analyzer")
    print(f"  - Algorithm: HNSW")
    
except Exception as e:
    print(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
```

**ì‹¤í–‰:**
```bash
python opensearch_create_index.py
```

### Nori ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸

ìƒì„±í•œ ì¸ë±ìŠ¤ì˜ Nori ë¶„ì„ê¸°ê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸:

```python
# test_nori_analyzer.py
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
import boto3
import os

# OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ìœ„ì™€ ë™ì¼)
# ...

# í•œêµ­ì–´ ë¶„ì„ í…ŒìŠ¤íŠ¸
test_text = "Amazon OpenSearchë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•"

result = client.indices.analyze(
    index=os.getenv('OPENSEARCH_INDEX'),
    body={
        "analyzer": "nori_custom_analyzer",
        "text": test_text
    }
)

print(f"ì›ë¬¸: {test_text}")
print(f"\ní† í°í™” ê²°ê³¼:")
for token in result['tokens']:
    print(f"  - {token['token']} (ìœ„ì¹˜: {token['position']})")

# ì˜ˆìƒ ì¶œë ¥:
# ì›ë¬¸: Amazon OpenSearchë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•
# í† í°í™” ê²°ê³¼:
#   - amazon (ìœ„ì¹˜: 0)
#   - opensearch (ìœ„ì¹˜: 1)
#   - ë¥¼ (ìœ„ì¹˜: 2)
#   - í™œìš© (ìœ„ì¹˜: 3)
#   - í•œ (ìœ„ì¹˜: 4)
#   - rag (ìœ„ì¹˜: 5)
#   - ì‹œìŠ¤í…œ (ìœ„ì¹˜: 6)
#   - êµ¬ì¶• (ìœ„ì¹˜: 7)
```

---

## ğŸ”§ Lambda ê¸°ë°˜ RAG êµ¬í˜„

### Lambda ê³„ì¸µ ìƒì„± (opensearch-py)

Lambdaì—ì„œ OpenSearchë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ê³„ì¸µ ì¤€ë¹„:

```bash
# 1. ê³„ì¸µì„ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p opensearch-layer/python

# 2. Python ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python3 -m venv opensearch-layer/venv
source opensearch-layer/venv/bin/activate

# 3. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install opensearch-py requests-aws4auth

# 4. site-packages í´ë”ë¥¼ python ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
cp -r opensearch-layer/venv/lib/python3.*/site-packages/* opensearch-layer/python/

# 5. ê³„ì¸µ íŒ¨í‚¤ì§•
cd opensearch-layer
zip -r opensearch-layer.zip python

# 6. ì••ì¶• íŒŒì¼ ìƒì„± í›„, ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”
deactivate

# 7. AWS Lambda ê³„ì¸µìœ¼ë¡œ ì—…ë¡œë“œ
aws lambda publish-layer-version \
    --layer-name opensearch-layer \
    --zip-file fileb://opensearch-layer.zip \
    --compatible-runtimes python3.12
```

### IAM ì—­í•  ìƒì„±

Lambda í•¨ìˆ˜ê°€ OpenSearch, Bedrock, S3ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ IAM ì—­í• :

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "BedrockAccess",
      "Effect": "Allow",
      "Action": [
        "bedrock:InvokeModel"
      ],
      "Resource": [
        "arn:aws:bedrock:*::foundation-model/amazon.titan-embed-text-v1",
        "arn:aws:bedrock:*::foundation-model/amazon.titan-embed-image-v1",
        "arn:aws:bedrock:*::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0"
      ]
    },
    {
      "Sid": "S3Access",
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject"
      ],
      "Resource": [
        "arn:aws:s3:::your-bucket-name/*"
      ]
    },
    {
      "Sid": "OpenSearchAccess",
      "Effect": "Allow",
      "Action": [
        "es:ESHttpGet",
        "es:ESHttpPut",
        "es:ESHttpPost",
        "es:ESHttpDelete"
      ],
      "Resource": [
        "arn:aws:es:*:*:domain/your-domain-name/*"
      ]
    },
    {
      "Sid": "CloudWatchLogs",
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:*:*:*"
    }
  ]
}
```

### Lambda í•¨ìˆ˜ 1: ë¬¸ì„œ ì¸ë±ì‹±

S3ì— ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ë©´ ìë™ìœ¼ë¡œ ì„ë² ë”©í•˜ì—¬ OpenSearchì— ì €ì¥:

```python
# lambda_indexing.py
import os
import json
import boto3
import base64
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth

def lambda_handler(event, context):
    """
    S3 ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°ë¡œ ë¬¸ì„œ ì¸ë±ì‹±
    """
    # í™˜ê²½ ë³€ìˆ˜
    opensearch_region = os.getenv('OPENSEARCH_REGION')
    opensearch_host = os.getenv('OPENSEARCH_HOST')
    opensearch_index = os.getenv('OPENSEARCH_INDEX')
    
    # S3 ì´ë²¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    
    print(f"Processing: s3://{bucket}/{key}")
    
    # S3ì—ì„œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    s3 = boto3.client('s3')
    response = s3.get_object(Bucket=bucket, Key=key)
    
    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
    if key.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp')):
        # ì´ë¯¸ì§€ íŒŒì¼
        image_content = response['Body'].read()
        vector = embed_image(image_content)
        text = f"Image: {key}"
    else:
        # í…ìŠ¤íŠ¸ íŒŒì¼
        text_content = response['Body'].read().decode('utf-8')
        vector = embed_text(text_content)
        text = text_content
    
    # OpenSearchì— ì €ì¥
    save_to_opensearch(
        opensearch_host,
        opensearch_index,
        opensearch_region,
        vector,
        text,
        {
            's3_bucket': bucket,
            's3_key': key,
            'content_type': key.split('.')[-1]
        }
    )
    
    return {
        'statusCode': 200,
        'body': json.dumps(f'Successfully indexed: {key}')
    }

def embed_image(image_bytes):
    """ì´ë¯¸ì§€ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©"""
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
    
    image_base64 = base64.b64encode(image_bytes).decode('utf-8')
    
    response = bedrock.invoke_model(
        modelId="amazon.titan-embed-image-v1",
        contentType="application/json",
        accept="application/json",
        body=json.dumps({
            "inputImage": image_base64
        })
    )
    
    result = json.loads(response['body'].read())
    return result['embedding']

def embed_text(text):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©"""
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
    
    response = bedrock.invoke_model(
        modelId='amazon.titan-embed-text-v1',
        body=json.dumps({"inputText": text})
    )
    
    result = json.loads(response['body'].read())
    return result['embedding']

def save_to_opensearch(host, index, region, vector, text, metadata):
    """OpenSearchì— ë²¡í„° ì €ì¥"""
    # AWS ì¸ì¦
    service = 'es'
    credentials = boto3.Session().get_credentials()
    awsauth = AWS4Auth(
        credentials.access_key,
        credentials.secret_key,
        region,
        service,
        session_token=credentials.token
    )
    
    # OpenSearch í´ë¼ì´ì–¸íŠ¸
    client = OpenSearch(
        hosts=[{'host': host, 'port': 443}],
        http_auth=awsauth,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection
    )
    
    # ë¬¸ì„œ ì €ì¥
    document = {
        'vector_field': vector,
        'text': text,
        'metadata': metadata
    }
    
    client.index(index=index, body=document)
    print(f"âœ… Saved to OpenSearch: {metadata['s3_key']}")
```

### Lambda í•¨ìˆ˜ 2: ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±

ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ OpenSearch ê²€ìƒ‰ í›„ Claudeë¡œ ë‹µë³€ ìƒì„±:

```python
# lambda_query.py
import os
import json
import boto3
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth

def lambda_handler(event, context):
    """
    RAG íŒŒì´í”„ë¼ì¸: ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±
    """
    # í™˜ê²½ ë³€ìˆ˜
    opensearch_region = os.getenv('OPENSEARCH_REGION')
    opensearch_host = os.getenv('OPENSEARCH_HOST')
    opensearch_index = os.getenv('OPENSEARCH_INDEX')
    
    # ì‚¬ìš©ì ì§ˆë¬¸
    query = event.get('query', '')
    search_type = event.get('type', 'text')  # text ë˜ëŠ” image
    top_k = event.get('top_k', 5)
    
    print(f"Query: {query}, Type: {search_type}")
    
    # 1. ì§ˆë¬¸ ì„ë² ë”©
    if search_type == 'image':
        # ì´ë¯¸ì§€ ê²€ìƒ‰ (S3 ê²½ë¡œë¡œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°)
        image_bucket = event.get('s3_bucket')
        image_key = event.get('s3_key')
        s3 = boto3.client('s3')
        response = s3.get_object(Bucket=image_bucket, Key=image_key)
        image_content = response['Body'].read()
        query_vector = embed_image(image_content)
    else:
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        query_vector = embed_text(query)
    
    # 2. OpenSearch ê²€ìƒ‰
    search_results = search_opensearch(
        opensearch_host,
        opensearch_index,
        opensearch_region,
        query_vector,
        top_k
    )
    
    # 3. Claudeë¡œ ë‹µë³€ ìƒì„±
    if search_type == 'text':
        answer = generate_answer(query, search_results)
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'answer': answer,
                'sources': [
                    {
                        'text': hit['_source']['text'][:200],
                        'score': hit['_score'],
                        'metadata': hit['_source'].get('metadata', {})
                    }
                    for hit in search_results
                ]
            }, ensure_ascii=False)
        }
    else:
        # ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
        return {
            'statusCode': 200,
            'body': json.dumps({
                'results': [
                    {
                        'score': hit['_score'],
                        's3_key': hit['_source']['metadata']['s3_key'],
                        's3_bucket': hit['_source']['metadata']['s3_bucket']
                    }
                    for hit in search_results
                ]
            })
        }

def embed_text(text):
    """í…ìŠ¤íŠ¸ ì„ë² ë”©"""
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
    
    response = bedrock.invoke_model(
        modelId='amazon.titan-embed-text-v1',
        body=json.dumps({"inputText": text})
    )
    
    result = json.loads(response['body'].read())
    return result['embedding']

def embed_image(image_bytes):
    """ì´ë¯¸ì§€ ì„ë² ë”©"""
    import base64
    
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
    image_base64 = base64.b64encode(image_bytes).decode('utf-8')
    
    response = bedrock.invoke_model(
        modelId="amazon.titan-embed-image-v1",
        contentType="application/json",
        accept="application/json",
        body=json.dumps({"inputImage": image_base64})
    )
    
    result = json.loads(response['body'].read())
    return result['embedding']

def search_opensearch(host, index, region, query_vector, top_k):
    """OpenSearch k-NN ê²€ìƒ‰"""
    # AWS ì¸ì¦
    service = 'es'
    credentials = boto3.Session().get_credentials()
    awsauth = AWS4Auth(
        credentials.access_key,
        credentials.secret_key,
        region,
        service,
        session_token=credentials.token
    )
    
    # OpenSearch í´ë¼ì´ì–¸íŠ¸
    client = OpenSearch(
        hosts=[{'host': host, 'port': 443}],
        http_auth=awsauth,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection
    )
    
    # k-NN ê²€ìƒ‰ ì¿¼ë¦¬
    search_body = {
        "size": top_k,
        "query": {
            "knn": {
                "vector_field": {
                    "vector": query_vector,
                    "k": top_k
                }
            }
        },
        "_source": ["text", "metadata"]
    }
    
    response = client.search(index=index, body=search_body)
    return response['hits']['hits']

def generate_answer(query, search_results):
    """Claudeë¡œ ë‹µë³€ ìƒì„±"""
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}]\n{hit['_source']['text']}"
        for i, hit in enumerate(search_results)
    ])
    
    # í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.

<ë¬¸ì„œ>
{context}
</ë¬¸ì„œ>

<ì§ˆë¬¸>
{query}
</ì§ˆë¬¸>

ë‹µë³€:"""
    
    # Claude í˜¸ì¶œ
    response = bedrock.invoke_model(
        modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',
        body=json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 2000,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3
        })
    )
    
    result = json.loads(response['body'].read())
    return result['content'][0]['text']
```

### Lambda ë°°í¬

```bash
# Lambda í•¨ìˆ˜ 1 ë°°í¬
zip -r lambda_indexing.zip lambda_indexing.py

aws lambda create-function \
    --function-name RAG-Indexing \
    --runtime python3.12 \
    --role arn:aws:iam::YOUR_ACCOUNT:role/lambda-opensearch-role \
    --handler lambda_indexing.lambda_handler \
    --zip-file fileb://lambda_indexing.zip \
    --timeout 60 \
    --memory-size 512 \
    --layers arn:aws:lambda:us-east-1:YOUR_ACCOUNT:layer:opensearch-layer:1 \
    --environment Variables="{OPENSEARCH_HOST=your-domain.us-east-1.es.amazonaws.com,OPENSEARCH_INDEX=mi_content_rag_dev_index,OPENSEARCH_REGION=us-east-1}"

# S3 íŠ¸ë¦¬ê±° ì¶”ê°€
aws s3api put-bucket-notification-configuration \
    --bucket your-bucket-name \
    --notification-configuration file://s3-notification.json

# Lambda í•¨ìˆ˜ 2 ë°°í¬
zip -r lambda_query.zip lambda_query.py

aws lambda create-function \
    --function-name RAG-Query \
    --runtime python3.12 \
    --role arn:aws:iam::YOUR_ACCOUNT:role/lambda-opensearch-role \
    --handler lambda_query.lambda_handler \
    --zip-file fileb://lambda_query.zip \
    --timeout 60 \
    --memory-size 1024 \
    --layers arn:aws:lambda:us-east-1:YOUR_ACCOUNT:layer:opensearch-layer:1 \
    --environment Variables="{OPENSEARCH_HOST=your-domain.us-east-1.es.amazonaws.com,OPENSEARCH_INDEX=mi_content_rag_dev_index,OPENSEARCH_REGION=us-east-1}"
```

**s3-notification.json:**
```json
{
  "LambdaFunctionConfigurations": [
    {
      "LambdaFunctionArn": "arn:aws:lambda:us-east-1:YOUR_ACCOUNT:function:RAG-Indexing",
      "Events": ["s3:ObjectCreated:*"],
      "Filter": {
        "Key": {
          "FilterRules": [
            {
              "Name": "prefix",
              "Value": "documents/"
            }
          ]
        }
      }
    }
  ]
}
```

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1. ë¡œì»¬ í™˜ê²½ì—ì„œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (ì´ˆë³´ììš©)

Lambdaë‚˜ ë³µì¡í•œ AWS ì„¤ì • ì—†ì´ ë¡œì»¬ì—ì„œ OpenSearchì™€ Bedrockì„ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# simple_test.py - ë¡œì»¬ í™˜ê²½ í…ŒìŠ¤íŠ¸
import boto3
import json
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
import os
from dotenv import load_dotenv

load_dotenv()

def main():
    # 1. OpenSearch ì—°ê²°
    print("1ï¸âƒ£ OpenSearch ì—°ê²° ì¤‘...")
    region = os.getenv('AWS_REGION', 'us-east-1')
    service = 'es'
    credentials = boto3.Session().get_credentials()
    awsauth = AWS4Auth(
        credentials.access_key,
        credentials.secret_key,
        region,
        service,
        session_token=credentials.token
    )

    opensearch_client = OpenSearch(
        hosts=[{'host': os.getenv('OPENSEARCH_ENDPOINT'), 'port': 443}],
        http_auth=awsauth,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection
    )

    # ì—°ê²° í…ŒìŠ¤íŠ¸
    info = opensearch_client.info()
    print(f"âœ… OpenSearch ì—°ê²° ì„±ê³µ: {info['version']['number']}")

    # 2. Bedrockìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”©
    print("\n2ï¸âƒ£ Bedrockìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘...")
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')

    test_text = "Amazon OpenSearchëŠ” ê°•ë ¥í•œ ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤."

    response = bedrock.invoke_model(
        modelId='amazon.titan-embed-text-v1',
        body=json.dumps({"inputText": test_text})
    )

    result = json.loads(response['body'].read())
    vector = result['embedding']
    print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(vector)}ì°¨ì› ë²¡í„°")

    # 3. OpenSearchì— ì €ì¥
    print("\n3ï¸âƒ£ OpenSearchì— ë¬¸ì„œ ì €ì¥ ì¤‘...")
    index_name = os.getenv('OPENSEARCH_INDEX')

    document = {
        'vector_field': vector,
        'text': test_text,
        'metadata': {
            'source': 'test',
            'timestamp': '2024-12-09'
        }
    }

    opensearch_client.index(
        index=index_name,
        body=document,
        refresh=True
    )
    print("âœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")

    # 4. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    query_text = "OpenSearchì˜ íŠ¹ì§•ì€?"

    # ì¿¼ë¦¬ ì„ë² ë”©
    query_response = bedrock.invoke_model(
        modelId='amazon.titan-embed-text-v1',
        body=json.dumps({"inputText": query_text})
    )
    query_vector = json.loads(query_response['body'].read())['embedding']

    # k-NN ê²€ìƒ‰
    search_body = {
        "size": 3,
        "query": {
            "knn": {
                "vector_field": {
                    "vector": query_vector,
                    "k": 3
                }
            }
        }
    }

    search_results = opensearch_client.search(
        index=index_name,
        body=search_body
    )

    print(f"\nê²€ìƒ‰ ê²°ê³¼ ({search_results['hits']['total']['value']}ê°œ):")
    for hit in search_results['hits']['hits']:
        print(f"  - {hit['_source']['text']} (ì ìˆ˜: {hit['_score']:.3f})")

    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
```

**ì‹¤í–‰ ë°©ë²•:**
```bash
python simple_test.py
```

**ì˜ˆìƒ ì¶œë ¥:**
```
1ï¸âƒ£ OpenSearch ì—°ê²° ì¤‘...
âœ… OpenSearch ì—°ê²° ì„±ê³µ: 2.17.0

2ï¸âƒ£ Bedrockìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘...
âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: 1024ì°¨ì› ë²¡í„°

3ï¸âƒ£ OpenSearchì— ë¬¸ì„œ ì €ì¥ ì¤‘...
âœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ

4ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...

ê²€ìƒ‰ ê²°ê³¼ (1ê°œ):
  - Amazon OpenSearchëŠ” ê°•ë ¥í•œ ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤. (ì ìˆ˜: 0.985)

âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
```

### 2. ì—”ë“œíˆ¬ì—”ë“œ Lambda í…ŒìŠ¤íŠ¸ (í”„ë¡œë•ì…˜)

Lambda í•¨ìˆ˜ê°€ ë°°í¬ëœ í›„ ì „ì²´ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

```python
# test_rag_system.py
import boto3
import json

# Lambda í´ë¼ì´ì–¸íŠ¸
lambda_client = boto3.client('lambda', region_name='us-east-1')

# 1. ë¬¸ì„œ ì—…ë¡œë“œ (S3ì— ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ Lambda íŠ¸ë¦¬ê±°)
s3 = boto3.client('s3')
s3.upload_file(
    'company_handbook.pdf',
    'your-bucket-name',
    'documents/company_handbook.pdf'
)
print("âœ… ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ (ìë™ ì¸ë±ì‹± ì¤‘...)")

# ì¸ë±ì‹± ëŒ€ê¸°
import time
time.sleep(5)

# 2. RAG ì§ˆì˜
response = lambda_client.invoke(
    FunctionName='RAG-Query',
    Payload=json.dumps({
        'query': 'íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ ì •ì±…ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?',
        'type': 'text',
        'top_k': 5
    })
)

result = json.loads(response['Payload'].read())
body = json.loads(result['body'])

print(f"\nì§ˆë¬¸: íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ ì •ì±…ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")
print(f"\në‹µë³€:\n{body['answer']}")
print(f"\nì°¸ê³  ë¬¸ì„œ:")
for i, source in enumerate(body['sources'], 1):
    print(f"  {i}. {source['text'][:100]}... (ì ìˆ˜: {source['score']:.3f})")
```

---

## ğŸ“š ìƒì„¸ ê°€ì´ë“œ

### 1. Hybrid Search êµ¬í˜„ (Semantic + Lexical)

ìµœê³ ì˜ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰:

```python
def hybrid_search(client, index, query_text, query_vector, top_k=10):
    """
    ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°í•©
    - Semantic Search: ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
    - Lexical Search: BM25 í‚¤ì›Œë“œ ê²€ìƒ‰
    """
    search_body = {
        "size": top_k,
        "query": {
            "bool": {
                "should": [
                    {
                        # Semantic Search
                        "knn": {
                            "vector_field": {
                                "vector": query_vector,
                                "k": top_k,
                                "boost": 1.0  # ê°€ì¤‘ì¹˜
                            }
                        }
                    },
                    {
                        # Lexical Search (BM25)
                        "multi_match": {
                            "query": query_text,
                            "fields": ["text^2", "metadata.content_subject"],
                            "type": "best_fields",
                            "boost": 0.5,
                            "analyzer": "nori_custom_analyzer"
                        }
                    }
                ],
                "minimum_should_match": 1
            }
        },
        "_source": ["text", "metadata"]
    }
    
    response = client.search(index=index, body=search_body)
    return response['hits']['hits']
```

### 2. ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰

íŠ¹ì • ì¹´í…Œê³ ë¦¬ë‚˜ ë¬¸ì„œ íƒ€ì…ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ ì œí•œ:

```python
def filtered_search(client, index, query_vector, filters, top_k=10):
    """
    ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ ê²€ìƒ‰
    ì˜ˆ: íŠ¹ì • ì¹´í…Œê³ ë¦¬, ë¬¸ì„œ íƒ€ì…, ë‚ ì§œ ë²”ìœ„ ë“±
    """
    filter_clauses = []
    
    # í•„í„° ì¡°ê±´ êµ¬ì„±
    for field, value in filters.items():
        if isinstance(value, list):
            # IN ì¡°ê±´
            filter_clauses.append({
                "terms": {f"metadata.{field}": value}
            })
        else:
            # ì¼ì¹˜ ì¡°ê±´
            filter_clauses.append({
                "term": {f"metadata.{field}.keyword": value}
            })
    
    search_body = {
        "size": top_k,
        "query": {
            "bool": {
                "must": [
                    {
                        "knn": {
                            "vector_field": {
                                "vector": query_vector,
                                "k": top_k
                            }
                        }
                    }
                ],
                "filter": filter_clauses
            }
        }
    }
    
    response = client.search(index=index, body=search_body)
    return response['hits']['hits']

# ì‚¬ìš© ì˜ˆì‹œ
filters = {
    "content_type": "pdf",
    "content_category1_name": "HRì •ì±…"
}
results = filtered_search(client, index_name, query_vector, filters)
```

### 3. ì²­í‚¹ ì „ëµ

#### ê³ ì • í¬ê¸° ì²­í‚¹
```python
def fixed_size_chunking(text, chunk_size=1000, overlap=200):
    """
    ê³ ì • í¬ê¸° ì²­í‚¹
    - ì¥ì : êµ¬í˜„ ê°„ë‹¨, ì¼ê´€ëœ í¬ê¸°
    - ë‹¨ì : ì˜ë¯¸ ë‹¨ìœ„ ë¬´ì‹œ ê°€ëŠ¥
    """
    chunks = []
    start = 0
    text_len = len(text)
    
    while start < text_len:
        end = min(start + chunk_size, text_len)
        chunks.append(text[start:end])
        start = end - overlap  # ì˜¤ë²„ë© ì ìš©
    
    return chunks
```

#### ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ (ê¶Œì¥)
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

def semantic_chunking(text, chunk_size=1500, chunk_overlap=200):
    """
    ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹
    - ì¥ì : ë¬¸ë§¥ ë³´ì¡´, ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ
    - ê¶Œì¥: RAG ì‹œìŠ¤í…œì— ìµœì 
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", "!", "?", ";", ",", " ", ""],
        length_function=len
    )
    
    chunks = splitter.split_text(text)
    return chunks
```

### 4. ë°°ì¹˜ ì„ë² ë”©

ëŒ€ëŸ‰ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì„ë² ë”©:

```python
def batch_embed_documents(documents, batch_size=25):
    """
    ë°°ì¹˜ ì„ë² ë”©ìœ¼ë¡œ ì²˜ë¦¬ ì†ë„ í–¥ìƒ
    - Bedrock API í˜¸ì¶œ ìµœì í™”
    - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ ê°œì„ 
    """
    bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
    all_embeddings = []
    
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i+batch_size]
        print(f"Processing batch {i//batch_size + 1}/{(len(documents)-1)//batch_size + 1}")
        
        embeddings = []
        for doc in batch:
            response = bedrock.invoke_model(
                modelId='amazon.titan-embed-text-v1',
                body=json.dumps({"inputText": doc})
            )
            result = json.loads(response['body'].read())
            embeddings.append(result['embedding'])
        
        all_embeddings.extend(embeddings)
    
    return all_embeddings
```

---

## ğŸ”§ ì„±ëŠ¥ ìµœì í™”

### 1. ì„±ëŠ¥ í‰ê°€ ê¸°ë°˜ ìµœì í™” ì „ëµ

#### ì„±ëŠ¥ ì§€í‘œ ì´í•´

| ì§€í‘œ | ì„¤ëª… | ìµœì í™” ëª©í‘œ | SKí•˜ì´ë‹‰ìŠ¤ ì‹¤ì¸¡ |
|------|------|------------|----------------|
| **TTFT** | Time-To-First-Token | <2ì´ˆ | 1-2ì´ˆ |
| **Query Response Time** | ì „ì²´ ì‘ë‹µ ì‹œê°„ | <5ì´ˆ | 3-5ì´ˆ |
| **QPS** | Query Per Second | >10 QPS | 10-15 QPS |
| **ê²€ìƒ‰ ì‹œê°„** | ë²¡í„° ê²€ìƒ‰ ì†Œìš” ì‹œê°„ | <500ms | 80ms (1ëª…) â†’ 2.96ì´ˆ (100ëª…) |

#### ë³‘ëª© êµ¬ê°„ ë¶„ì„ 

```
ì‚¬ìš©ì 1ëª… ê¸°ì¤€:
â”œâ”€ ì„ë² ë”©: 0.08ì´ˆ (5%)
â”œâ”€ ë²¡í„° ê²€ìƒ‰: 0.08ì´ˆ (5%) 
â””â”€ LLM ìƒì„±: 0.96ì´ˆ (90%) âš ï¸ ì£¼ìš” ë³‘ëª©

ì‚¬ìš©ì 100ëª… ê¸°ì¤€:
â”œâ”€ ì„ë² ë”©: 0.12ì´ˆ (1%)
â”œâ”€ ë²¡í„° ê²€ìƒ‰: 2.96ì´ˆ (17%) âš ï¸ 38ë°° ì¦ê°€!
â””â”€ LLM ìƒì„±: 14.65ì´ˆ (82%) âš ï¸ 15ë°° ì¦ê°€
```

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**
- ë²¡í„° ê²€ìƒ‰ ì‹œê°„ì´ ì‚¬ìš©ì ì¦ê°€ ì‹œ ê¸‰ê²©íˆ ì¦ê°€ (38ë°°)
- Disk-based vector searchë¡œ ì „í™˜ ê²€í†  í•„ìš”

### 2. OpenSearch ìµœì í™”

#### HNSW vs Disk-based ì„ íƒ ê¸°ì¤€

```python
def choose_vector_search_method(vector_count, memory_available_gb):
    """
    ë²¡í„° ìˆ˜ì™€ ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì  ë°©ë²• ì„ íƒ
    
    ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ê³µì‹ (HNSW):
    - 1M ë²¡í„° (1024ì°¨ì›) â‰ˆ 3GB
    - 10M ë²¡í„° â‰ˆ 30GB
    """
    hnsw_memory_required = vector_count * 0.003  # GB
    
    if hnsw_memory_required < memory_available_gb * 0.7:
        return {
            "method": "HNSW (In-memory)",
            "reason": "ë©”ëª¨ë¦¬ ì¶©ë¶„, ìµœê³  ì„±ëŠ¥",
            "latency": "5-20ms",
            "accuracy": "> 95%",
            "cost": "$$"
        }
    else:
        return {
            "method": "Disk-based Vector Search",
            "reason": "ë©”ëª¨ë¦¬ ë¶€ì¡±, ë¹„ìš© ìµœì í™”",
            "latency": "50-100ms",
            "accuracy": "> 95%",
            "cost": "$ (32ë°° ë©”ëª¨ë¦¬ ì ˆê°)",
            "compression": "Binary quantization (32x)"
        }

# ì‚¬ìš© ì˜ˆì‹œ
recommendation = choose_vector_search_method(
    vector_count=10_000_000,  # 1000ë§Œ ë²¡í„°
    memory_available_gb=64
)
print(f"ê¶Œì¥ ë°©ë²•: {recommendation['method']}")
print(f"ì´ìœ : {recommendation['reason']}")
print(f"ì‘ë‹µ ì‹œê°„: {recommendation['latency']}")
```

#### ì¸ë±ìŠ¤ ìµœì í™” (í”„ë¡œë•ì…˜ ë ˆë²¨)

```python
# ìµœì í™”ëœ ì¸ë±ìŠ¤ ì„¤ì •
optimal_settings = {
    "settings": {
        "index": {
            "knn": True,
            "knn.algo_param.ef_search": 512,  # ê²€ìƒ‰ ì •í™•ë„ vs ì†ë„
            "number_of_shards": 5,  # ë°ì´í„° í¬ê¸°ì— ë”°ë¼
            "number_of_replicas": 2,  # ê°€ìš©ì„± í™•ë³´
            "refresh_interval": "30s",  # ì‹¤ì‹œê°„ì„± vs ì„±ëŠ¥
            "codec": "best_compression"  # ë””ìŠ¤í¬ ì ˆì•½
        }
    }
}

# ìƒ¤ë“œ ìˆ˜ ê³„ì‚°
def calculate_optimal_shards(index_size_gb, target_shard_size_gb=30):
    """
    ê¶Œì¥: ìƒ¤ë“œë‹¹ 30-50GB
    """
    return max(1, int(index_size_gb / target_shard_size_gb))

# ë ˆí”Œë¦¬ì¹´ ìˆ˜ ê²°ì •
def calculate_replicas(availability_requirement):
    """
    - high: 2ê°œ (Multi-AZ)
    - medium: 1ê°œ
    - low: 0ê°œ (ê°œë°œ í™˜ê²½)
    """
    mapping = {"high": 2, "medium": 1, "low": 0}
    return mapping.get(availability_requirement, 1)
```

### 3. Lambda ìµœì í™”

#### ì½œë“œ ìŠ¤íƒ€íŠ¸ ìµœì†Œí™”

```python
# Lambda í•¨ìˆ˜ ì™¸ë¶€ì—ì„œ ì´ˆê¸°í™” (ì¬ì‚¬ìš©)
import boto3
from opensearchpy import OpenSearch

# ì „ì—­ ë³€ìˆ˜ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
bedrock_client = None
opensearch_client = None

def get_bedrock_client():
    global bedrock_client
    if bedrock_client is None:
        bedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')
    return bedrock_client

def get_opensearch_client():
    global opensearch_client
    if opensearch_client is None:
        # OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì¬ì‚¬ìš©)
        opensearch_client = OpenSearch(...)
    return opensearch_client

def lambda_handler(event, context):
    # ì´ë¯¸ ì´ˆê¸°í™”ëœ í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©
    bedrock = get_bedrock_client()
    opensearch = get_opensearch_client()
    
    # ...
```

#### í”„ë¡œë¹„ì €ë‹ëœ ë™ì‹œì„±

ê³ ì • íŠ¸ë˜í”½ì´ ì˜ˆìƒë˜ëŠ” ê²½ìš°:

```bash
aws lambda put-provisioned-concurrency-config \
    --function-name RAG-Query \
    --provisioned-concurrent-executions 10
```

### 4. ë©€í‹° ë¦¬ì „ ë¡œë“œ ë°¸ëŸ°ì‹± 

```python
class MultiRegionBedrock:
    """
    ë©€í‹° ë¦¬ì „ Bedrockìœ¼ë¡œ íŠ¸ë˜í”½ ë¶„ì‚°
    - ì¥ì : ThrottlingException ë°©ì§€, ê³ ê°€ìš©ì„±
    - us-east-1 + us-west-2
    """
    def __init__(self):
        self.regions = ['us-east-1', 'us-west-2']
        self.current_region_idx = 0
        self.clients = {
            region: boto3.client('bedrock-runtime', region_name=region)
            for region in self.regions
        }
    
    def get_client(self):
        """ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹"""
        region = self.regions[self.current_region_idx]
        self.current_region_idx = (self.current_region_idx + 1) % len(self.regions)
        return self.clients[region], region
    
    def invoke_with_fallback(self, model_id, body):
        """ì¥ì•  ì‹œ ìë™ í˜ì¼ì˜¤ë²„"""
        for region in self.regions:
            try:
                client = self.clients[region]
                response = client.invoke_model(
                    modelId=model_id,
                    body=body
                )
                print(f"âœ… Success in {region}")
                return response
            except Exception as e:
                print(f"âš ï¸ Failed in {region}: {e}")
                continue
        
        raise Exception("ëª¨ë“  ë¦¬ì „ì—ì„œ ì‹¤íŒ¨")

# ì‚¬ìš©
bedrock_multi = MultiRegionBedrock()
response = bedrock_multi.invoke_with_fallback(
    model_id='anthropic.claude-3-5-sonnet-20240620-v1:0',
    body=json.dumps({...})
)
```

### 5. ìºì‹± ì „ëµ

```python
class RAGCache:
    """
    ì‘ë‹µ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ë° ì§€ì—° ì‹œê°„ ì ˆê°
    - ë™ì¼ ì§ˆë¬¸ì— ëŒ€í•œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
    - ë¹„ìš© ì ˆê°: Bedrock API í˜¸ì¶œ ê°ì†Œ
    """
    def __init__(self, max_size=1000, ttl_seconds=3600):
        self.cache = {}
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
    
    def _hash_query(self, query):
        import hashlib
        return hashlib.md5(query.encode()).hexdigest()
    
    def get(self, query):
        """ìºì‹œ ì¡°íšŒ"""
        key = self._hash_query(query)
        if key in self.cache:
            item = self.cache[key]
            # TTL í™•ì¸
            import time
            if time.time() - item['timestamp'] < self.ttl_seconds:
                print("âœ… Cache Hit")
                return item['response']
            else:
                del self.cache[key]
        return None
    
    def set(self, query, response):
        """ìºì‹œ ì €ì¥"""
        import time
        if len(self.cache) >= self.max_size:
            # LRU: ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = min(self.cache, key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]
        
        key = self._hash_query(query)
        self.cache[key] = {
            'response': response,
            'timestamp': time.time()
        }

# Lambdaì—ì„œ ì „ì—­ ë³€ìˆ˜ë¡œ ì‚¬ìš©
cache = RAGCache()

def lambda_handler(event, context):
    query = event['query']
    
    # ìºì‹œ í™•ì¸
    cached = cache.get(query)
    if cached:
        return cached
    
    # ìºì‹œ ë¯¸ìŠ¤: ì‹¤ì œ RAG ì‹¤í–‰
    answer = perform_rag(query)
    
    # ìºì‹œ ì €ì¥
    cache.set(query, answer)
    
    return answer
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. OpenSearch ì—°ê²° ì˜¤ë¥˜

**ë¬¸ì œ:** `ConnectionError` ë˜ëŠ” `Timeout`

```python
# í•´ê²°ì±… 1: íƒ€ì„ì•„ì›ƒ ì¦ê°€
client = OpenSearch(
    hosts=[...],
    timeout=30,  # 10ì´ˆ â†’ 30ì´ˆ
    max_retries=3,
    retry_on_timeout=True
)

# í•´ê²°ì±… 2: VPC ì„¤ì • í™•ì¸
# OpenSearchê°€ VPC ë‚´ë¶€ì¸ ê²½ìš°, Lambdaë„ ê°™ì€ VPCì— ë°°ì¹˜
```

### 2. Bedrock ThrottlingException

**ë¬¸ì œ:** `ThrottlingException: Rate exceeded`

```python
# í•´ê²°ì±… 1: ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
import time
import random

def invoke_with_retry(bedrock_client, **kwargs):
    max_retries = 5
    for attempt in range(max_retries):
        try:
            return bedrock_client.invoke_model(**kwargs)
        except Exception as e:
            if 'ThrottlingException' in str(e):
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"ì¬ì‹œë„ {attempt + 1}/{max_retries}, {wait_time}ì´ˆ ëŒ€ê¸°")
                time.sleep(wait_time)
            else:
                raise
    raise Exception("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")

# í•´ê²°ì±… 2: ë©€í‹° ë¦¬ì „ ì‚¬ìš© (ìœ„ MultiRegionBedrock ì°¸ì¡°)

# í•´ê²°ì±… 3: Provisioned Throughput êµ¬ë§¤
# ê³ ì • ìš©ëŸ‰ í™•ë³´ë¡œ ThrottlingException ë°©ì§€
```

### 3. ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì •í™•í•¨

**ë¬¸ì œ:** ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œê°€ ê²€ìƒ‰ë¨

```python
# í•´ê²°ì±… 1: Hybrid Search ì‚¬ìš©
# Semantic + Lexical ê²€ìƒ‰ ê²°í•© (ìœ„ ì½”ë“œ ì°¸ì¡°)

# í•´ê²°ì±… 2: ì²­í‚¹ ì „ëµ ê°œì„ 
# - ë„ˆë¬´ í° ì²­í¬: ë…¸ì´ì¦ˆ ì¦ê°€
# - ê¶Œì¥: 1000-1500ì, 200ì ì˜¤ë²„ë©

# í•´ê²°ì±… 3: ì„ë² ë”© ëª¨ë¸ ë³€ê²½
# Titan â†’ Cohere Embed v3 (ë‹¤êµ­ì–´ ê°•í™”)

# í•´ê²°ì±… 4: ë©”íƒ€ë°ì´í„° í•„í„°ë§
# ê²€ìƒ‰ ë²”ìœ„ë¥¼ íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ ì œí•œ
```

### 4. ì‘ë‹µ ì†ë„ê°€ ëŠë¦¼

**ë¬¸ì œ:** TTFT > 5ì´ˆ

```python
# í•´ê²°ì±… 1: Claude Sonnet â†’ Haiku
# 3ë°° ë¹ ë¥¸ ì‘ë‹µ ì†ë„

# í•´ê²°ì±… 2: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
response_stream = bedrock.invoke_model_with_response_stream(
    modelId='anthropic.claude-3-haiku-20240307-v1:0',
    body=json.dumps({...})
)

# ì²« í† í° ì¦‰ì‹œ ë°˜í™˜
for event in response_stream['body']:
    chunk = json.loads(event['chunk']['bytes'])
    if 'delta' in chunk:
        print(chunk['delta']['text'], end='', flush=True)

# í•´ê²°ì±… 3: Top-K ê°’ ì¤„ì´ê¸°
# 10 â†’ 5ë¡œ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ê°ì†Œ
```

### 5. ë©”ëª¨ë¦¬ ë¶€ì¡± (Lambda)

**ë¬¸ì œ:** Lambda ë©”ëª¨ë¦¬ ì´ˆê³¼

```bash
# í•´ê²°ì±…: ë©”ëª¨ë¦¬ ì¦ê°€
aws lambda update-function-configuration \
    --function-name RAG-Query \
    --memory-size 2048  # ê¸°ë³¸ 512MB â†’ 2048MB
```

### 6. í•œêµ­ì–´ ê²€ìƒ‰ ì •í™•ë„ ë‚®ìŒ

**ë¬¸ì œ:** Nori ë¶„ì„ê¸°ê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ

```python
# í•´ê²°ì±…: ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ë° ì¬ì„¤ì •
result = client.indices.analyze(
    index=index_name,
    body={
        "analyzer": "nori_custom_analyzer",
        "text": "í…ŒìŠ¤íŠ¸ ë¬¸ì¥"
    }
)
print(result)

# Nori ì„¤ì • í™•ì¸
settings = client.indices.get_settings(index=index_name)
print(settings)
```

---

## â“ FAQ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸)

### Q1. OpenSearch vs Elasticsearch ì°¨ì´ì ì€?
**A:** OpenSearchëŠ” Elasticsearch 7.10.2ì—ì„œ í¬í¬ëœ ì˜¤í”ˆì†ŒìŠ¤ ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤.
- **ë¼ì´ì„ ìŠ¤**: OpenSearchëŠ” Apache 2.0 (ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤), ElasticsearchëŠ” SSPL/Elastic License
- **AWS í†µí•©**: OpenSearchëŠ” AWS ì„œë¹„ìŠ¤(Bedrock, Lambda, S3)ì™€ ë„¤ì´í‹°ë¸Œ í†µí•©
- **ê¸°ëŠ¥**: ìµœì‹  ë²¡í„° ê²€ìƒ‰, k-NN, Nori ë¶„ì„ê¸° ë“± ë™ì¼í•˜ê²Œ ì§€ì›
- **ë¹„ìš©**: AWS Managed Serviceë¡œ ìš´ì˜ ë¹„ìš© ì ˆê°

### Q2. Bedrock ë¦¬ì „ì´ ì œí•œì ì¸ë° ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?
**A:** í¬ë¡œìŠ¤ ë¦¬ì „ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
```python
# OpenSearch: ap-northeast-2 (ì„œìš¸)
opensearch_client = OpenSearch(
    hosts=[{'host': 'your-domain.ap-northeast-2.es.amazonaws.com', 'port': 443}],
    ...
)

# Bedrock: us-east-1 (ë²„ì§€ë‹ˆì•„)
bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
```
**ì¥ì **: Bedrockì€ ë¦¬ì „ ê°„ í˜¸ì¶œ ë¹„ìš©ì´ ë‚®ê³ , ì§€ì—° ì‹œê°„ë„ í—ˆìš© ë²”ìœ„ ë‚´ì…ë‹ˆë‹¤.

### Q3. í•œêµ­ì–´ ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ë ¤ë©´?
**A:** Nori ë¶„ì„ê¸° + Hybrid Search ì¡°í•©ì´ ìµœì ì…ë‹ˆë‹¤.
1. **Nori ë¶„ì„ê¸°**: í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ (ì˜ˆ: "ë¨¹ì—ˆë‹¤" â†’ "ë¨¹ë‹¤")
2. **Hybrid Search**: ì˜ë¯¸ ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°í•©
3. **ì»¤ìŠ¤í…€ ì‚¬ì „**: ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ì¶”ê°€
```python
# íšŒì‚¬ëª…, ì œí’ˆëª… ë“± ì»¤ìŠ¤í…€ ë‹¨ì–´ ì¶”ê°€
"user_dictionary": ["ì‚¼ì„±ì „ì", "ê°¤ëŸ­ì‹œí´ë“œ"]
```

### Q4. ë²¡í„° ì°¨ì›ì€ ì–´ë–»ê²Œ ì„ íƒí•˜ë‚˜ìš”?
**A:** ì‚¬ìš©í•˜ëŠ” ì„ë² ë”© ëª¨ë¸ì— ë”°ë¼ ê³ ì •ë©ë‹ˆë‹¤.
| ëª¨ë¸ | ì°¨ì› | íŠ¹ì§• |
|------|------|------|
| Titan Embeddings G1 | 1024 | ë‹¤êµ­ì–´ ì§€ì›, í•œêµ­ì–´ ìš°ìˆ˜ |
| Titan Multimodal | 1024 | í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ |
| Cohere Embed v3 | 1024 | ë‹¤êµ­ì–´ ê°•í™”, ë” ì •í™• |

**ê¶Œì¥**: í•œêµ­ì–´ RAGëŠ” Titan Embeddings G1 (1024ì°¨ì›)

### Q5. ëª‡ ê°œì˜ ë¬¸ì„œê¹Œì§€ ì €ì¥í•  ìˆ˜ ìˆë‚˜ìš”?
**A:** ì´ë¡ ìƒ ë¬´ì œí•œì´ì§€ë§Œ, ì‹¤ìš©ì ì¸ ì œí•œì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
- **Serverless**: ìµœëŒ€ 30TB
- **Domain (Cluster)**: ìµœëŒ€ 25PB (1000 ë…¸ë“œ)
- **ê¶Œì¥**: ë‹¨ì¼ ì¸ë±ìŠ¤ë‹¹ 10-20GB (ê²€ìƒ‰ ì†ë„ ìµœì í™”)

### Q6. ê²€ìƒ‰ ì†ë„ê°€ ëŠë¦°ë° ì–´ë–»ê²Œ ê°œì„ í•˜ë‚˜ìš”?
**A:** ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸:
1. **Top-K ì¤„ì´ê¸°**: 10 â†’ 5ê°œë¡œ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ê°ì†Œ
2. **ef_search ì¡°ì •**: 1024 â†’ 512ë¡œ ë‚®ì¶° ì†ë„ í–¥ìƒ
3. **Disk-based Vector Search**: ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
4. **ì¸ìŠ¤í„´ìŠ¤ ì—…ê·¸ë ˆì´ë“œ**: t3 â†’ m6g â†’ r6g (ë©”ëª¨ë¦¬ ì§‘ì•½ì )
5. **ìºì‹±**: ë™ì¼ ì§ˆë¬¸ ë°˜ë³µ ì‹œ ìºì‹œ ì‚¬ìš©

**SKí•˜ì´ë‹‰ìŠ¤ ì‹¤ì¸¡**:
- 1ëª…: 80ms
- 100ëª…: 2.96ì´ˆ â†’ Disk-basedë¡œ ì „í™˜ ê²€í† 

### Q7. Lambda ë©”ëª¨ë¦¬ëŠ” ì–¼ë§ˆë‚˜ í•„ìš”í•œê°€ìš”?
**A:** ì‘ì—… ìœ í˜•ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.
| ì‘ì—… | ê¶Œì¥ ë©”ëª¨ë¦¬ | ì´ìœ  |
|------|------------|------|
| ê°„ë‹¨í•œ ê²€ìƒ‰ | 512MB | ë²¡í„° ê²€ìƒ‰ë§Œ |
| RAG (ì„ë² ë”© + ê²€ìƒ‰ + LLM) | 1024MB | ì „ì²´ íŒŒì´í”„ë¼ì¸ |
| PDF íŒŒì‹± + ì„ë² ë”© | 2048MB | ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ |
| ì´ë¯¸ì§€ ì²˜ë¦¬ | 1536-2048MB | ì´ë¯¸ì§€ ì¸ì½”ë”© + ì„ë² ë”© |

**íŒ**: CloudWatch Logsì—ì„œ ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ í›„ ì¡°ì •

### Q8. Serverless vs Domain, ì–´ë–¤ ê±¸ ì„ íƒí•´ì•¼ í•˜ë‚˜ìš”?
**A:** ì‚¬ìš© ì‚¬ë¡€ì— ë”°ë¼ ì„ íƒí•˜ì„¸ìš”.

**Serverless ì¶”ì²œ:**
- ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½
- íŠ¸ë˜í”½ ë³€ë™ì´ í° ê²½ìš°
- ê´€ë¦¬ ë¶€ë‹´ ìµœì†Œí™”
- < 30TB ë°ì´í„°

**Domain (Cluster) ì¶”ì²œ:**
- í”„ë¡œë•ì…˜ í™˜ê²½
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŠ¸ë˜í”½
- ì„¸ë°€í•œ ì„±ëŠ¥ íŠœë‹ í•„ìš”
- ì»¤ìŠ¤í…€ í”ŒëŸ¬ê·¸ì¸ ì‚¬ìš©
- > 30TB ë°ì´í„°

### Q9. ë¹„ìš©ì„ ì ˆê°í•˜ë ¤ë©´?
**A:** ë¹„ìš© ìµœì í™” ì „ëµ:
1. **OR1 ì¸ìŠ¤í„´ìŠ¤**: ê¸°ì¡´ ëŒ€ë¹„ 30% ì ˆê°
2. **Disk-based Vector Search**: ë©”ëª¨ë¦¬ ë¹„ìš© 32ë°° ì ˆê°
3. **Reserved Instances**: 1ë…„ ì•½ì • 40% í• ì¸
4. **Claude Haiku**: Sonnet ëŒ€ë¹„ 80% ì ˆê°
5. **ìºì‹±**: ì¤‘ë³µ API í˜¸ì¶œ ë°©ì§€
6. **ì²­í‚¹ ìµœì í™”**: í† í° ì‚¬ìš©ëŸ‰ ê°ì†Œ

**ì˜ˆì‹œ**: ì›” 100,000 ì¿¼ë¦¬
- Sonnetë§Œ ì‚¬ìš©: ~$2,000
- Haiku + ìºì‹±: ~$400 (80% ì ˆê°!)

### Q10. ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰(ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)ì´ ê°€ëŠ¥í•œê°€ìš”?
**A:** ê°€ëŠ¥í•©ë‹ˆë‹¤! Titan Multimodal Embeddingsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
```python
# ì´ë¯¸ì§€ ì„ë² ë”©
image_vector = embed_image(image_bytes)

# í…ìŠ¤íŠ¸ ì„ë² ë”©
text_vector = embed_text("ë¹¨ê°„ ìë™ì°¨")

# í†µí•© ê²€ìƒ‰
# ê°™ì€ ë²¡í„° ê³µê°„ì—ì„œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë™ì‹œì— ê²€ìƒ‰
```

---

## ğŸ”— ì°¸ê³  ìë£Œ

### AWS ê³µì‹ ë¬¸ì„œ

- **[Amazon OpenSearch Service](https://aws.amazon.com/opensearch-service/)**: ê³µì‹ ì œí’ˆ í˜ì´ì§€
- **[OpenSearch Documentation](https://opensearch.org/docs/latest/)**: ì˜¤í”ˆì†ŒìŠ¤ OpenSearch ë¬¸ì„œ
- **[Amazon Bedrock](https://aws.amazon.com/bedrock/)**: Bedrock ê³µì‹ í˜ì´ì§€
- **[AWS Lambda](https://aws.amazon.com/lambda/)**: Lambda ê³µì‹ ë¬¸ì„œ

### GitHub ì €ì¥ì†Œ

- **[aws-samples](https://github.com/aws-samples)**: AWS ê³µì‹ ìƒ˜í”Œ ì½”ë“œ
- **[opensearch-py](https://github.com/opensearch-project/opensearch-py)**: OpenSearch Python í´ë¼ì´ì–¸íŠ¸

### ì»¤ë®¤ë‹ˆí‹°

- **[AWS re:Post](https://repost.aws/)**: AWS ì»¤ë®¤ë‹ˆí‹° Q&A
- **[OpenSearch Forum](https://forum.opensearch.org/)**: OpenSearch ì»¤ë®¤ë‹ˆí‹°

