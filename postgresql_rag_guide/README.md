# PostgreSQLê³¼ pgvectorë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ì „ ê°€ì´ë“œ

> í•œêµ­ì–´ ê°œë°œìë¥¼ ìœ„í•œ ì‹¤ì „ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œ êµ¬ì¶• íŠœí† ë¦¬ì–¼

[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)
[![pgvector](https://img.shields.io/badge/pgvector-0.5.1-green.svg)](https://github.com/pgvector/pgvector)
[![Python](https://img.shields.io/badge/Python-3.8+-yellow.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-red.svg)](LICENSE)

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ì†Œê°œ](#-í”„ë¡œì íŠ¸-ì†Œê°œ)
- [ì™œ PostgreSQLì¸ê°€?](#-ì™œ-postgresqlì¸ê°€)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [í™˜ê²½ êµ¬ì¶•](#-í™˜ê²½-êµ¬ì¶•)
- [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
- [ìƒì„¸ ê°€ì´ë“œ](#-ìƒì„¸-ê°€ì´ë“œ)
- [ì„±ëŠ¥ ìµœì í™”](#-ì„±ëŠ¥-ìµœì í™”)
- [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
- [ì‹¤ì „ ì˜ˆì œ](#-ì‹¤ì „-ì˜ˆì œ)
- [FAQ](#-faq)
- [ì°¸ê³  ìë£Œ](#-ì°¸ê³ -ìë£Œ)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì†Œê°œ

ì´ í”„ë¡œì íŠ¸ëŠ” **PostgreSQL + pgvector + Ollama(Llama3)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- âœ… **ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤**: ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ë¬´ë£Œ
- âœ… **ì‹¤ì „ ì¤‘ì‹¬**: ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì œê³µ
- âœ… **í•œêµ­ì–´ ìµœì í™”**: í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ ë° ê²€ìƒ‰
- âœ… **í”„ë¡œë•ì…˜ ì¤€ë¹„**: ì„±ëŠ¥ ìµœì í™” ë° ë°°í¬ ê°€ì´ë“œ
- âœ… **í™•ì¥ ê°€ëŠ¥**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì§€ì›

### í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. PostgreSQLê³¼ pgvector ì„¤ì¹˜ ë° ì„¤ì •
2. ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
3. ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ êµ¬í˜„
4. LLMê³¼ ì—°ë™í•˜ì—¬ RAG ì‹œìŠ¤í…œ êµ¬ì¶•
5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(ë²¡í„° + ì „ë¬¸ê²€ìƒ‰) êµ¬í˜„
6. ì„±ëŠ¥ ìµœì í™” ë° í”„ë¡œë•ì…˜ ë°°í¬

---

## ğŸ¤” ì™œ PostgreSQLì¸ê°€?

### PostgreSQLì˜ ê°•ì 

PostgreSQLì€ **ì „ ì„¸ê³„ì ìœ¼ë¡œ ê°€ì¥ ì„±ê³µí•œ Enterprise Level Open Source RDBMS**ì…ë‹ˆë‹¤.

| ê¸°ëŠ¥ | PostgreSQL | ì „ìš© ë²¡í„° DB |
|------|------------|--------------|
| **ë²¡í„° ê²€ìƒ‰** | âœ… pgvector í™•ì¥ | âœ… ë„¤ì´í‹°ë¸Œ ì§€ì› |
| **SQL ì§€ì›** | âœ… ANSI SQL 90%+ | âŒ ì œí•œì  |
| **íŠ¸ëœì­ì…˜** | âœ… ACID ë³´ì¥ | âš ï¸ ì œí•œì  |
| **í™•ì¥ì„±** | âœ… ë‹¤ì–‘í•œ í™•ì¥ | âŒ ì œí•œì  |
| **ë¹„ìš©** | âœ… ì™„ì „ ë¬´ë£Œ | ğŸ’° ìœ ë£Œ ë˜ëŠ” ì œí•œ |
| **ìƒíƒœê³„** | âœ… ì„±ìˆ™í•œ ë„êµ¬ | âš ï¸ ë°œì „ ì¤‘ |

### RAGì— ìµœì ì¸ ì´ìœ 

1. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ë²¡í„° ê²€ìƒ‰ + ì „ë¬¸ ê²€ìƒ‰(Full-text Search) ê²°í•©
2. **ë°ì´í„° ë¬´ê²°ì„±**: ACID íŠ¹ì„±ìœ¼ë¡œ ì•ˆì •ì  ë°ì´í„° ê´€ë¦¬
3. **í™•ì¥ì„±**: ìˆ˜ë°±ë§Œ ê°œ ë¬¸ì„œ ì²˜ë¦¬ ê°€ëŠ¥
4. **ìš´ì˜ í¸ì˜ì„±**: ê¸°ì¡´ PostgreSQL ìš´ì˜ ê²½í—˜ í™œìš©
5. **ë¹„ìš© íš¨ìœ¨ì„±**: ë³„ë„ ë²¡í„° DB ë¶ˆí•„ìš”

---

## ğŸ— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### RAG ì›Œí¬í”Œë¡œìš°

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
ì„ë² ë”© ìƒì„± (Ollama Llama3, 4096ì°¨ì›)
    â†“
PostgreSQL + pgvector ë²¡í„° ê²€ìƒ‰
    â†“
Top-K ë¬¸ì„œ ê²€ìƒ‰ (ê¸°ë³¸ 3ê°œ)
    â†“
ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í”„ë¡¬í”„íŠ¸ ìƒì„±)
    â†“
LLM ì‘ë‹µ ìƒì„± (Ollama Llama3)
    â†“
ìµœì¢… ë‹µë³€
```

### ì‹œìŠ¤í…œ êµ¬ì„±ë„

```
Application Layer
    FastAPI (REST) | Streamlit (Web UI) | CLI Interface | Custom App
                            â†“
RAG Engine Layer
    RAG Orchestrator
        - Query Understanding & Processing
        - Context Assembly & Management
        - Response Generation & Streaming
        - Chat History Management
            â†“                           â†“
    Document Retriever          LLM Generator
        - Vector Search             - Prompt Engineering
        - Hybrid Search             - Streaming Response
        - Metadata Filter           - Context Injection
        - Re-ranking                - Token Management
                            â†“
Data Layer (PostgreSQL)
    documents â†’ document_chunks â†’ metadata (JSONB)
        - id, title, content       - category, tags[], author
        - source, embedding        - version, language
        - created_at               - custom_fields
                â†“
    pgvector Extension
        - Vector Operations (<->, <#>, <=>)
        - IVFFlat Index (Fast Approximate Search)
        - HNSW Index (High Accuracy Search)
        - Distance Metrics (Cosine, L2, Inner Product)
                â†“
External Services
    Ollama Server              Document Store
        - Llama3                   - File System
        - Embeddings               - S3/MinIO
        - Generation               - Google Drive
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

1. **EmbeddingManager**: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
2. **DocumentRetriever**: ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰
3. **RAGEngine**: ê²€ìƒ‰ + ìƒì„± í†µí•©
4. **DocumentLoader**: ë‹¤ì–‘í•œ í˜•ì‹ ë¬¸ì„œ ë¡œë“œ

---

## ğŸš€ í™˜ê²½ êµ¬ì¶•

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **OS**: Ubuntu 20.04+, macOS 11+, Windows 10+ (WSL2)
- **Python**: 3.8 ì´ìƒ
- **PostgreSQL**: 12 ì´ìƒ (15 ê¶Œì¥)
- **RAM**: ìµœì†Œ 8GB (16GB ê¶Œì¥)
- **ë””ìŠ¤í¬**: ìµœì†Œ 10GB ì—¬ìœ  ê³µê°„

### 1. PostgreSQL ì„¤ì¹˜

#### Ubuntu/Debian

```bash
# PostgreSQL ê³µì‹ ì €ì¥ì†Œ ì¶”ê°€
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'

# GPG í‚¤ ì¶”ê°€
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -

# ì„¤ì¹˜
sudo apt-get update
sudo apt-get install -y postgresql-15 postgresql-contrib-15

# ì„œë¹„ìŠ¤ ì‹œì‘
sudo systemctl start postgresql
sudo systemctl enable postgresql
```

#### macOS

```bash
# Homebrew ì‚¬ìš©
brew install postgresql@15

# ì„œë¹„ìŠ¤ ì‹œì‘
brew services start postgresql@15
```

#### Windows

1. https://www.postgresql.org/download/windows/ ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ
2. ì„¤ì¹˜ ë§ˆë²•ì‚¬ ì‹¤í–‰
3. í¬íŠ¸: 5432 (ê¸°ë³¸ê°’)
4. ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ê¸°ì–µí•  ê²ƒ!)

#### Docker (ëª¨ë“  OS)

```bash
docker run -d \
  --name postgres-rag \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=rag_db \
  -p 5432:5432 \
  -v postgres_data:/var/lib/postgresql/data \
  postgres:15
```

### 2. pgvector ì„¤ì¹˜

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜ (Ubuntu/Debian)
sudo apt-get install -y postgresql-server-dev-15 build-essential git

# pgvector ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
cd /tmp
git clone --branch v0.5.1 https://github.com/pgvector/pgvector.git
cd pgvector
make
sudo make install

# ì„¤ì¹˜ í™•ì¸
sudo -u postgres psql -c "SELECT * FROM pg_available_extensions WHERE name = 'vector';"
```

**macOS:**
```bash
brew install pgvector
```

**Docker:** pgvectorê°€ í¬í•¨ëœ ì´ë¯¸ì§€ ì‚¬ìš©
```bash
docker run -d \
  --name postgres-rag \
  -e POSTGRES_PASSWORD=your_password \
  -p 5432:5432 \
  ankane/pgvector
```

### 3. Ollama ì„¤ì¹˜

#### Linux

```bash
curl -fsSL https://ollama.com/install.sh | sh

# Llama3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3
```

#### macOS

```bash
# Homebrew ì‚¬ìš©
brew install ollama

# ë˜ëŠ” ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë¡œë“œ
# https://ollama.com/download
```

#### Windows

1. https://ollama.com/download ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ
2. ì„¤ì¹˜ í›„ ëª…ë ¹ í”„ë¡¬í”„íŠ¸ì—ì„œ:
```cmd
ollama pull llama3
```

### 4. Python í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python -m venv rag-env

# í™œì„±í™”
source rag-env/bin/activate  # Linux/macOS
# rag-env\Scripts\activate   # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install --upgrade pip
pip install psycopg2-binary pgvector requests numpy python-dotenv
```

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1. í”„ë¡œì íŠ¸ í´ë¡ 

```bash
cd C:\git_clone
git clone <repository-url> postgresql_rag_guide
cd postgresql_rag_guide
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”

```bash
# PostgreSQL ì ‘ì†
psql -U postgres

# ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
CREATE DATABASE rag_db ENCODING 'UTF8';
\c rag_db

# pgvector í™•ì¥ ì„¤ì¹˜
CREATE EXTENSION vector;

# ìŠ¤í‚¤ë§ˆ ìƒì„±
\i schema.sql

# ì¢…ë£Œ
\q
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:

```env
# PostgreSQL ì„¤ì •
DB_HOST=localhost
DB_PORT=5432
DB_NAME=rag_db
DB_USER=postgres
DB_PASSWORD=your_password

# Ollama ì„¤ì •
OLLAMA_URL=http://localhost:11434
EMBEDDING_MODEL=llama3
GENERATION_MODEL=llama3

# RAG ì„¤ì •
EMBEDDING_DIMENSION=4096
TOP_K_RESULTS=3
MAX_CONTEXT_LENGTH=4000
```

### 4. ìƒ˜í”Œ ì‹¤í–‰

```python
from embedding_manager import EmbeddingManager
from rag_engine import RAGEngine

# ë¬¸ì„œ ì¶”ê°€
emb_mgr = EmbeddingManager()
doc_id = emb_mgr.insert_document(
    title="PostgreSQL ì†Œê°œ",
    content="PostgreSQLì€ ê°•ë ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
    source="sample.txt"
)
print(f"âœ“ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ (ID: {doc_id})")

# RAG ì§ˆì˜
rag = RAGEngine()
result = rag.generate_response("PostgreSQLì˜ íŠ¹ì§•ì€?")
print(f"\nì§ˆë¬¸: {result['query']}")
print(f"ë‹µë³€: {result['answer']}")

# ì •ë¦¬
emb_mgr.close()
rag.close()
```

---

## ğŸ“š ìƒì„¸ ê°€ì´ë“œ

### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
#### ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ

```sql
-- ë¬¸ì„œ í…Œì´ë¸”
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500),
    content TEXT NOT NULL,
    source VARCHAR(255),
    metadata JSONB,
    embedding vector(4096),  -- Llama3 ì„ë² ë”© ì°¨ì›
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_documents_updated_at 
    BEFORE UPDATE ON documents
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_documents_source ON documents(source);
CREATE INDEX idx_documents_created_at ON documents(created_at);
CREATE INDEX idx_documents_metadata ON documents USING GIN(metadata);

-- ë²¡í„° ì¸ë±ìŠ¤ (IVFFlat - ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰)
CREATE INDEX documents_embedding_idx ON documents 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤
CREATE INDEX idx_documents_content_fts ON documents 
USING GIN(to_tsvector('english', content));
```

#### ë¬¸ì„œ ë¶„í•  ìŠ¤í‚¤ë§ˆ (ê¸´ ë¬¸ì„œìš©)

```sql
-- ì²­í¬ í…Œì´ë¸”
CREATE TABLE document_chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    embedding vector(4096),
    token_count INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(document_id, chunk_index)
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_chunks_document_id ON document_chunks(document_id);
CREATE INDEX chunks_embedding_idx ON document_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### Python êµ¬í˜„

#### 1. ì„¤ì • íŒŒì¼ (config.py)

```python
import os
from dotenv import load_dotenv

load_dotenv()

# PostgreSQL ì„¤ì •
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'rag_db'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD')
}

# Ollama ì„¤ì •
OLLAMA_BASE_URL = os.getenv('OLLAMA_URL', 'http://localhost:11434')
EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL', 'llama3')
GENERATION_MODEL = os.getenv('GENERATION_MODEL', 'llama3')

# RAG ì„¤ì •
EMBEDDING_DIMENSION = int(os.getenv('EMBEDDING_DIMENSION', '4096'))
TOP_K_RESULTS = int(os.getenv('TOP_K_RESULTS', '3'))
MAX_CONTEXT_LENGTH = int(os.getenv('MAX_CONTEXT_LENGTH', '4000'))
```

#### 2. ì„ë² ë”© ë§¤ë‹ˆì € (embedding_manager.py)

```python
import requests
import psycopg2
from pgvector.psycopg2 import register_vector
from typing import List, Dict, Optional
import config

class EmbeddingManager:
    """ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë° ì €ì¥"""
    
    def __init__(self):
        self.conn = psycopg2.connect(**config.DB_CONFIG)
        register_vector(self.conn)
        self.cursor = self.conn.cursor()
    
    def generate_embedding(self, text: str) -> List[float]:
        """Ollamaë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            response = requests.post(
                f"{config.OLLAMA_BASE_URL}/api/embeddings",
                json={
                    "model": config.EMBEDDING_MODEL,
                    "prompt": text
                },
                timeout=30
            )
            response.raise_for_status()
            return response.json()['embedding']
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def insert_document(
        self, 
        title: str, 
        content: str, 
        source: str,
        metadata: Optional[Dict] = None
    ) -> int:
        """ë¬¸ì„œì™€ ì„ë² ë”©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            # ì„ë² ë”© ìƒì„±
            embedding = self.generate_embedding(content)
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            query = """
                INSERT INTO documents (title, content, source, metadata, embedding)
                VALUES (%s, %s, %s, %s, %s)
                RETURNING id
            """
            
            self.cursor.execute(
                query,
                (title, content, source, 
                 psycopg2.extras.Json(metadata or {}),
                 embedding)
            )
            
            doc_id = self.cursor.fetchone()[0]
            self.conn.commit()
            return doc_id
            
        except Exception as e:
            self.conn.rollback()
            print(f"âŒ ë¬¸ì„œ ì‚½ì… ì‹¤íŒ¨: {e}")
            raise
    
    def bulk_insert_documents(self, documents: List[Dict]) -> List[int]:
        """ì—¬ëŸ¬ ë¬¸ì„œ ì¼ê´„ ì‚½ì…"""
        doc_ids = []
        
        for i, doc in enumerate(documents, 1):
            try:
                doc_id = self.insert_document(
                    title=doc['title'],
                    content=doc['content'],
                    source=doc['source'],
                    metadata=doc.get('metadata')
                )
                doc_ids.append(doc_id)
                print(f"âœ“ [{i}/{len(documents)}] {doc['title']} (ID: {doc_id})")
            except Exception as e:
                print(f"âœ— [{i}/{len(documents)}] {doc['title']} ì‹¤íŒ¨: {e}")
        
        return doc_ids
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        self.cursor.close()
        self.conn.close()
```

#### 3. ë¬¸ì„œ ê²€ìƒ‰ê¸° (retriever.py)

```python
import psycopg2
from pgvector.psycopg2 import register_vector
from typing import List, Dict
import config

class DocumentRetriever:
    """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰"""
    
    def __init__(self):
        self.conn = psycopg2.connect(**config.DB_CONFIG)
        register_vector(self.conn)
        self.cursor = self.conn.cursor()
    
    def search_similar_documents(
        self,
        query_embedding: List[float],
        top_k: int = config.TOP_K_RESULTS,
        metadata_filter: Dict = None,
        distance_metric: str = 'cosine'
    ) -> List[Dict]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
        
        # ê±°ë¦¬ ì¸¡ì • ì—°ì‚°ì
        operators = {
            'cosine': '<->',      # ì½”ì‚¬ì¸ ê±°ë¦¬
            'l2': '<->',          # L2 ê±°ë¦¬
            'inner_product': '<#>' # ë‚´ì 
        }
        operator = operators.get(distance_metric, '<->')
        
        # ì¿¼ë¦¬ êµ¬ì„±
        query = f"""
            SELECT 
                id,
                title,
                content,
                source,
                metadata,
                embedding {operator} %s AS distance
            FROM documents
        """
        
        params = [query_embedding]
        
        # ë©”íƒ€ë°ì´í„° í•„í„°
        if metadata_filter:
            conditions = []
            for key, value in metadata_filter.items():
                conditions.append(f"metadata->>%s = %s")
                params.extend([key, value])
            query += " WHERE " + " AND ".join(conditions)
        
        query += f" ORDER BY distance LIMIT %s"
        params.append(top_k)
        
        self.cursor.execute(query, params)
        
        results = []
        for row in self.cursor.fetchall():
            results.append({
                'id': row[0],
                'title': row[1],
                'content': row[2],
                'source': row[3],
                'metadata': row[4],
                'distance': float(row[5]),
                'similarity': 1 - float(row[5])  # ìœ ì‚¬ë„ (0~1)
            })
        
        return results
    
    def hybrid_search(
        self,
        query_text: str,
        query_embedding: List[float],
        top_k: int = config.TOP_K_RESULTS,
        vector_weight: float = 0.7,
        text_weight: float = 0.3
    ) -> List[Dict]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + ì „ë¬¸ ê²€ìƒ‰)"""
        
        query = """
            WITH vector_search AS (
                SELECT 
                    id,
                    title,
                    content,
                    source,
                    metadata,
                    embedding <-> %s AS vector_distance
                FROM documents
                ORDER BY vector_distance
                LIMIT 20
            ),
            text_search AS (
                SELECT 
                    id,
                    ts_rank(to_tsvector('english', content), 
                            plainto_tsquery('english', %s)) AS text_score
                FROM documents
                WHERE to_tsvector('english', content) @@ 
                      plainto_tsquery('english', %s)
            )
            SELECT 
                v.id,
                v.title,
                v.content,
                v.source,
                v.metadata,
                v.vector_distance,
                ((%s * (1 - v.vector_distance)) + 
                 (%s * COALESCE(t.text_score, 0))) AS combined_score
            FROM vector_search v
            LEFT JOIN text_search t ON v.id = t.id
            ORDER BY combined_score DESC
            LIMIT %s
        """
        
        self.cursor.execute(
            query,
            (query_embedding, query_text, query_text, 
             vector_weight, text_weight, top_k)
        )
        
        results = []
        for row in self.cursor.fetchall():
            results.append({
                'id': row[0],
                'title': row[1],
                'content': row[2],
                'source': row[3],
                'metadata': row[4],
                'distance': float(row[5]),
                'score': float(row[6])
            })
        
        return results
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        self.cursor.close()
        self.conn.close()
```

#### 4. RAG ì—”ì§„ (rag_engine.py)

```python
import requests
from typing import List, Dict
from embedding_manager import EmbeddingManager
from retriever import DocumentRetriever
import config

class RAGEngine:
    """RAG íŒŒì´í”„ë¼ì¸ í†µí•©"""
    
    def __init__(self):
        self.embedding_mgr = EmbeddingManager()
        self.retriever = DocumentRetriever()
    
    def generate_response(
        self,
        query: str,
        top_k: int = config.TOP_K_RESULTS,
        use_hybrid: bool = False,
        metadata_filter: Dict = None,
        stream: bool = False
    ) -> Dict:
        """RAG ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        print(f"ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘: {query}")
        
        # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self.embedding_mgr.generate_embedding(query)
        print("âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        
        # 2. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        if use_hybrid:
            documents = self.retriever.hybrid_search(
                query_text=query,
                query_embedding=query_embedding,
                top_k=top_k
            )
            print(f"âœ“ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ ({len(documents)}ê°œ ë¬¸ì„œ)")
        else:
            documents = self.retriever.search_similar_documents(
                query_embedding=query_embedding,
                top_k=top_k,
                metadata_filter=metadata_filter
            )
            print(f"âœ“ ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ ({len(documents)}ê°œ ë¬¸ì„œ)")
        
        # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_context(documents)
        
        # 4. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(query, context)
        
        # 5. LLM ì‘ë‹µ ìƒì„±
        print("ğŸ’¬ ì‘ë‹µ ìƒì„± ì¤‘...")
        llm_response = self._generate_llm_response(prompt, stream=stream)
        print("âœ“ ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        
        return {
            'query': query,
            'answer': llm_response,
            'sources': documents,
            'context': context
        }
    
    def _build_context(self, documents: List[Dict]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not documents:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        for i, doc in enumerate(documents, 1):
            similarity = doc.get('similarity', 1 - doc.get('distance', 0))
            context_parts.append(
                f"[ë¬¸ì„œ {i}] {doc['title']} (ìœ ì‚¬ë„: {similarity:.2%})\n"
                f"ì¶œì²˜: {doc['source']}\n"
                f"{doc['content'][:500]}{'...' if len(doc['content']) > 500 else ''}\n"
            )
        
        return "\n" + "="*80 + "\n".join(context_parts)
    
    def _build_prompt(self, query: str, context: str) -> str:
        """RAG í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""ì•„ë˜ ì°¸ê³  ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€ ì§€ì¹¨:
1. ì°¸ê³  ë¬¸ì„œì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. ê°€ëŠ¥í•˜ë©´ ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ ì–¸ê¸‰í•˜ì„¸ìš”
4. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€:"""
    
    def _generate_llm_response(self, prompt: str, stream: bool = False) -> str:
        """Llama3ë¡œ ì‘ë‹µ ìƒì„±"""
        try:
            response = requests.post(
                f"{config.OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": config.GENERATION_MODEL,
                    "prompt": prompt,
                    "stream": stream
                },
                timeout=60
            )
            response.raise_for_status()
            
            if stream:
                # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (í–¥í›„ êµ¬í˜„)
                pass
            else:
                return response.json()['response']
                
        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def conversational_query(
        self,
        query: str,
        chat_history: List[Dict],
        top_k: int = config.TOP_K_RESULTS
    ) -> Dict:
        """ëŒ€í™”í˜• ì¿¼ë¦¬ ì²˜ë¦¬"""
        
        # ëŒ€í™” ê¸°ë¡ í¬í•¨
        history_text = "\n".join([
            f"ì‚¬ìš©ì: {h['query']}\nì¡°ìˆ˜: {h['answer']}"
            for h in chat_history[-5:]  # ìµœê·¼ 5ê°œë§Œ
        ])
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedding_mgr.generate_embedding(query)
        
        # ë¬¸ì„œ ê²€ìƒ‰
        documents = self.retriever.search_similar_documents(
            query_embedding=query_embedding,
            top_k=top_k
        )
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_context(documents)
        
        # ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸
        prompt = f"""ì´ì „ ëŒ€í™”:
{history_text}

ì°¸ê³  ë¬¸ì„œ:
{context}

í˜„ì¬ ì§ˆë¬¸: {query}

ìœ„ ëŒ€í™” ê¸°ë¡ê³¼ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€:"""
        
        llm_response = self._generate_llm_response(prompt)
        
        return {
            'query': query,
            'answer': llm_response,
            'sources': documents
        }
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        self.embedding_mgr.close()
        self.retriever.close()
```

#### 5. ë¬¸ì„œ ë¡œë” (document_loader.py)

```python
import os
import json
from typing import List, Dict
from pathlib import Path

class DocumentLoader:
    """ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œ ë¡œë“œ"""
    
    @staticmethod
    def load_text_file(filepath: str) -> Dict:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ"""
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return {
            'title': Path(filepath).stem,
            'content': content,
            'source': filepath,
            'metadata': {
                'file_type': 'txt',
                'file_size': os.path.getsize(filepath),
                'file_name': os.path.basename(filepath)
            }
        }
    
    @staticmethod
    def load_markdown_file(filepath: str) -> Dict:
        """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë“œ"""
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ì²« ì¤„ì—ì„œ ì œëª© ì¶”ì¶œ
        lines = content.split('\n')
        title = lines[0].replace('#', '').strip() if lines else Path(filepath).stem
        
        return {
            'title': title,
            'content': content,
            'source': filepath,
            'metadata': {
                'file_type': 'markdown',
                'file_size': os.path.getsize(filepath),
                'file_name': os.path.basename(filepath)
            }
        }
    
    @staticmethod
    def load_json_file(filepath: str) -> List[Dict]:
        """JSON íŒŒì¼ ë¡œë“œ"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            return data
        else:
            return [data]
    
    @staticmethod
    def load_directory(
        directory: str,
        file_extensions: List[str] = ['.txt', '.md', '.json'],
        recursive: bool = True
    ) -> List[Dict]:
        """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ë¬¸ì„œ ë¡œë“œ"""
        documents = []
        
        if recursive:
            iterator = os.walk(directory)
        else:
            iterator = [(directory, [], os.listdir(directory))]
        
        for root, _, files in iterator:
            for file in files:
                if any(file.endswith(ext) for ext in file_extensions):
                    filepath = os.path.join(root, file)
                    
                    try:
                        if file.endswith('.txt'):
                            doc = DocumentLoader.load_text_file(filepath)
                            documents.append(doc)
                        elif file.endswith('.md'):
                            doc = DocumentLoader.load_markdown_file(filepath)
                            documents.append(doc)
                        elif file.endswith('.json'):
                            docs = DocumentLoader.load_json_file(filepath)
                            documents.extend(docs)
                        
                        print(f"âœ“ {file} ë¡œë“œ ì™„ë£Œ")
                    
                    except Exception as e:
                        print(f"âœ— {file} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return documents
    
    @staticmethod
    def chunk_text(
        text: str, 
        chunk_size: int = 1000, 
        overlap: int = 200
    ) -> List[str]:
        """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            chunks.append(text[start:end])
            start = end - overlap
        
        return chunks
```

#### 6. CLI ì• í”Œë¦¬ì¼€ì´ì…˜ (app.py)

```python
from embedding_manager import EmbeddingManager
from rag_engine import RAGEngine
from document_loader import DocumentLoader
import sys

def print_header():
    """í—¤ë” ì¶œë ¥"""
    print("=" * 80)
    print("PostgreSQL RAG ì‹œìŠ¤í…œ".center(80))
    print("=" * 80)
    print()

def print_menu():
    """ë©”ë‰´ ì¶œë ¥"""
    print("\n" + "-" * 80)
    print("1. ë¬¸ì„œ ì¶”ê°€ (ë‹¨ì¼ íŒŒì¼)")
    print("2. ë¬¸ì„œ ì¶”ê°€ (ë””ë ‰í† ë¦¬)")
    print("3. ì§ˆë¬¸í•˜ê¸° (ë‹¨ì¼)")
    print("4. ì§ˆë¬¸í•˜ê¸° (ëŒ€í™”í˜•)")
    print("5. ì¢…ë£Œ")
    print("-" * 80)

def add_single_file(rag):
    """ë‹¨ì¼ íŒŒì¼ ì¶”ê°€"""
    print("\n=== ë¬¸ì„œ ì¶”ê°€ (ë‹¨ì¼ íŒŒì¼) ===")
    filepath = input("íŒŒì¼ ê²½ë¡œ: ").strip()
    
    if not filepath:
        print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        return
    
    try:
        if filepath.endswith('.txt'):
            doc = DocumentLoader.load_text_file(filepath)
        elif filepath.endswith('.md'):
            doc = DocumentLoader.load_markdown_file(filepath)
        else:
            print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ (.txt, .mdë§Œ ì§€ì›)")
            return
        
        doc_id = rag.embedding_mgr.insert_document(
            title=doc['title'],
            content=doc['content'],
            source=doc['source'],
            metadata=doc['metadata']
        )
        print(f"âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ (ID: {doc_id})")
        
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")

def add_directory(rag):
    """ë””ë ‰í† ë¦¬ ë¬¸ì„œ ì¶”ê°€"""
    print("\n=== ë¬¸ì„œ ì¶”ê°€ (ë””ë ‰í† ë¦¬) ===")
    directory = input("ë””ë ‰í† ë¦¬ ê²½ë¡œ: ").strip()
    
    if not directory:
        print("âŒ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        return
    
    try:
        documents = DocumentLoader.load_directory(directory)
        
        if not documents:
            print("âŒ ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print(f"\nğŸ“š ì´ {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
        confirm = input("ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        
        if confirm == 'y':
            doc_ids = rag.embedding_mgr.bulk_insert_documents(documents)
            print(f"\nâœ… {len(doc_ids)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
        else:
            print("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
    
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")

def ask_question(rag):
    """ë‹¨ì¼ ì§ˆë¬¸"""
    print("\n=== ì§ˆë¬¸í•˜ê¸° ===")
    query = input("ì§ˆë¬¸: ").strip()
    
    if not query:
        return
    
    use_hybrid = input("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©? (y/n, ê¸°ë³¸:n): ").strip().lower() == 'y'
    
    print("\n" + "=" * 80)
    result = rag.generate_response(query, use_hybrid=use_hybrid)
    print("=" * 80)
    
    print(f"\nğŸ“ ë‹µë³€:\n{result['answer']}\n")
    print(f"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(result['sources'])}ê°œ):")
    for i, source in enumerate(result['sources'], 1):
        sim = source.get('similarity', 1 - source.get('distance', 0))
        print(f"  {i}. {source['title']} (ìœ ì‚¬ë„: {sim:.2%})")
        print(f"     ì¶œì²˜: {source['source']}")

def conversational_mode(rag):
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("\n=== ëŒ€í™”í˜• ëª¨ë“œ ===")
    print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', 'ì¢…ë£Œ' ì…ë ¥")
    
    chat_history = []
    
    while True:
        print("\n" + "-" * 80)
        query = input("ì§ˆë¬¸: ").strip()
        
        if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤")
            break
        
        if not query:
            continue
        
        result = rag.conversational_query(query, chat_history)
        
        print(f"\nğŸ’¬ ë‹µë³€:\n{result['answer']}\n")
        
        # ê¸°ë¡ ì €ì¥
        chat_history.append({
            'query': query,
            'answer': result['answer']
        })
        
        # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
        if len(chat_history) > 10:
            chat_history = chat_history[-10:]

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print_header()
    
    try:
        # RAG ì—”ì§„ ì´ˆê¸°í™”
        print("ğŸ”§ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        rag = RAGEngine()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ\n")
        
        while True:
            print_menu()
            choice = input("\nì„ íƒ (1-5): ").strip()
            
            if choice == '1':
                add_single_file(rag)
            elif choice == '2':
                add_directory(rag)
            elif choice == '3':
                ask_question(rag)
            elif choice == '4':
                conversational_mode(rag)
            elif choice == '5':
                print("\nğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤")
                rag.close()
                break
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤ (1-5 ì…ë ¥)")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## ğŸ¯ ì„±ëŠ¥ ìµœì í™”

### ì¸ë±ìŠ¤ ì „ëµ

#### IVFFlat ì¸ë±ìŠ¤ (ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰)

```sql
-- ê¸°ë³¸ IVFFlat ì¸ë±ìŠ¤
CREATE INDEX documents_embedding_idx ON documents 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- lists íŒŒë¼ë¯¸í„° ì„ íƒ ê°€ì´ë“œ:
-- ì‘ì€ ë°ì´í„°ì…‹ (< 100K): lists = 100
-- ì¤‘ê°„ ë°ì´í„°ì…‹ (100K-1M): lists = sqrt(í–‰ìˆ˜)
-- í° ë°ì´í„°ì…‹ (> 1M): lists = sqrt(í–‰ìˆ˜) * 2

-- ì˜ˆ: 1M í–‰ì¸ ê²½ìš°
-- lists = sqrt(1000000) * 2 = 1000 * 2 = 2000
```

#### HNSW ì¸ë±ìŠ¤ (ë†’ì€ ì •í™•ë„)
```sql
-- PostgreSQL 14+ í•„ìš”
CREATE INDEX documents_embedding_hnsw_idx ON documents 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- íŒŒë¼ë¯¸í„°:
-- m: ì—°ê²° ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì •í™•, ë©”ëª¨ë¦¬ ì¦ê°€, ê¸°ë³¸ 16)
-- ef_construction: êµ¬ì¶• ì‹œ íƒìƒ‰ ê¹Šì´ (ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
```

### ì—°ê²° í’€ë§

```python
from psycopg2 import pool
from contextlib import contextmanager
import config

class DatabasePool:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€"""
    
    def __init__(self, minconn=1, maxconn=10):
        self.pool = pool.ThreadedConnectionPool(
            minconn,
            maxconn,
            **config.DB_CONFIG
        )
    
    @contextmanager
    def get_connection(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ì•ˆì „í•œ ì—°ê²° ê´€ë¦¬"""
        conn = self.pool.getconn()
        try:
            yield conn
            conn.commit()
        except Exception:
            conn.rollback()
            raise
        finally:
            self.pool.putconn(conn)
    
    def close_all(self):
        """ëª¨ë“  ì—°ê²° ì¢…ë£Œ"""
        self.pool.closeall()

# ì‚¬ìš© ì˜ˆì‹œ
db_pool = DatabasePool(minconn=2, maxconn=10)

with db_pool.get_connection() as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM documents LIMIT 10")
    results = cursor.fetchall()
```

### ìºì‹±

```python
import hashlib
from functools import lru_cache
from typing import List

class CachedEmbeddingManager(EmbeddingManager):
    """ì„ë² ë”© ìºì‹±ì„ ì§€ì›í•˜ëŠ” ë§¤ë‹ˆì €"""
    
    def __init__(self, cache_size=1000):
        super().__init__()
        self._cache = {}
        self._max_cache_size = cache_size
    
    def generate_embedding(self, text: str) -> List[float]:
        # MD5 í•´ì‹œë¡œ ìºì‹œ í‚¤ ìƒì„±
        cache_key = hashlib.md5(text.encode()).hexdigest()
        
        # ìºì‹œ í™•ì¸
        if cache_key in self._cache:
            print("âœ“ ìºì‹œì—ì„œ ì„ë² ë”© ë¡œë“œ")
            return self._cache[cache_key]
        
        # ìºì‹œ ë¯¸ìŠ¤ - ìƒˆë¡œ ìƒì„±
        embedding = super().generate_embedding(text)
        
        # ìºì‹œ ì €ì¥ (í¬ê¸° ì œí•œ)
        if len(self._cache) >= self._max_cache_size:
            # FIFO: ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            self._cache.pop(next(iter(self._cache)))
        
        self._cache[cache_key] = embedding
        return embedding
```

### ì¿¼ë¦¬ ìµœì í™”

```sql
-- 1. EXPLAIN ANALYZEë¡œ ì¿¼ë¦¬ ë¶„ì„
EXPLAIN ANALYZE
SELECT id, title, content, 
       embedding <-> '[0.1, 0.2, ...]'::vector AS distance
FROM documents
ORDER BY distance
LIMIT 10;

-- 2. VACUUMìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
VACUUM ANALYZE documents;

-- 3. í†µê³„ ì •ë³´ ê°±ì‹ 
ANALYZE documents;

-- 4. ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
REINDEX INDEX documents_embedding_idx;

-- 5. í…Œì´ë¸” í†µê³„ í™•ì¸
SELECT 
    schemaname,
    tablename,
    n_live_tup,
    n_dead_tup,
    last_vacuum,
    last_autovacuum
FROM pg_stat_user_tables
WHERE tablename = 'documents';
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. pgvector ì„¤ì¹˜ ì‹¤íŒ¨

**ë¬¸ì œ:**
```
ERROR: extension "vector" does not exist
```

**í•´ê²° ë°©ë²•:**

```bash
# 1. ê°œë°œ ë„êµ¬ í™•ì¸
sudo apt-get install postgresql-server-dev-15 build-essential git

# 2. pgvector ì¬ì„¤ì¹˜
cd /tmp
rm -rf pgvector
git clone --branch v0.5.1 https://github.com/pgvector/pgvector.git
cd pgvector
make clean
make
sudo make install

# 3. PostgreSQL ì¬ì‹œì‘
sudo systemctl restart postgresql

# 4. í™•ì¥ ìƒì„±
psql -U postgres -d rag_db
CREATE EXTENSION IF NOT EXISTS vector;

# 5. í™•ì¸
SELECT * FROM pg_extension WHERE extname = 'vector';
```

### 2. ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜

**ë¬¸ì œ:**
```
ERROR: dimension of vector must match declared dimension
```

**í•´ê²° ë°©ë²•:**

```python
# 1. ì‹¤ì œ ì„ë² ë”© ì°¨ì› í™•ì¸
from embedding_manager import EmbeddingManager

emb_mgr = EmbeddingManager()
test_embedding = emb_mgr.generate_embedding("test")
print(f"ì‹¤ì œ ì°¨ì›: {len(test_embedding)}")

# 2. í…Œì´ë¸” ì¬ìƒì„± (ë°ì´í„° ë°±ì—… í•„ìˆ˜!)
# DROP TABLE documents;
# CREATE TABLE documents (..., embedding vector(ì‹¤ì œ_ì°¨ì›));
```

### 3. Ollama ì—°ê²° ì‹¤íŒ¨

**ë¬¸ì œ:**
```
requests.exceptions.ConnectionError: Connection refused
```

**í•´ê²° ë°©ë²•:**

```bash
# 1. Ollama ì„œë¹„ìŠ¤ í™•ì¸
systemctl status ollama  # Linux
ps aux | grep ollama     # macOS/Linux

# 2. Ollama ì‹œì‘
ollama serve  # ìˆ˜ë™ ì‹œì‘

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸
ollama list
ollama pull llama3

# 4. í¬íŠ¸ í™•ì¸
curl http://localhost:11434/api/tags

# 5. ë°©í™”ë²½ í™•ì¸ (í•„ìš”ì‹œ)
sudo ufw allow 11434/tcp
```

### 4. ê²€ìƒ‰ ì†ë„ ëŠë¦¼

**ë¬¸ì œ:** ê²€ìƒ‰ ì‹œê°„ì´ ìˆ˜ ì´ˆ ì´ìƒ ì†Œìš”

**í•´ê²° ë°©ë²•:**

```sql
-- 1. ì¸ë±ìŠ¤ í™•ì¸
SELECT 
    indexname, 
    indexdef,
    pg_size_pretty(pg_relation_size(indexname::regclass)) AS size
FROM pg_indexes 
WHERE tablename = 'documents';

-- 2. ì¸ë±ìŠ¤ê°€ ì—†ë‹¤ë©´ ìƒì„±
CREATE INDEX IF NOT EXISTS documents_embedding_idx ON documents 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- 3. VACUUM ì‹¤í–‰
VACUUM ANALYZE documents;

-- 4. ì¿¼ë¦¬ í”Œëœ í™•ì¸
EXPLAIN ANALYZE
SELECT * FROM documents
ORDER BY embedding <-> '[...]'::vector
LIMIT 10;
```

### 5. ë©”ëª¨ë¦¬ ë¶€ì¡± (ëŒ€ìš©ëŸ‰ ë¬¸ì„œ)

**ë¬¸ì œ:**
```
ERROR: out of memory
```

**í•´ê²° ë°©ë²•:**

```python
# ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬
from document_loader import DocumentLoader

def process_large_document(filepath, chunk_size=1000):
    """ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ì²˜ë¦¬"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ì²­í¬ë¡œ ë¶„í• 
    chunks = DocumentLoader.chunk_text(content, chunk_size=chunk_size)
    
    # ê° ì²­í¬ë¥¼ ë³„ë„ ë¬¸ì„œë¡œ ì €ì¥
    for i, chunk in enumerate(chunks):
        doc_id = emb_mgr.insert_document(
            title=f"{Path(filepath).stem} - Part {i+1}",
            content=chunk,
            source=filepath,
            metadata={'chunk_index': i, 'total_chunks': len(chunks)}
        )
```

### 6. PostgreSQL ë¹„ë°€ë²ˆí˜¸ ë¶„ì‹¤

**í•´ê²° ë°©ë²•:**

```bash
# 1. pg_hba.conf ìˆ˜ì • (trust ëª¨ë“œë¡œ ë³€ê²½)
sudo nano /var/lib/pgsql/15/data/pg_hba.conf

# ë‹¤ìŒ ì¤„ì„ ì°¾ì•„ì„œ md5ë¥¼ trustë¡œ ë³€ê²½
# local all all md5
local all all trust

# 2. PostgreSQL ì¬ì‹œì‘
sudo systemctl restart postgresql

# 3. ë¹„ë°€ë²ˆí˜¸ ë³€ê²½
psql -U postgres
\password postgres
# ìƒˆ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥

# 4. pg_hba.conf ì›ë˜ëŒ€ë¡œ ë³µì› (md5)
sudo nano /var/lib/pgsql/15/data/pg_hba.conf
# trustë¥¼ ë‹¤ì‹œ md5ë¡œ ë³€ê²½

# 5. ì¬ì‹œì‘
sudo systemctl restart postgresql
```

---

## ğŸ’¡ ì‹¤ì „ ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ìˆ  ë¬¸ì„œ RAG

```python
# ìƒ˜í”Œ ê¸°ìˆ  ë¬¸ì„œ
tech_docs = [
    {
        'title': 'PostgreSQL ì¸ë±ìŠ¤ ìµœì í™”',
        'content': '''
        PostgreSQLì—ì„œ ì¸ë±ìŠ¤ëŠ” ì¿¼ë¦¬ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        B-tree ì¸ë±ìŠ¤ëŠ” ê°€ì¥ ì¼ë°˜ì ì´ë©°, ëŒ€ë¶€ë¶„ì˜ ê²½ìš°ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
        GIN ì¸ë±ìŠ¤ëŠ” JSONBë‚˜ ë°°ì—´ íƒ€ì…ì— ì í•©í•©ë‹ˆë‹¤.
        ''',
        'source': '/docs/postgresql/indexing.md',
        'metadata': {'category': 'database', 'level': 'advanced'}
    },
    {
        'title': 'Python ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°',
        'content': '''
        asyncioëŠ” Pythonì˜ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
        async/await í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë£¨í‹´ì„ ì •ì˜í•©ë‹ˆë‹¤.
        I/O ë°”ìš´ë“œ ì‘ì—…ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ''',
        'source': '/docs/python/async.md',
        'metadata': {'category': 'programming', 'language': 'python'}
    }
]

# ë¬¸ì„œ ì¶”ê°€
from embedding_manager import EmbeddingManager

emb_mgr = EmbeddingManager()
doc_ids = emb_mgr.bulk_insert_documents(tech_docs)
print(f"âœ… {len(doc_ids)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")

# RAG ì§ˆì˜
from rag_engine import RAGEngine

rag = RAGEngine()

# ì¼ë°˜ ê²€ìƒ‰
result = rag.generate_response("PostgreSQL ì¸ë±ìŠ¤ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”")
print(f"ë‹µë³€: {result['answer']}")

# ë©”íƒ€ë°ì´í„° í•„í„°ë§
result = rag.generate_response(
    "í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”",
    metadata_filter={'category': 'programming'}
)

# ì •ë¦¬
emb_mgr.close()
rag.close()
```

### ì˜ˆì œ 2: íšŒì‚¬ ì •ì±… ë¬¸ì„œ RAG

```python
# íšŒì‚¬ ì •ì±… ë¬¸ì„œ
policy_docs = [
    {
        'title': 'ì¬íƒê·¼ë¬´ ì •ì±…',
        'content': '''
        ì¬íƒê·¼ë¬´ëŠ” ì£¼ 2íšŒê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        ì‚¬ì „ì— íŒ€ì¥ ìŠ¹ì¸ì´ í•„ìš”í•˜ë©°, ê·¼ë¬´ ì¼ì§€ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
        ì¬íƒê·¼ë¬´ ì‹œì—ë„ ì •ìƒ ê·¼ë¬´ ì‹œê°„(9-6ì‹œ)ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.
        ''',
        'source': '/policies/remote_work.md',
        'metadata': {
            'category': 'hr',
            'effective_date': '2024-01-01',
            'department': 'all'
        }
    },
    {
        'title': 'ì—°ì°¨ ì‚¬ìš© ê·œì •',
        'content': '''
        ì—°ì°¨ëŠ” ì…ì‚¬ì¼ ê¸°ì¤€ìœ¼ë¡œ ë¶€ì—¬ë©ë‹ˆë‹¤.
        1ë…„ ë¯¸ë§Œ: ì›” 1ê°œ, 1ë…„ ì´ìƒ: 15ê°œ (ìµœëŒ€ 25ê°œ)
        ì—°ì°¨ëŠ” ì‹œìŠ¤í…œì„ í†µí•´ ì‹ ì²­í•˜ë©°, 3ì¼ ì „ ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
        ''',
        'source': '/policies/annual_leave.md',
        'metadata': {
            'category': 'hr',
            'effective_date': '2024-01-01',
            'department': 'all'
        }
    }
]

# ì¶”ê°€ ë° ê²€ìƒ‰
emb_mgr = EmbeddingManager()
emb_mgr.bulk_insert_documents(policy_docs)

rag = RAGEngine()
result = rag.generate_response("ì¬íƒê·¼ë¬´ë¥¼ í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?")
print(result['answer'])

# ì •ë¦¬
emb_mgr.close()
rag.close()
```

### ì˜ˆì œ 3: ëŒ€í™”í˜• ê³ ê° ì§€ì›

```python
from rag_engine import RAGEngine

rag = RAGEngine()
chat_history = []

# ì‹œë®¬ë ˆì´ì…˜
questions = [
    "ì œí’ˆ ë³´ì¦ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
    "ë³´ì¦ ê¸°ê°„ì´ ì§€ë‚˜ë©´ ìˆ˜ë¦¬ ë¹„ìš©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "í™˜ë¶ˆì€ ê°€ëŠ¥í•œê°€ìš”?"
]

for question in questions:
    print(f"\nì‚¬ìš©ì: {question}")
    
    result = rag.conversational_query(question, chat_history)
    print(f"ë´‡: {result['answer']}")
    
    # ê¸°ë¡ ì €ì¥
    chat_history.append({
        'query': question,
        'answer': result['answer']
    })

rag.close()
```

---

## â“ FAQ

### Q1: pgvectorì™€ ì „ìš© ë²¡í„° DB(Pinecone, Weaviate ë“±)ì˜ ì°¨ì´ëŠ”?

**A:** 

| í•­ëª© | pgvector | ì „ìš© ë²¡í„° DB |
|------|----------|--------------|
| **ì„¤ì¹˜** | PostgreSQL í™•ì¥ | ë³„ë„ ì„œë¹„ìŠ¤ í•„ìš” |
| **SQL ì§€ì›** | ì™„ì „ ì§€ì› | ì œí•œì  |
| **ë¹„ìš©** | ë¬´ë£Œ | ìœ ë£Œ ë˜ëŠ” ì œí•œ |
| **í•™ìŠµ ê³¡ì„ ** | ë‚®ìŒ (SQL ì‚¬ìš©) | ë†’ìŒ (ìƒˆ API) |
| **í™•ì¥ì„±** | ìˆ˜ë°±ë§Œ ë²¡í„° | ìˆ˜ì–µ ë²¡í„° |
| **ì„±ëŠ¥** | ì¢‹ìŒ | ë§¤ìš° ì¢‹ìŒ |

**ì¶”ì²œ:** ëŒ€ë¶€ë¶„ì˜ ê²½ìš° pgvectorë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤. ìˆ˜ì–µ ê°œ ì´ìƒì˜ ë²¡í„°ë¥¼ ë‹¤ë£¨ê±°ë‚˜ ì´ˆê³ ì† ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì „ìš© ë²¡í„° DBë¥¼ ê³ ë ¤í•˜ì„¸ìš”.

### Q2: OpenAI API ëŒ€ì‹  Ollamaë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ”?

**A:**

**Ollama ì¥ì :**
- âœ… ì™„ì „ ë¬´ë£Œ
- âœ… ë¡œì»¬ ì‹¤í–‰ (ê°œì¸ì •ë³´ ë³´í˜¸)
- âœ… ì¸í„°ë„· ë¶ˆí•„ìš”
- âœ… ì†ë„ ì œí•œ ì—†ìŒ

**OpenAI API ì¥ì :**
- âœ… ë” ë†’ì€ í’ˆì§ˆ (GPT-4)
- âœ… ì„¤ì • ê°„ë‹¨
- âœ… ì„œë²„ ë¶ˆí•„ìš”

**ì¶”ì²œ:** ê°œë°œ/í…ŒìŠ¤íŠ¸ëŠ” Ollama, í”„ë¡œë•ì…˜ì€ ìƒí™©ì— ë”°ë¼ ì„ íƒ

### Q3: í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ê°€ ì˜ ë˜ë‚˜ìš”?

**A:** ë„¤, Llama3ëŠ” í•œêµ­ì–´ë¥¼ ì˜ ì§€ì›í•©ë‹ˆë‹¤. ì¶”ê°€ ìµœì í™”:

```python
# í•œêµ­ì–´ ì „ë¬¸ ê²€ìƒ‰ ì„¤ì •
CREATE INDEX idx_documents_content_fts_korean ON documents 
USING GIN(to_tsvector('simple', content));  # í•œêµ­ì–´ëŠ” 'simple' ì‚¬ìš©

# í•œêµ­ì–´ í† í¬ë‚˜ì´ì € (ì„ íƒì‚¬í•­)
# pip install konlpy
from konlpy.tag import Okt
okt = Okt()
tokens = okt.morphs(text)
```

### Q4: ì–¼ë§ˆë‚˜ ë§ì€ ë¬¸ì„œë¥¼ ì €ì¥í•  ìˆ˜ ìˆë‚˜ìš”?

**A:** PostgreSQL + pgvectorëŠ” ìˆ˜ë°±ë§Œ ê°œì˜ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ìš©ëŸ‰ ê°€ì´ë“œ:**
- 1M ë¬¸ì„œ (4096 ì°¨ì›): ~16GB (ë²¡í„°ë§Œ)
- 10M ë¬¸ì„œ: ~160GB
- ìµœì í™” ì‹œ 100M+ ê°€ëŠ¥

**ê¶Œì¥ ì‚¬í•­:**
- 10K ë¯¸ë§Œ: ê¸°ë³¸ ì„¤ì •
- 100K - 1M: IVFFlat ì¸ë±ìŠ¤ + íŒŒí‹°ì…”ë‹
- 1M ì´ìƒ: HNSW ì¸ë±ìŠ¤ + ìƒ¤ë”© ê³ ë ¤

### Q5: ì‹¤ì‹œê°„ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆë‚˜ìš”?

**A:** ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤.

```python
# ë¬¸ì„œ ì—…ë°ì´íŠ¸
def update_document(doc_id, new_content):
    new_embedding = emb_mgr.generate_embedding(new_content)
    
    query = """
        UPDATE documents 
        SET content = %s, embedding = %s, updated_at = CURRENT_TIMESTAMP
        WHERE id = %s
    """
    cursor.execute(query, (new_content, new_embedding, doc_id))
    conn.commit()

# ë¬¸ì„œ ì‚­ì œ
def delete_document(doc_id):
    cursor.execute("DELETE FROM documents WHERE id = %s", (doc_id,))
    conn.commit()
```

### Q6: ì´ë¯¸ì§€ë‚˜ PDFë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‚˜ìš”?

**A:** ë„¤, ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

```bash
# PDF ì²˜ë¦¬
pip install PyPDF2 pdfplumber

# ì´ë¯¸ì§€ OCR
pip install pytesseract Pillow

# Office ë¬¸ì„œ
pip install python-docx openpyxl
```

```python
# PDF ë¡œë” ì˜ˆì‹œ
import PyPDF2

def load_pdf(filepath):
    with open(filepath, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    return text
```

---

## ğŸ“– ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ

- [PostgreSQL ê³µì‹ ë¬¸ì„œ](https://www.postgresql.org/docs/)
- [pgvector GitHub](https://github.com/pgvector/pgvector)
- [Ollama ë¬¸ì„œ](https://ollama.ai/docs)
- [psycopg2 ë¬¸ì„œ](https://www.psycopg.org/docs/)

### í•™ìŠµ ìë£Œ

- [RAG ë…¼ë¬¸ (ì›ë¬¸)](https://arxiv.org/abs/2005.11401)
- [PostgreSQLì„ ì—¬í–‰í•˜ëŠ” ì…ë¬¸ìë¥¼ ìœ„í•œ ì•ˆë‚´ì„œ](https://wikidocs.net/book/8814)
- [pgvector Tutorial](https://github.com/pgvector/pgvector#getting-started)

### ê´€ë ¨ í”„ë¡œì íŠ¸

- [LangChain](https://python.langchain.com/) - RAG í”„ë ˆì„ì›Œí¬
- [LlamaIndex](https://www.llamaindex.ai/) - ë°ì´í„° í”„ë ˆì„ì›Œí¬
- [Haystack](https://haystack.deepset.ai/) - NLP í”„ë ˆì„ì›Œí¬

