# MongoDB Atlas Vector Searchë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ

> í•œêµ­ì–´ ê°œë°œìë¥¼ ìœ„í•œ MongoDB Atlas Vector Search ê¸°ë°˜ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œ ì™„ë²½ êµ¬ì¶• ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ì†Œê°œ](#-í”„ë¡œì íŠ¸-ì†Œê°œ)
- [ì™œ MongoDB Atlas Vector Searchì¸ê°€?](#-ì™œ-mongodb-atlas-vector-searchì¸ê°€)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [í™˜ê²½ êµ¬ì¶•](#-í™˜ê²½-êµ¬ì¶•)
- [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
- [ìƒì„¸ ê°€ì´ë“œ](#-ìƒì„¸-ê°€ì´ë“œ)
- [ì„±ëŠ¥ ìµœì í™”](#-ì„±ëŠ¥-ìµœì í™”)
- [í”„ë¡œë•ì…˜ ë°°í¬](#-í”„ë¡œë•ì…˜-ë°°í¬)
- [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
- [FAQ](#-faq)
- [ì°¸ê³  ìë£Œ](#-ì°¸ê³ -ìë£Œ)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì†Œê°œ

ì´ í”„ë¡œì íŠ¸ëŠ” **MongoDB Atlas Vector Search**ë¥¼ í™œìš©í•˜ì—¬ ê³ ì„±ëŠ¥ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- âœ… **í†µí•© ë°ì´í„°ë² ì´ìŠ¤**: ë²¡í„° ê²€ìƒ‰ê³¼ ì¼ë°˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DBì—ì„œ ê´€ë¦¬
- âœ… **ìë™ ìŠ¤ì¼€ì¼ë§**: Atlasì˜ ìë™ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ íŠ¸ë˜í”½ ë³€í™”ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘
- âœ… **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ë²¡í„° ê²€ìƒ‰ + ì „í†µì  ì¿¼ë¦¬ ê²°í•©
- âœ… **ê¸€ë¡œë²Œ ë°°í¬**: ë©€í‹° ë¦¬ì „ í´ëŸ¬ìŠ¤í„°ë¡œ ì „ ì„¸ê³„ ì €ì§€ì—° ì„œë¹„ìŠ¤
- âœ… **Change Streams**: ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”

### í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. MongoDB Atlas í´ëŸ¬ìŠ¤í„° ìƒì„± ë° Vector Search ì¸ë±ìŠ¤ ì„¤ì •
2. ë²¡í„° ì„ë² ë”© ìƒì„± ë° ì €ì¥
3. ì˜ë¯¸ë¡ ì  ê²€ìƒ‰(Semantic Search)ê³¼ ë©”íƒ€ë°ì´í„° í•„í„°ë§ êµ¬í˜„
4. RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° í”„ë¡œë•ì…˜ ë°°í¬
5. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### ì‹¤ì œ í™œìš© ì‚¬ë¡€

MongoDB Atlas Vector Search ê¸°ë°˜ RAGëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ê³¼ì ì…ë‹ˆë‹¤:

- **ğŸ“š ì „ììƒê±°ë˜ ìƒí’ˆ ê²€ìƒ‰**: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ
- **ğŸ¢ ê³ ê° ì§€ì› ì±—ë´‡**: ê³ ê° íˆìŠ¤í† ë¦¬ì™€ ì§€ì‹ë² ì´ìŠ¤ í†µí•© ê²€ìƒ‰
- **ğŸ“Š ê¸ˆìœµ ë¬¸ì„œ ë¶„ì„**: ê·œì •, ë³´ê³ ì„œ, ê±°ë˜ ë‚´ì—­ í†µí•© ê²€ìƒ‰
- **ğŸ” ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ**: ì‚¬ìš©ì í”„ë¡œí•„ + ì½˜í…ì¸  ë²¡í„° ê¸°ë°˜ ì¶”ì²œ
- **ğŸ’¼ ê¸°ì—… ì§€ì‹ ê²€ìƒ‰**: ë¬¸ì„œ, ì½”ë“œ, ì´ë©”ì¼ í†µí•© ê²€ìƒ‰

---

## ğŸ“‹ ì£¼ìš” ì‚¬ì–‘ (Specs)

### ì§€ì›í•˜ëŠ” ì„ë² ë”© ëª¨ë¸

| ëª¨ë¸ | ì°¨ì› | ì œê³µì‚¬ | íŠ¹ì§• |
|------|------|--------|------|
| **text-embedding-3-small** | 1536 | OpenAI | ë¹ ë¥¸ ì†ë„, ë‚®ì€ ë¹„ìš© |
| **text-embedding-3-large** | 3072 | OpenAI | ë†’ì€ ì •í™•ë„ |
| **text-embedding-ada-002** | 1536 | OpenAI | ì•ˆì •ì ì¸ ë ˆê±°ì‹œ ëª¨ë¸ |
| **amazon.titan-embed-text-v1** | 1024 | AWS Bedrock | ë‹¤êµ­ì–´ ì§€ì› |
| **cohere.embed-multilingual-v3** | 1024 | Cohere | 100+ ì–¸ì–´ ì§€ì› |

### ë²¡í„° ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜

| ì•Œê³ ë¦¬ì¦˜ | ì„¤ëª… | ì„±ëŠ¥ | ì •í™•ë„ |
|----------|------|------|--------|
| **Approximate kNN (HNSW)** | ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ ê²€ìƒ‰ | ë¹ ë¦„ (10-50ms) | 99%+ |
| **Hierarchical Navigable Small World** | ê³„ì¸µì  ê·¸ë˜í”„ ê¸°ë°˜ | ì´ˆê³ ì† | ë§¤ìš° ë†’ìŒ |

### ì˜ˆìƒ ë¹„ìš© (2025ë…„ ê¸°ì¤€)

#### ì†Œê·œëª¨ í”„ë¡œì íŠ¸ (ê°œë°œ/í…ŒìŠ¤íŠ¸)
```
âœ… MongoDB Atlas M0 (Free Tier)
- ì €ì¥ ìš©ëŸ‰: 512MB
- RAM: ê³µìœ  ë©”ëª¨ë¦¬
- ë²¡í„° ê²€ìƒ‰: ì§€ì› (ì œí•œì )
- ë¹„ìš©: $0/ì›”

ğŸ’¡ ë¬´ë£Œ í‹°ì–´ë¡œ RAG í”„ë¡œí† íƒ€ì… ê°œë°œ ê°€ëŠ¥!
```

#### ì¤‘ê·œëª¨ í”„ë¡œì íŠ¸ (í”„ë¡œë•ì…˜)
```
âœ… MongoDB Atlas M10
- ì €ì¥ ìš©ëŸ‰: 10GB
- RAM: 2GB
- vCPU: 2 ì½”ì–´
- ë¹„ìš©: ~$57/ì›”

âœ… OpenAI API (ì›” 10,000 ì¿¼ë¦¬)
- text-embedding-3-small: $0.20
- GPT-4o-mini: ~$10
- ì´ ì˜ˆìƒ: ~$10/ì›”

ğŸ“Š ì´ ì˜ˆìƒ ë¹„ìš©: $67/ì›”
```

#### ëŒ€ê·œëª¨ ì—”í„°í”„ë¼ì´ì¦ˆ
```
âœ… MongoDB Atlas M30 (Multi-region)
- ì €ì¥ ìš©ëŸ‰: 60GB
- RAM: 8GB
- vCPU: 4 ì½”ì–´
- ë¹„ìš©: ~$440/ì›”

âœ… OpenAI API (ì›” 100,000+ ì¿¼ë¦¬)
- Embeddings + LLM: ~$200-500/ì›”

ğŸ“Š ì´ ì˜ˆìƒ ë¹„ìš©: $640-940/ì›”
```

**ë¹„ìš© ìµœì í™” íŒ:**
- **M0 Free Tier**: ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½ì— í™œìš©
- **Reserved Capacity**: 1ë…„ ì•½ì • ì‹œ ìµœëŒ€ 30% í• ì¸
- **Compression**: ë¬¸ì„œ ì••ì¶•ìœ¼ë¡œ ì €ì¥ ê³µê°„ ì ˆì•½
- **Index Optimization**: í•„ìš”í•œ í•„ë“œë§Œ ì¸ë±ì‹±

---

## ğŸ¤” ì™œ MongoDB Atlas Vector Searchì¸ê°€?

### ê¸°ì¡´ ì†”ë£¨ì…˜ vs MongoDB Atlas

| ê¸°ëŠ¥ | ì „ìš© ë²¡í„° DB<br/>(Pinecone, Weaviate) | MongoDB Atlas |
|------|--------------------------------------|---------------|
| **ë²¡í„° ê²€ìƒ‰** | âœ… ì „ë¬¸í™”ë¨ | âœ… ë‚´ì¥ ì§€ì› |
| **ì¼ë°˜ ë°ì´í„°** | âŒ ë³„ë„ DB í•„ìš” | âœ… í†µí•© ê´€ë¦¬ |
| **íŠ¸ëœì­ì…˜** | âŒ ì œí•œì  | âœ… ACID ë³´ì¥ |
| **ë©”íƒ€ë°ì´í„° í•„í„°** | ì œí•œì  | âœ… ê°•ë ¥í•œ ì¿¼ë¦¬ |
| **ìŠ¤ì¼€ì¼ë§** | ìˆ˜ë™ | âœ… ìë™ |
| **í•™ìŠµ ê³¡ì„ ** | ê°€íŒŒë¦„ | âœ… MongoDB ì§€ì‹ í™œìš© |
| **ë¹„ìš©** | ë†’ìŒ | âœ… í•©ë¦¬ì  |

### RAGì— ìµœì ì¸ ì´ìœ 

1. **ë‹¨ì¼ ë°ì´í„°ë² ì´ìŠ¤**: ì‚¬ìš©ì ì •ë³´, ë¬¸ì„œ, ë²¡í„°ë¥¼ í•œê³³ì—ì„œ ê´€ë¦¬
2. **ê°•ë ¥í•œ í•„í„°ë§**: ë³µì¡í•œ ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬ì™€ ë²¡í„° ê²€ìƒ‰ ê²°í•©
3. **Change Streams**: ë¬¸ì„œ ë³€ê²½ ì‹œ ìë™ìœ¼ë¡œ ì„ë² ë”© ì—…ë°ì´íŠ¸
4. **ê¸€ë¡œë²Œ ë°°í¬**: ë©€í‹° ë¦¬ì „ í´ëŸ¬ìŠ¤í„°ë¡œ ì „ ì„¸ê³„ ì €ì§€ì—°
5. **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰**: ë°±ì—…, ë³´ì•ˆ, ëª¨ë‹ˆí„°ë§ ê¸°ë³¸ ì œê³µ
6. **ê°œë°œì ì¹œí™”ì **: ì¹œìˆ™í•œ MongoDB ì¿¼ë¦¬ ë¬¸ë²• ì‚¬ìš©

---

## ğŸ— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### RAG ì›Œí¬í”Œë¡œìš°

```mermaid
graph TD
    User[ì‚¬ìš©ì ì§ˆë¬¸] --> App[ì• í”Œë¦¬ì¼€ì´ì…˜]

    App -->|ì„ë² ë”©| OpenAI[OpenAI/Bedrock<br/>Embedding API]
    OpenAI -->|ë²¡í„° ë°˜í™˜| App

    App -->|ë²¡í„° ê²€ìƒ‰| Atlas[(MongoDB Atlas<br/>Vector Search<br/>HNSW Index)]
    Atlas -->|ë¬¸ì„œ ë°˜í™˜| App

    App -->|í”„ë¡¬í”„íŠ¸| LLM[OpenAI GPT-4o<br/>or Claude]
    LLM -->|ë‹µë³€| App

    App --> User
```

### ë¬¸ì„œ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸

```mermaid
graph LR
    Doc[ì›ë³¸ ë¬¸ì„œ] -->|ì—…ë¡œë“œ| Storage[íŒŒì¼ ì €ì¥ì†Œ]
    Storage -->|íŒŒì‹±| Parser[ë¬¸ì„œ íŒŒì„œ<br/>PDF/DOCX/etc]
    Parser -->|ì²­í‚¹| Chunker[í…ìŠ¤íŠ¸ ë¶„í• <br/>1000-1500ì]
    Chunker -->|ì„ë² ë”©| Embed[ì„ë² ë”© ìƒì„±<br/>OpenAI API]
    Embed -->|ì €ì¥| MongoDB[(MongoDB Atlas<br/>documents ì»¬ë ‰ì…˜)]
```

### ì•„í‚¤í…ì²˜ ìƒì„¸ (í”„ë¡œë•ì…˜)

```
í´ë¼ì´ì–¸íŠ¸ ê³„ì¸µ
â”œâ”€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ (React/Vue/Next.js)
â””â”€ ëª¨ë°”ì¼ ì•± (iOS/Android)
    â†“
API ê³„ì¸µ
â”œâ”€ FastAPI/Express Server
â”‚  â”œâ”€ ì¸ì¦/ì¸ê°€ (JWT)
â”‚  â”œâ”€ Rate Limiting
â”‚  â””â”€ Request Validation
â””â”€ Redis Cache
   â”œâ”€ ì„ë² ë”© ìºì‹œ (ì¿¼ë¦¬ ì¬ì‚¬ìš©)
   â””â”€ ì„¸ì…˜ ê´€ë¦¬
    â†“
ë°ì´í„°ë² ì´ìŠ¤ ê³„ì¸µ
â”œâ”€ MongoDB Atlas (Seoul Region)
â”‚  â”œâ”€ Vector Search Index (HNSW)
â”‚  â”œâ”€ Change Streams (ì‹¤ì‹œê°„ ë™ê¸°í™”)
â”‚  â”œâ”€ documents ì»¬ë ‰ì…˜
â”‚  â””â”€ Row Level Security
    â†“
ML ì„œë¹„ìŠ¤ ê³„ì¸µ
â”œâ”€ OpenAI API
â”‚  â”œâ”€ text-embedding-3-small (ì„ë² ë”©)
â”‚  â””â”€ gpt-4o-mini (ë‹µë³€ ìƒì„±)
â””â”€ AWS Bedrock (ëŒ€ì•ˆ)
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

#### 1. MongoDB Collections

**documents ì»¬ë ‰ì…˜:**
```javascript
{
  _id: ObjectId("..."),
  content: "íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” 15ì¼ì…ë‹ˆë‹¤.",
  embedding: [0.123, -0.456, ...],  // 1536ì°¨ì› ë²¡í„°
  metadata: {
    source: "employee_handbook.pdf",
    page: 5,
    category: "HR",
    created_at: ISODate("2024-12-10T...")
  },
  user_id: ObjectId("..."),
  created_at: ISODate("2024-12-10T...")
}
```

#### 2. Vector Search Index

```javascript
{
  "mappings": {
    "dynamic": true,
    "fields": {
      "embedding": {
        "type": "knnVector",
        "dimensions": 1536,
        "similarity": "cosine"
      },
      "metadata.category": {
        "type": "string"
      }
    }
  }
}
```

---

## ğŸš€ í™˜ê²½ êµ¬ì¶•

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **MongoDB Atlas ê³„ì •**: [mongodb.com/cloud/atlas](https://www.mongodb.com/cloud/atlas) ë¬´ë£Œ ê°€ì…
- **Python**: 3.8 ì´ìƒ ë˜ëŠ” **Node.js**: 16 ì´ìƒ
- **OpenAI API Key** (ì„ íƒ): ì„ë² ë”©/LLM ì‚¬ìš© ì‹œ
- **Git**: ì½”ë“œ ê´€ë¦¬

### 1. MongoDB Atlas í´ëŸ¬ìŠ¤í„° ìƒì„± (ì›¹ ëŒ€ì‹œë³´ë“œ)

#### ë‹¨ê³„ 1: íšŒì›ê°€ì… ë° ë¡œê·¸ì¸

1. [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) ì ‘ì†
2. **"Try Free"** ë²„íŠ¼ í´ë¦­
3. Google, GitHub, ë˜ëŠ” ì´ë©”ì¼ë¡œ íšŒì›ê°€ì…/ë¡œê·¸ì¸

#### ë‹¨ê³„ 2: ì¡°ì§(Organization) ìƒì„±

ì²˜ìŒ ë¡œê·¸ì¸í•˜ë©´ ì¡°ì§ ìƒì„±ì„ ìš”êµ¬í•©ë‹ˆë‹¤:

1. **Organization Name**: ê°œì¸ ë˜ëŠ” íšŒì‚¬ ì´ë¦„ ì…ë ¥ (ì˜ˆ: `my-company`)
2. **Create Organization** í´ë¦­

#### ë‹¨ê³„ 3: í”„ë¡œì íŠ¸ ìƒì„±

1. **"New Project"** ë²„íŠ¼ í´ë¦­
2. **Project Name**: `rag-project` (í”„ë¡œì íŠ¸ ì´ë¦„)
3. **Next** í´ë¦­
4. ë©¤ë²„ ì¶”ê°€ëŠ” ê±´ë„ˆë›°ê³  **"Create Project"** í´ë¦­

#### ë‹¨ê³„ 4: í´ëŸ¬ìŠ¤í„° ìƒì„±

1. **"Build a Database"** ë²„íŠ¼ í´ë¦­
2. ë°°í¬ ìœ í˜• ì„ íƒ:

   **ë¬´ë£Œ í‹°ì–´ (ê°œë°œ/í…ŒìŠ¤íŠ¸):**
   - **M0 FREE** ì„ íƒ
   - Provider: **AWS**
   - Region: **Seoul (ap-northeast-2)** (í•œêµ­ ì‚¬ìš©ì ê¶Œì¥)
   - Cluster Name: `rag-cluster`
   - **Create** í´ë¦­

   **í”„ë¡œë•ì…˜ í™˜ê²½:**
   - **M10** ì´ìƒ ì„ íƒ (Vector Search ìµœì í™”)
   - Multi-region ì„¤ì • ê°€ëŠ¥
   - ìë™ ë°±ì—… í™œì„±í™”

3. â³ í´ëŸ¬ìŠ¤í„° ìƒì„± ëŒ€ê¸° (ì•½ 3-5ë¶„ ì†Œìš”)

#### ë‹¨ê³„ 5: ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©ì ìƒì„±

1. **Security â†’ Database Access** í´ë¦­
2. **"Add New Database User"** í´ë¦­
3. ì •ë³´ ì…ë ¥:
   - **Username**: `rag_user`
   - **Password**: ê°•ë ¥í•œ ë¹„ë°€ë²ˆí˜¸ ìƒì„± (ì˜ˆ: `RAGp@ssw0rd2024!`)
   - âš ï¸ **ë°˜ë“œì‹œ ì•ˆì „í•œ ê³³ì— ì €ì¥í•˜ì„¸ìš”!**
   - **Database User Privileges**: `Read and write to any database`
4. **"Add User"** í´ë¦­

#### ë‹¨ê³„ 6: ë„¤íŠ¸ì›Œí¬ ì•¡ì„¸ìŠ¤ ì„¤ì •

1. **Security â†’ Network Access** í´ë¦­
2. **"Add IP Address"** í´ë¦­
3. ì˜µì…˜ ì„ íƒ:
   - **ê°œë°œ í™˜ê²½**: `Allow Access from Anywhere` (0.0.0.0/0)
   - **í”„ë¡œë•ì…˜**: íŠ¹ì • IP ë˜ëŠ” VPC ì„¤ì •
4. **"Confirm"** í´ë¦­

#### ë‹¨ê³„ 7: ì—°ê²° ë¬¸ìì—´ ë³µì‚¬

1. **Database â†’ Clusters** í´ë¦­
2. í´ëŸ¬ìŠ¤í„°ì—ì„œ **"Connect"** ë²„íŠ¼ í´ë¦­
3. **"Drivers"** ì„ íƒ
4. **Driver**: Python (ë˜ëŠ” ì‚¬ìš© ì–¸ì–´)
5. **Connection String** ë³µì‚¬:

```
mongodb+srv://rag_user:<password>@rag-cluster.xxxxx.mongodb.net/?retryWrites=true&w=majority
```

6. `<password>`ë¥¼ ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ êµì²´í•˜ì—¬ ì•ˆì „í•œ ê³³ì— ì €ì¥

### 2. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install pymongo openai python-dotenv

# ì„ íƒì  íŒ¨í‚¤ì§€ (ë¬¸ì„œ ì²˜ë¦¬)
pip install pypdf langchain-text-splitters
```

**requirements.txt:**
```txt
pymongo>=4.6.0
openai>=1.10.0
python-dotenv>=1.0.0
pypdf>=3.17.0
langchain-text-splitters>=0.0.1
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:

```env
# MongoDB Atlas ì—°ê²° ì •ë³´
MONGODB_URI=mongodb+srv://rag_user:<password>@rag-cluster.xxxxx.mongodb.net/?retryWrites=true&w=majority
MONGODB_DB=rag_database
MONGODB_COLLECTION=documents

# OpenAI API (ì„ë² ë”© ë° LLM)
OPENAI_API_KEY=sk-...

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
LLM_MODEL=gpt-4o-mini
```

**MongoDB ì—°ê²° ë¬¸ìì—´ ì°¾ê¸°:**
1. Atlas Dashboard â†’ Database â†’ Connect
2. Drivers ì„ íƒ
3. Connection String ë³µì‚¬
4. `<password>`ë¥¼ ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ êµì²´

### 4. ì„¤ì¹˜ í™•ì¸

```python
# test_setup.py
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

def test_mongodb():
    """MongoDB Atlas ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("1ï¸âƒ£ MongoDB Atlas ì—°ê²° í…ŒìŠ¤íŠ¸...\n")

    try:
        client = MongoClient(os.getenv('MONGODB_URI'))
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        client.admin.command('ping')
        print("âœ… MongoDB Atlas ì—°ê²° ì„±ê³µ!")

        # ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´
        db_name = os.getenv('MONGODB_DB', 'rag_database')
        db = client[db_name]
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤: {db_name}")

        # ì»¬ë ‰ì…˜ ëª©ë¡
        collections = db.list_collection_names()
        print(f"âœ… ì»¬ë ‰ì…˜ ìˆ˜: {len(collections)}")

        client.close()
        return True
    except Exception as e:
        print(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def test_openai():
    """OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\n2ï¸âƒ£ OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸...\n")

    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

        # ê°„ë‹¨í•œ ì„ë² ë”© í…ŒìŠ¤íŠ¸
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input="í…ŒìŠ¤íŠ¸"
        )

        print("âœ… OpenAI API ì—°ê²° ì„±ê³µ!")
        print(f"âœ… ì„ë² ë”© ì°¨ì›: {len(response.data[0].embedding)}")
        return True
    except Exception as e:
        print(f"âŒ OpenAI ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def main():
    print("=" * 60)
    print("  MongoDB Atlas RAG í™˜ê²½ ì„¤ì • í™•ì¸")
    print("=" * 60 + "\n")

    mongodb_ok = test_mongodb()
    openai_ok = test_openai()

    print("\n" + "=" * 60)
    if mongodb_ok and openai_ok:
        print("ğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("   ì´ì œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  ì¼ë¶€ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”.")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

**ì‹¤í–‰:**
```bash
python test_setup.py
```

**ì˜ˆìƒ ì¶œë ¥:**
```
============================================================
  MongoDB Atlas RAG í™˜ê²½ ì„¤ì • í™•ì¸
============================================================

1ï¸âƒ£ MongoDB Atlas ì—°ê²° í…ŒìŠ¤íŠ¸...

âœ… MongoDB Atlas ì—°ê²° ì„±ê³µ!
âœ… ë°ì´í„°ë² ì´ìŠ¤: rag_database
âœ… ì»¬ë ‰ì…˜ ìˆ˜: 0

2ï¸âƒ£ OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸...

âœ… OpenAI API ì—°ê²° ì„±ê³µ!
âœ… ì„ë² ë”© ì°¨ì›: 1536

============================================================
ğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!
   ì´ì œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.
============================================================
```

### 5. Vector Search Index ìƒì„± (ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ)

ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

#### ë°©ë²• 1: Atlas UI ì‚¬ìš© (ê¶Œì¥)

1. **Database â†’ Clusters** í´ë¦­
2. í´ëŸ¬ìŠ¤í„°ì—ì„œ **"Browse Collections"** í´ë¦­
3. **"Create Database"** ë²„íŠ¼ í´ë¦­:
   - Database name: `rag_database`
   - Collection name: `documents`
   - **Create** í´ë¦­

4. **Atlas Search** íƒ­ í´ë¦­
5. **"Create Search Index"** í´ë¦­
6. **"JSON Editor"** ì„ íƒ
7. ë‹¤ìŒ ì„¤ì • ì…ë ¥:

```json
{
  "mappings": {
    "dynamic": true,
    "fields": {
      "embedding": {
        "type": "knnVector",
        "dimensions": 1536,
        "similarity": "cosine"
      },
      "metadata": {
        "type": "document",
        "fields": {
          "category": {
            "type": "string"
          },
          "source": {
            "type": "string"
          }
        }
      }
    }
  }
}
```

8. **Index Name**: `vector_index`
9. **Database**: `rag_database`
10. **Collection**: `documents`
11. **"Create Search Index"** í´ë¦­
12. â³ ì¸ë±ìŠ¤ ìƒì„± ëŒ€ê¸° (ì•½ 1-2ë¶„)

#### ë°©ë²• 2: Pythonìœ¼ë¡œ ìƒì„±

```python
# create_index.py
import os
from pymongo import MongoClient
from dotenv import load_dotenv

load_dotenv()

client = MongoClient(os.getenv('MONGODB_URI'))
db = client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]

# Vector Search Index ì •ì˜
index_definition = {
    "mappings": {
        "dynamic": True,
        "fields": {
            "embedding": {
                "type": "knnVector",
                "dimensions": 1536,
                "similarity": "cosine"
            },
            "metadata.category": {
                "type": "string"
            },
            "metadata.source": {
                "type": "string"
            }
        }
    }
}

print("Vector Search Indexë¥¼ ìƒì„±í•˜ë ¤ë©´ Atlas UIë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
print("ìœ„ì˜ index_definitionì„ Atlas Search JSON Editorì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
```

**ì£¼ì˜**: Vector Search IndexëŠ” Atlas UIì—ì„œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. Python APIë¡œëŠ” ì§ì ‘ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1. ì²« RAG ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

`simple_rag.py` íŒŒì¼ ìƒì„±:

```python
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

# 1. ë¬¸ì„œ ì €ì¥
print("1ï¸âƒ£ ë¬¸ì„œ ì €ì¥ ì¤‘...")
text = "íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” 15ì¼ì…ë‹ˆë‹¤."

# ì„ë² ë”© ìƒì„±
embedding_response = openai_client.embeddings.create(
    model="text-embedding-3-small",
    input=text
)
embedding = embedding_response.data[0].embedding

# MongoDBì— ì €ì¥
document = {
    'content': text,
    'embedding': embedding,
    'metadata': {
        'source': 'test',
        'category': 'HR'
    }
}
result = collection.insert_one(document)
print(f"âœ… ì €ì¥ ì™„ë£Œ: {result.inserted_id}")

# 2. ë²¡í„° ê²€ìƒ‰
print("\n2ï¸âƒ£ ê²€ìƒ‰ ì¤‘...")
query = "ì—°ì°¨ëŠ” ëª‡ ì¼?"

# ì¿¼ë¦¬ ì„ë² ë”©
query_embedding = openai_client.embeddings.create(
    model="text-embedding-3-small",
    input=query
).data[0].embedding

# Vector Search ì¿¼ë¦¬
pipeline = [
    {
        "$vectorSearch": {
            "index": "vector_index",
            "path": "embedding",
            "queryVector": query_embedding,
            "numCandidates": 100,
            "limit": 3
        }
    },
    {
        "$project": {
            "content": 1,
            "metadata": 1,
            "score": {"$meta": "vectorSearchScore"}
        }
    }
]

docs = list(collection.aggregate(pipeline))

print(f"\nâœ… ê²€ìƒ‰ ê²°ê³¼ ({len(docs)}ê°œ):")
for doc in docs:
    print(f"  - {doc['content']} (ì ìˆ˜: {doc['score']:.3f})")

# 3. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
print("\n3ï¸âƒ£ ë‹µë³€ ìƒì„± ì¤‘...")
context = "\n".join([doc['content'] for doc in docs])

response = openai_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì‚¬ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        {"role": "user", "content": f"ë¬¸ì„œ:\n{context}\n\nì§ˆë¬¸: {query}"}
    ],
    temperature=0.3
)

answer = response.choices[0].message.content
print(f"\nğŸ’¡ ë‹µë³€: {answer}")

mongo_client.close()
```

### 2. ì‹¤í–‰

```bash
python simple_rag.py
```

### 3. ì˜ˆìƒ ì¶œë ¥

```
1ï¸âƒ£ ë¬¸ì„œ ì €ì¥ ì¤‘...
âœ… ì €ì¥ ì™„ë£Œ: 675820a1b2c3d4e5f6g7h8i9

2ï¸âƒ£ ê²€ìƒ‰ ì¤‘...

âœ… ê²€ìƒ‰ ê²°ê³¼ (1ê°œ):
  - íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” 15ì¼ì…ë‹ˆë‹¤. (ì ìˆ˜: 0.985)

3ï¸âƒ£ ë‹µë³€ ìƒì„± ì¤‘...

ğŸ’¡ ë‹µë³€: íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” 15ì¼ì…ë‹ˆë‹¤.
```

### 4. Atlas UIì—ì„œ í™•ì¸

1. **Database â†’ Browse Collections** í´ë¦­
2. **rag_database â†’ documents** ì„ íƒ
3. ë°©ê¸ˆ ì €ì¥í•œ ë¬¸ì„œ í™•ì¸:

```json
{
  "_id": ObjectId("675820a1b2c3d4e5f6g7h8i9"),
  "content": "íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” 15ì¼ì…ë‹ˆë‹¤.",
  "embedding": [0.123, -0.456, ...],
  "metadata": {
    "source": "test",
    "category": "HR"
  }
}
```

ğŸ‰ **ì¶•í•˜í•©ë‹ˆë‹¤!** ì²« MongoDB RAG ì‹œìŠ¤í…œì´ ì‘ë™í–ˆìŠµë‹ˆë‹¤!

---

## ğŸ“š ìƒì„¸ ê°€ì´ë“œ

### 1. ì—¬ëŸ¬ ë¬¸ì„œ ì €ì¥ (ë°°ì¹˜ ì—…ë¡œë“œ)

`upload_docs.py` ìƒì„±:

```python
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

load_dotenv()

mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

def create_embeddings_batch(texts: List[str]) -> List[List[float]]:
    """ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (ë¹„ìš© ìµœì í™”)"""
    response = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=texts
    )
    return [data.embedding for data in response.data]

def upload_documents(texts: List[str], metadata_list: List[Dict]):
    """ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ì—…ë¡œë“œ"""
    print(f"ğŸ“š {len(texts)}ê°œ ë¬¸ì„œ ì—…ë¡œë“œ ì¤‘...\n")

    # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (API í˜¸ì¶œ ìµœì†Œí™”)
    embeddings = create_embeddings_batch(texts)

    # ë¬¸ì„œ ì¤€ë¹„
    documents = []
    for text, embedding, metadata in zip(texts, embeddings, metadata_list):
        documents.append({
            'content': text,
            'embedding': embedding,
            'metadata': metadata
        })

    # MongoDBì— ë°°ì¹˜ ì‚½ì…
    result = collection.insert_many(documents)

    print(f"âœ… {len(result.inserted_ids)}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ!")
    return result.inserted_ids

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # íšŒì‚¬ ê·œì • ë¬¸ì„œë“¤
    documents = [
        "íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” ì…ì‚¬ 1ë…„ë§ˆë‹¤ 15ì¼ì´ ì œê³µë©ë‹ˆë‹¤.",
        "ì¬íƒê·¼ë¬´ëŠ” ì£¼ 2íšŒê¹Œì§€ ê°€ëŠ¥í•˜ë©°, ì‚¬ì „ ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "ì ì‹¬ì‹œê°„ì€ 12ì‹œë¶€í„° 1ì‹œê¹Œì§€ì´ë©°, ììœ¨ì ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "ì•¼ê·¼ ìˆ˜ë‹¹ì€ ì‹œê°„ë‹¹ ê¸°ë³¸ê¸‰ì˜ 1.5ë°°ë¡œ ì§€ê¸‰ë©ë‹ˆë‹¤.",
        "ìœ¡ì•„íœ´ì§ì€ ìµœëŒ€ 1ë…„ê¹Œì§€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
    ]

    metadata_list = [
        {'source': 'employee_handbook.pdf', 'category': 'HR', 'page': 5},
        {'source': 'employee_handbook.pdf', 'category': 'Work', 'page': 12},
        {'source': 'employee_handbook.pdf', 'category': 'Work', 'page': 8},
        {'source': 'employee_handbook.pdf', 'category': 'HR', 'page': 15},
        {'source': 'employee_handbook.pdf', 'category': 'HR', 'page': 20}
    ]

    upload_documents(documents, metadata_list)

    # í†µê³„ í™•ì¸
    total = collection.count_documents({})
    print(f"\nğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {total}ê°œ")

    mongo_client.close()
```

**ì‹¤í–‰:**
```bash
python upload_docs.py
```

### 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + ë©”íƒ€ë°ì´í„° í•„í„°)

```python
# hybrid_search.py
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

def hybrid_search(query: str, category_filter: str = None, limit: int = 5):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„°

    Args:
        query: ê²€ìƒ‰ ì§ˆë¬¸
        category_filter: ì¹´í…Œê³ ë¦¬ í•„í„° (ì˜ˆ: "HR", "Work")
        limit: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    """
    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

    # Vector Search íŒŒì´í”„ë¼ì¸ êµ¬ì„±
    pipeline = [
        {
            "$vectorSearch": {
                "index": "vector_index",
                "path": "embedding",
                "queryVector": query_embedding,
                "numCandidates": 100,
                "limit": limit
            }
        }
    ]

    # ë©”íƒ€ë°ì´í„° í•„í„° ì¶”ê°€
    if category_filter:
        pipeline.append({
            "$match": {
                "metadata.category": category_filter
            }
        })

    # í”„ë¡œì ì…˜ ì¶”ê°€
    pipeline.append({
        "$project": {
            "content": 1,
            "metadata": 1,
            "score": {"$meta": "vectorSearchScore"}
        }
    })

    # ê²€ìƒ‰ ì‹¤í–‰
    results = list(collection.aggregate(pipeline))

    return results

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # 1. ì¼ë°˜ ë²¡í„° ê²€ìƒ‰
    print("1ï¸âƒ£ ì¼ë°˜ ê²€ìƒ‰: ì—°ì°¨ ê´€ë ¨")
    results = hybrid_search("ì—°ì°¨ëŠ” ëª‡ ì¼ì´ì•¼?")
    for doc in results:
        print(f"  - [{doc['metadata']['category']}] {doc['content']} (ì ìˆ˜: {doc['score']:.3f})")

    # 2. ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    print("\n2ï¸âƒ£ HR ì¹´í…Œê³ ë¦¬ë§Œ ê²€ìƒ‰")
    results = hybrid_search("íœ´ê°€ ê·œì •", category_filter="HR")
    for doc in results:
        print(f"  - [{doc['metadata']['category']}] {doc['content']} (ì ìˆ˜: {doc['score']:.3f})")

    mongo_client.close()
```

### 3. PDF ë¬¸ì„œ ì—…ë¡œë“œ

```python
# upload_pdf.py
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv
import pypdf
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()

mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

def upload_pdf(pdf_path: str):
    """PDFë¥¼ ì²­í‚¹í•˜ì—¬ MongoDBì— ì—…ë¡œë“œ"""
    print(f"ğŸ“„ PDF ì½ëŠ” ì¤‘: {pdf_path}")

    # 1. PDF ì½ê¸°
    reader = pypdf.PdfReader(pdf_path)
    full_text = ""
    for page in reader.pages:
        full_text += page.extract_text()

    print(f"  ì´ {len(reader.pages)}í˜ì´ì§€, {len(full_text)}ì")

    # 2. ì²­í‚¹
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ". ", " "]
    )
    chunks = splitter.split_text(full_text)
    print(f"  {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")

    # 3. ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
    print(f"\nğŸ’¾ ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = []
    batch_size = 100  # OpenAI API ì œí•œ

    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        response = openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=batch
        )
        embeddings.extend([data.embedding for data in response.data])
        print(f"  [{i+len(batch)}/{len(chunks)}] ì™„ë£Œ")

    # 4. MongoDBì— ì €ì¥
    print(f"\nğŸ’¾ MongoDBì— ì—…ë¡œë“œ ì¤‘...")
    documents = []
    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
        documents.append({
            'content': chunk,
            'embedding': embedding,
            'metadata': {
                'source': pdf_path,
                'chunk_index': i,
                'total_chunks': len(chunks)
            }
        })

    result = collection.insert_many(documents)
    print(f"\nâœ… {len(result.inserted_ids)}ê°œ ì²­í¬ ì—…ë¡œë“œ ì™„ë£Œ!")

# ì‚¬ìš©
if __name__ == "__main__":
    # PDF íŒŒì¼ ê²½ë¡œ (ë³¸ì¸ì˜ íŒŒì¼ë¡œ ë³€ê²½í•˜ì„¸ìš”)
    upload_pdf("company_handbook.pdf")

    mongo_client.close()
```

### 4. RAG ì±—ë´‡ êµ¬í˜„

```python
# chatbot.py
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

def ask(question: str, category_filter: str = None):
    """RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ"""
    print(f"\nâ“ ì§ˆë¬¸: {question}")

    # 1. ì§ˆë¬¸ ì„ë² ë”©
    query_embedding = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=question
    ).data[0].embedding

    # 2. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    pipeline = [
        {
            "$vectorSearch": {
                "index": "vector_index",
                "path": "embedding",
                "queryVector": query_embedding,
                "numCandidates": 100,
                "limit": 3
            }
        },
        {
            "$project": {
                "content": 1,
                "metadata": 1,
                "score": {"$meta": "vectorSearchScore"}
            }
        }
    ]

    docs = list(collection.aggregate(pipeline))

    if not docs:
        return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "\n".join([doc['content'] for doc in docs])

    # 4. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
    response = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì‚¬ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."},
            {"role": "user", "content": f"ë¬¸ì„œ:\n{context}\n\nì§ˆë¬¸: {question}"}
        ],
        temperature=0.3
    )

    answer = response.choices[0].message.content

    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ’¡ ë‹µë³€: {answer}\n")
    print("ğŸ“š ì°¸ê³  ë¬¸ì„œ:")
    for i, doc in enumerate(docs, 1):
        source = doc['metadata'].get('source', 'Unknown')
        print(f"  {i}. {doc['content'][:50]}... (ì¶œì²˜: {source}, ì ìˆ˜: {doc['score']:.3f})")

    return answer

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¤– íšŒì‚¬ ê·œì • ì±—ë´‡")
    print("=" * 60)

    questions = [
        "ì—°ì°¨ëŠ” ëª‡ ì¼ì´ì•¼?",
        "ì¬íƒê·¼ë¬´ ê°€ëŠ¥í•´?",
        "ì ì‹¬ì‹œê°„ì´ ì–¸ì œì•¼?",
        "ìœ¡ì•„íœ´ì§ì€ ì–¼ë§ˆë‚˜ ì“¸ ìˆ˜ ìˆì–´?"
    ]

    for q in questions:
        ask(q)
        print("\n" + "-" * 60)

    mongo_client.close()
```

**ì‹¤í–‰:**
```bash
python chatbot.py
```

### 5. Change Streamsë¡œ ì‹¤ì‹œê°„ ë™ê¸°í™”

ë¬¸ì„œê°€ ë³€ê²½ë  ë•Œ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

```python
# watch_changes.py
import os
from pymongo import MongoClient
from openai import OpenAI
from dotenv import load_dotenv
import threading

load_dotenv()

mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

def update_embedding(doc_id, content):
    """ë¬¸ì„œ ë‚´ìš©ì´ ë³€ê²½ë˜ë©´ ì„ë² ë”© ì¬ìƒì„±"""
    print(f"ğŸ”„ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì¤‘: {doc_id}")

    # ìƒˆ ì„ë² ë”© ìƒì„±
    embedding = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=content
    ).data[0].embedding

    # MongoDB ì—…ë°ì´íŠ¸
    collection.update_one(
        {'_id': doc_id},
        {'$set': {'embedding': embedding}}
    )

    print(f"âœ… ì„ë² ë”© ì—…ë°ì´íŠ¸ ì™„ë£Œ: {doc_id}")

def watch_collection():
    """Change Streamsë¡œ ì»¬ë ‰ì…˜ ë³€ê²½ ê°ì§€"""
    print("ğŸ‘€ Change Streams ì‹œì‘...")
    print("ë¬¸ì„œê°€ ë³€ê²½ë˜ë©´ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n")

    # Change Stream ìƒì„±
    with collection.watch() as stream:
        for change in stream:
            operation = change['operationType']

            # INSERT ë˜ëŠ” UPDATE ì‘ì—… ê°ì§€
            if operation in ['insert', 'update', 'replace']:
                doc_id = change['documentKey']['_id']

                # ì „ì²´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
                doc = collection.find_one({'_id': doc_id})

                if doc and 'content' in doc:
                    content = doc['content']

                    # ì„ë² ë”©ì´ ì—†ê±°ë‚˜ contentê°€ ë³€ê²½ëœ ê²½ìš°
                    if 'embedding' not in doc or operation in ['update', 'replace']:
                        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì„ë² ë”© ì—…ë°ì´íŠ¸
                        thread = threading.Thread(
                            target=update_embedding,
                            args=(doc_id, content)
                        )
                        thread.start()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    try:
        watch_collection()
    except KeyboardInterrupt:
        print("\nâ›” Change Streams ì¢…ë£Œ")
        mongo_client.close()
```

**ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰:**
```bash
# ë³„ë„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
python watch_changes.py &
```

---

## ğŸ”§ ì„±ëŠ¥ ìµœì í™”

### 1. ì¸ë±ìŠ¤ ìµœì í™”

```python
# optimize_indexes.py
from pymongo import MongoClient, ASCENDING
import os
from dotenv import load_dotenv

load_dotenv()

client = MongoClient(os.getenv('MONGODB_URI'))
db = client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]

# 1. ë©”íƒ€ë°ì´í„° í•„ë“œ ì¸ë±ìŠ¤ (ë¹ ë¥¸ í•„í„°ë§)
collection.create_index([
    ("metadata.category", ASCENDING),
    ("metadata.source", ASCENDING)
])

# 2. ìƒì„±ì¼ ì¸ë±ìŠ¤ (ì‹œê°„ ê¸°ë°˜ ì¿¼ë¦¬)
collection.create_index([("created_at", ASCENDING)])

# 3. ë³µí•© ì¸ë±ìŠ¤ (ì¹´í…Œê³ ë¦¬ + ìƒì„±ì¼)
collection.create_index([
    ("metadata.category", ASCENDING),
    ("created_at", ASCENDING)
])

print("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!")

# ì¸ë±ìŠ¤ í™•ì¸
indexes = collection.list_indexes()
print("\nğŸ“Š ì¸ë±ìŠ¤ ëª©ë¡:")
for idx in indexes:
    print(f"  - {idx['name']}: {idx.get('key', {})}")

client.close()
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
def bulk_upsert_documents(documents: list, batch_size: int = 100):
    """
    ëŒ€ëŸ‰ ë¬¸ì„œ ì—…ë¡œë“œ ìµœì í™”
    - ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    - Bulk Write ì‚¬ìš©
    """
    from pymongo import UpdateOne

    print(f"ğŸ“¦ {len(documents)}ê°œ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘...")

    # 1. ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
    texts = [doc['content'] for doc in documents]
    all_embeddings = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        response = openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=batch
        )
        all_embeddings.extend([data.embedding for data in response.data])
        print(f"  ì„ë² ë”©: [{i+len(batch)}/{len(texts)}]")

    # 2. Bulk Write ì¤€ë¹„
    operations = []
    for doc, embedding in zip(documents, all_embeddings):
        doc['embedding'] = embedding
        operations.append(
            UpdateOne(
                {'content': doc['content']},  # ì¤‘ë³µ ì²´í¬
                {'$set': doc},
                upsert=True
            )
        )

    # 3. Bulk Write ì‹¤í–‰
    result = collection.bulk_write(operations)

    print(f"âœ… ì‚½ì…: {result.upserted_count}, ì—…ë°ì´íŠ¸: {result.modified_count}")
    return result
```

### 3. ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •

```python
import time
from pymongo import MongoClient
from openai import OpenAI

def benchmark_search(query: str, num_runs: int = 10):
    """ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •"""

    # ì¿¼ë¦¬ ì„ë² ë”© (í•œ ë²ˆë§Œ)
    query_embedding = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

    # ê²€ìƒ‰ ë°˜ë³µ ì¸¡ì •
    times = []
    for _ in range(num_runs):
        start = time.time()

        pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "path": "embedding",
                    "queryVector": query_embedding,
                    "numCandidates": 100,
                    "limit": 5
                }
            }
        ]

        results = list(collection.aggregate(pipeline))

        elapsed = time.time() - start
        times.append(elapsed)

    # í†µê³„ ì¶œë ¥
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)

    print(f"\nğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ ({num_runs}íšŒ í‰ê· ):")
    print(f"  í‰ê· : {avg_time*1000:.2f}ms")
    print(f"  ìµœì†Œ: {min_time*1000:.2f}ms")
    print(f"  ìµœëŒ€: {max_time*1000:.2f}ms")
    print(f"  ê²°ê³¼ ìˆ˜: {len(results)}ê°œ")
```

### 4. ìºì‹± ì „ëµ

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def get_query_embedding_cached(query: str):
    """ì¿¼ë¦¬ ì„ë² ë”© ìºì‹± (ë™ì¼ ì§ˆë¬¸ ë°˜ë³µ ì‹œ)"""
    return openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    ).data[0].embedding

def search_with_cache(query: str):
    """ìºì‹±ëœ ì„ë² ë”© ì‚¬ìš©"""
    query_embedding = get_query_embedding_cached(query)

    pipeline = [
        {
            "$vectorSearch": {
                "index": "vector_index",
                "path": "embedding",
                "queryVector": query_embedding,
                "numCandidates": 100,
                "limit": 5
            }
        }
    ]

    return list(collection.aggregate(pipeline))
```

---

## ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬

### 1. FastAPI ì„œë²„ êµ¬í˜„

```python
# api_server.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from pymongo import MongoClient
from openai import OpenAI
import os
from dotenv import load_dotenv
from typing import List, Optional

load_dotenv()

app = FastAPI(title="MongoDB RAG API")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
mongo_client = MongoClient(os.getenv('MONGODB_URI'))
db = mongo_client[os.getenv('MONGODB_DB')]
collection = db[os.getenv('MONGODB_COLLECTION')]
openai_client = OpenAI()

class QueryRequest(BaseModel):
    question: str
    category_filter: Optional[str] = None
    limit: int = 5

class QueryResponse(BaseModel):
    answer: str
    sources: List[dict]

@app.post("/ask", response_model=QueryResponse)
async def ask_question(request: QueryRequest):
    """RAG ì§ˆì˜ì‘ë‹µ API"""
    try:
        # 1. ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=request.question
        ).data[0].embedding

        # 2. ë²¡í„° ê²€ìƒ‰
        pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "path": "embedding",
                    "queryVector": query_embedding,
                    "numCandidates": 100,
                    "limit": request.limit
                }
            },
            {
                "$project": {
                    "content": 1,
                    "metadata": 1,
                    "score": {"$meta": "vectorSearchScore"}
                }
            }
        ]

        docs = list(collection.aggregate(pipeline))

        if not docs:
            raise HTTPException(status_code=404, detail="ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n".join([doc['content'] for doc in docs])

        # 4. LLM ë‹µë³€ ìƒì„±
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì‚¬ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": f"ë¬¸ì„œ:\n{context}\n\nì§ˆë¬¸: {request.question}"}
            ],
            temperature=0.3
        )

        answer = response.choices[0].message.content

        # 5. ì‘ë‹µ ë°˜í™˜
        return QueryResponse(
            answer=answer,
            sources=[
                {
                    "content": doc['content'][:100] + "...",
                    "metadata": doc['metadata'],
                    "score": doc['score']
                }
                for doc in docs
            ]
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    try:
        mongo_client.admin.command('ping')
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

@app.get("/stats")
async def get_stats():
    """í†µê³„ ì •ë³´"""
    total_docs = collection.count_documents({})
    categories = collection.distinct("metadata.category")

    return {
        "total_documents": total_docs,
        "categories": categories
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**ì‹¤í–‰:**
```bash
pip install fastapi uvicorn
python api_server.py
```

**API í…ŒìŠ¤íŠ¸:**
```bash
# cURLë¡œ í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "ì—°ì°¨ëŠ” ëª‡ ì¼ì´ì•¼?"}'

# í—¬ìŠ¤ ì²´í¬
curl "http://localhost:8000/health"

# í†µê³„ í™•ì¸
curl "http://localhost:8000/stats"
```

### 2. Docker ë°°í¬

**Dockerfile:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì„œë²„ ì‹¤í–‰
CMD ["uvicorn", "api_server:app", "--host", "0.0.0.0", "--port", "8000"]
```

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - MONGODB_DB=${MONGODB_DB}
      - MONGODB_COLLECTION=${MONGODB_COLLECTION}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    env_file:
      - .env
    restart: unless-stopped
```

**ì‹¤í–‰:**
```bash
docker-compose up -d
```

### 3. í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (í”„ë¡œë•ì…˜)

**.env.production:**
```env
# MongoDB Atlas (í”„ë¡œë•ì…˜)
MONGODB_URI=mongodb+srv://prod_user:<password>@prod-cluster.xxxxx.mongodb.net/?retryWrites=true&w=majority
MONGODB_DB=rag_production
MONGODB_COLLECTION=documents

# OpenAI API
OPENAI_API_KEY=sk-...

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
LLM_MODEL=gpt-4o-mini

# ì„±ëŠ¥ ì„¤ì •
MAX_POOL_SIZE=50
MIN_POOL_SIZE=10
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. `pymongo.errors.ServerSelectionTimeoutError`

**ì›ì¸**: MongoDB Atlas ë„¤íŠ¸ì›Œí¬ ì•¡ì„¸ìŠ¤ ë¬¸ì œ

**í•´ê²°ì±…**:
```bash
# 1. Atlas UIì—ì„œ Network Access í™•ì¸
# - Security â†’ Network Access
# - í˜„ì¬ IPê°€ í—ˆìš© ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸

# 2. ì—°ê²° ë¬¸ìì—´ í™•ì¸
# - <password> ë¶€ë¶„ì´ URL ì¸ì½”ë”©ë˜ì—ˆëŠ”ì§€ í™•ì¸
# - íŠ¹ìˆ˜ë¬¸ìê°€ ìˆìœ¼ë©´ ì¸ì½”ë”© í•„ìš” (ì˜ˆ: @ â†’ %40)

# 3. ë°©í™”ë²½ í™•ì¸
# - 27017 í¬íŠ¸ê°€ ì°¨ë‹¨ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
```

### 2. Vector Search ê²°ê³¼ê°€ ì—†ìŒ

**ì›ì¸**: ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜ëª» ì„¤ì •ë¨

**í•´ê²°ì±…**:
```python
# 1. ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸
# Atlas UI â†’ Atlas Search â†’ Indexes
# ìƒíƒœê°€ "Active"ì¸ì§€ í™•ì¸

# 2. ì¸ë±ìŠ¤ ì´ë¦„ í™•ì¸
pipeline = [
    {
        "$vectorSearch": {
            "index": "vector_index",  # ì •í™•í•œ ì¸ë±ìŠ¤ ì´ë¦„ ì‚¬ìš©
            "path": "embedding",
            "queryVector": query_embedding,
            "numCandidates": 100,
            "limit": 5
        }
    }
]

# 3. ì„ë² ë”© í•„ë“œ í™•ì¸
sample_doc = collection.find_one()
print("ì„ë² ë”© ì¡´ì¬:", "embedding" in sample_doc)
print("ì„ë² ë”© ì°¨ì›:", len(sample_doc.get("embedding", [])))
```

### 3. ëŠë¦° ê²€ìƒ‰ ì†ë„

**ì›ì¸**: ì¸ë±ìŠ¤ ìµœì í™” ë¶€ì¡± ë˜ëŠ” ë„ˆë¬´ ë§ì€ í›„ë³´

**í•´ê²°ì±…**:
```python
# numCandidates ì¡°ì • (ë„ˆë¬´ í¬ë©´ ëŠë¦¼)
pipeline = [
    {
        "$vectorSearch": {
            "index": "vector_index",
            "path": "embedding",
            "queryVector": query_embedding,
            "numCandidates": 50,  # 100ì—ì„œ 50ìœ¼ë¡œ ê°ì†Œ
            "limit": 5
        }
    }
]

# M10 ì´ìƒ í´ëŸ¬ìŠ¤í„° ì‚¬ìš© (í”„ë¡œë•ì…˜)
# Free Tier (M0)ëŠ” ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ ì œí•œ
```

### 4. ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜

**ì›ì¸**: ì¸ë±ìŠ¤ ì°¨ì›ê³¼ ì„ë² ë”© ì°¨ì›ì´ ë‹¤ë¦„

**í•´ê²°ì±…**:
```python
# 1. ì„ë² ë”© ëª¨ë¸ í™•ì¸
response = openai_client.embeddings.create(
    model="text-embedding-3-small",  # 1536ì°¨ì›
    input="test"
)
print("ì°¨ì›:", len(response.data[0].embedding))

# 2. ì¸ë±ìŠ¤ ì°¨ì› í™•ì¸
# Atlas UI â†’ Atlas Search â†’ vector_index
# dimensions: 1536ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

# 3. ì°¨ì›ì´ ë‹¤ë¥´ë©´ ì¸ë±ìŠ¤ ì¬ìƒì„±
# - ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
# - ì˜¬ë°”ë¥¸ ì°¨ì›ìœ¼ë¡œ ì¬ìƒì„±
# - ëª¨ë“  ë¬¸ì„œ ì„ë² ë”© ì¬ìƒì„±
```

---

## â“ FAQ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸)

### Q1. MongoDB Atlas Free Tierë¡œ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?

**A:** ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! M0 Free Tierì—ì„œë„ Vector Searchë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì œí•œ ì‚¬í•­:**
- ì €ì¥ ìš©ëŸ‰: 512MB
- ê³µìœ  RAM (ì„±ëŠ¥ ì œí•œ)
- ë²¡í„° ê²€ìƒ‰ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ

**ê¶Œì¥ ì‚¬ìš©ì²˜:**
- í”„ë¡œí† íƒ€ì… ê°œë°œ
- í•™ìŠµ ë° ì‹¤í—˜
- ì†Œê·œëª¨ ë°ëª¨ (<1000 ë¬¸ì„œ)

**í”„ë¡œë•ì…˜ ì „í™˜:** M10 ì´ìƒ ê¶Œì¥ (ì „ìš© ë¦¬ì†ŒìŠ¤, ë” ë¹ ë¥¸ ê²€ìƒ‰)

### Q2. ë²¡í„° ì„ë² ë”© ëª¨ë¸ì„ ë³€ê²½í•˜ë ¤ë©´?

**A:** ëª¨ë¸ ë³€ê²½ ì‹œ ëª¨ë“  ë¬¸ì„œì˜ ì„ë² ë”©ì„ ì¬ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

```python
# 1. ìƒˆ ëª¨ë¸ë¡œ ì„ë² ë”© ì¬ìƒì„±
def re_embed_all_documents(new_model: str, new_dimensions: int):
    """ëª¨ë“  ë¬¸ì„œ ì„ë² ë”© ì¬ìƒì„±"""
    docs = collection.find({})

    for doc in docs:
        # ìƒˆ ì„ë² ë”© ìƒì„±
        embedding = openai_client.embeddings.create(
            model=new_model,
            input=doc['content']
        ).data[0].embedding

        # ì—…ë°ì´íŠ¸
        collection.update_one(
            {'_id': doc['_id']},
            {'$set': {'embedding': embedding}}
        )

# 2. Vector Search Index ì°¨ì› ë³€ê²½
# Atlas UIì—ì„œ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±
# dimensions: 1536 â†’ 3072 (ì˜ˆ: text-embedding-3-large)

# 3. í™˜ê²½ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSIONS=3072
```

### Q3. í•œêµ­ì–´ ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ë ¤ë©´?

**A:** ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ê³¼ ë©”íƒ€ë°ì´í„° í™œìš©ì´ í•µì‹¬ì…ë‹ˆë‹¤.

```python
# 1. ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
# - OpenAI text-embedding-3-small/large (ë‹¤êµ­ì–´ ì§€ì›)
# - Cohere embed-multilingual-v3

# 2. ë©”íƒ€ë°ì´í„°ì— ì–¸ì–´ ì •ë³´ ì¶”ê°€
document = {
    'content': "íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” 15ì¼ì…ë‹ˆë‹¤.",
    'embedding': embedding,
    'metadata': {
        'language': 'ko',
        'source': 'handbook.pdf'
    }
}

# 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)
# MongoDBì˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ ê²°í•©
collection.create_index([("content", "text")])

# 4. ë™ì˜ì–´ ì²˜ë¦¬
# ì§ˆë¬¸ ì „ì²˜ë¦¬: "ì—°ì°¨" â†’ "ì—°ì°¨ íœ´ê°€", "íœ´ê°€"
```

### Q4. ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?

**A:** ì²­í‚¹, ë°°ì¹˜ ì²˜ë¦¬, ë¹„ë™ê¸° ì‘ì—…ì„ í™œìš©í•˜ì„¸ìš”.

```python
# 1. íš¨ìœ¨ì ì¸ ì²­í‚¹
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # ì ë‹¹í•œ í¬ê¸°
    chunk_overlap=200,    # ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
    separators=["\n\n", "\n", ". ", " "]
)

# 2. ë°°ì¹˜ ì„ë² ë”© (ë¹„ìš© ë° ì†ë„ ìµœì í™”)
batch_size = 100
for i in range(0, len(chunks), batch_size):
    batch = chunks[i:i+batch_size]
    embeddings = create_embeddings_batch(batch)
    # ë°°ì¹˜ ì €ì¥
    collection.insert_many(documents)

# 3. ë¹„ë™ê¸° ì²˜ë¦¬ (ëŒ€ìš©ëŸ‰ íŒŒì¼)
import asyncio
from motor.motor_asyncio import AsyncIOMotorClient

async def process_large_file(file_path):
    # ë¹„ë™ê¸°ë¡œ ë¬¸ì„œ ì²˜ë¦¬
    pass
```

### Q5. ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì •í™•í•œë° ì–´ë–»ê²Œ ê°œì„ í•˜ë‚˜ìš”?

**A:** ì—¬ëŸ¬ ì „ëµì„ ì¡°í•©í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# 1. numCandidates ì¦ê°€ (ë” ë§ì€ í›„ë³´ ê²€ìƒ‰)
"numCandidates": 200,  # ê¸°ë³¸ 100ì—ì„œ ì¦ê°€
"limit": 5

# 2. ë©”íƒ€ë°ì´í„° í•„í„°ë§ (ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œ)
{
    "$vectorSearch": {
        "index": "vector_index",
        "path": "embedding",
        "queryVector": query_embedding,
        "filter": {
            "metadata.category": {"$eq": "HR"}
        },
        "numCandidates": 100,
        "limit": 5
    }
}

# 3. ë¦¬ë­í‚¹ (Cross-encoder ì‚¬ìš©)
# 1ì°¨ ë²¡í„° ê²€ìƒ‰ â†’ 2ì°¨ ì •í™•ë„ í‰ê°€
from sentence_transformers import CrossEncoder
model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
scores = model.predict([(query, doc['content']) for doc in results])

# 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)
# ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ê²°í•©
```

### Q6. ë¹„ìš©ì„ ì ˆê°í•˜ë ¤ë©´?

**A:** ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬, ëª¨ë¸ ì„ íƒìœ¼ë¡œ ë¹„ìš©ì„ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# 1. ì„ë² ë”© ìºì‹± (ë™ì¼ ì¿¼ë¦¬ ì¬ì‚¬ìš©)
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_cached_embedding(text: str):
    return openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    ).data[0].embedding

# 2. ë°°ì¹˜ ì„ë² ë”© (API í˜¸ì¶œ ìµœì†Œí™”)
# 100ê°œ í…ìŠ¤íŠ¸ë¥¼ 1ë²ˆ í˜¸ì¶œë¡œ ì²˜ë¦¬

# 3. ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš©
# - Embedding: text-embedding-3-small (ada-002ë³´ë‹¤ ì €ë ´)
# - LLM: gpt-4o-mini (gpt-4 ëŒ€ë¹„ 80% ì ˆê°)

# 4. MongoDB ìµœì í™”
# - M0 Free Tierë¡œ ì‹œì‘
# - í•„ìš” ì‹œ M10ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
# - Reserved Capacity 1ë…„ ì•½ì • (30% í• ì¸)
```

### Q7. ë©€í‹° í…Œë„ŒíŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ë©´?

**A:** user_id í•„ë“œì™€ ë©”íƒ€ë°ì´í„° í•„í„°ë§ìœ¼ë¡œ êµ¬í˜„í•˜ì„¸ìš”.

```python
# 1. ë¬¸ì„œì— user_id ì¶”ê°€
document = {
    'content': "...",
    'embedding': [...],
    'user_id': "user123",  # ì‚¬ìš©ì ID
    'metadata': {
        'team_id': "team456",  # íŒ€ ID (ì„ íƒ)
        'access_level': "private"
    }
}

# 2. ì‚¬ìš©ìë³„ ê²€ìƒ‰
pipeline = [
    {
        "$vectorSearch": {
            "index": "vector_index",
            "path": "embedding",
            "queryVector": query_embedding,
            "filter": {
                "user_id": {"$eq": current_user_id}
            },
            "numCandidates": 100,
            "limit": 5
        }
    }
]

# 3. RLS (Row Level Security) ëŒ€ì‹  ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ê´€ë¦¬
# MongoDBëŠ” PostgreSQLì˜ RLSê°€ ì—†ìœ¼ë¯€ë¡œ ì½”ë“œì—ì„œ í•„í„°ë§
```

### Q8. ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ëŠ” ì–´ë–»ê²Œ êµ¬í˜„í•˜ë‚˜ìš”?

**A:** Change Streamsë¥¼ í™œìš©í•˜ì„¸ìš”.

```python
# 1. Change Streamsë¡œ ì‹¤ì‹œê°„ ê°ì§€
with collection.watch() as stream:
    for change in stream:
        if change['operationType'] == 'insert':
            doc_id = change['documentKey']['_id']
            # ìƒˆ ë¬¸ì„œ ì„ë² ë”© ìƒì„±
            update_embedding(doc_id)

# 2. íŠ¸ë¦¬ê±° í•¨ìˆ˜ (MongoDB Atlas Functions)
# Atlas UIì—ì„œ í•¨ìˆ˜ ìƒì„±:
exports = async function(changeEvent) {
    const doc = changeEvent.fullDocument;
    // ì„ë² ë”© API í˜¸ì¶œ
    // ë¬¸ì„œ ì—…ë°ì´íŠ¸
}

# 3. WebSocketìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ì•Œë¦¼
# ë¬¸ì„œ ë³€ê²½ â†’ í´ë¼ì´ì–¸íŠ¸ì— ì‹¤ì‹œê°„ í‘¸ì‹œ
```

### Q9. ì´ë¯¸ì§€ë‚˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ë„ ê°€ëŠ¥í•œê°€ìš”?

**A:** ë„¤, ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```python
# 1. OpenAI CLIP ë˜ëŠ” Multimodal Embeddings ì‚¬ìš©
# (í˜„ì¬ OpenAIëŠ” ë³„ë„ API ì œê³µí•˜ì§€ ì•ŠìŒ, ëŒ€ì•ˆ ì‚¬ìš©)

# 2. Cohere Embed v3 (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
import cohere
co = cohere.Client(api_key="...")

# ì´ë¯¸ì§€ ì„ë² ë”©
image_embedding = co.embed(
    texts=[""],
    images=["path/to/image.jpg"],
    model="embed-english-v3.0",
    input_type="image"
).embeddings[0]

# 3. MongoDBì— ì €ì¥ (ë™ì¼ í•„ë“œ)
collection.insert_one({
    'type': 'image',
    'image_url': 'https://...',
    'embedding': image_embedding,
    'metadata': {'tags': ['car', 'red']}
})

# 4. í†µí•© ê²€ìƒ‰ (í…ìŠ¤íŠ¸ ì¿¼ë¦¬ â†’ ì´ë¯¸ì§€ ê²°ê³¼)
query_embedding = co.embed(texts=["red car"], ...)
# ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì´ë¯¸ì§€ ì°¾ê¸°
```

### Q10. í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?

**A:** MongoDB Atlas ëª¨ë‹ˆí„°ë§ + ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê¹…ì„ ê²°í•©í•˜ì„¸ìš”.

```python
# 1. Atlas ëª¨ë‹ˆí„°ë§ (ë¬´ë£Œ ì œê³µ)
# - Atlas UI â†’ Metrics
# - CPU, Memory, Disk, Network í™•ì¸
# - Query Performance ë¶„ì„

# 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê¹…
import logging
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def monitored_search(query: str):
    start = time.time()

    # ê²€ìƒ‰ ì‹¤í–‰
    results = search(query)

    elapsed = time.time() - start
    logger.info(f"Search completed: query={query}, time={elapsed:.3f}s, results={len(results)}")

    return results

# 3. Prometheus + Grafana (ì—”í„°í”„ë¼ì´ì¦ˆ)
from prometheus_client import Counter, Histogram

search_requests = Counter('rag_search_requests_total', 'Total search requests')
search_duration = Histogram('rag_search_duration_seconds', 'Search duration')

@search_duration.time()
def search_with_metrics(query):
    search_requests.inc()
    return search(query)

# 4. ì•Œë¦¼ ì„¤ì • (Atlas Alerts)
# - ëŠë¦° ì¿¼ë¦¬ ê°ì§€ (>1ì´ˆ)
# - CPU ì‚¬ìš©ë¥  80% ì´ìƒ
# - ë””ìŠ¤í¬ ê³µê°„ 90% ì´ìƒ
```

---

## ğŸ”— ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ

- **[MongoDB Atlas](https://www.mongodb.com/cloud/atlas)**: ê³µì‹ ì œí’ˆ í˜ì´ì§€
- **[Atlas Vector Search Documentation](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-overview/)**: Vector Search ê³µì‹ ë¬¸ì„œ
- **[PyMongo Documentation](https://pymongo.readthedocs.io/)**: Python MongoDB ë“œë¼ì´ë²„
- **[MongoDB University](https://learn.mongodb.com/)**: ë¬´ë£Œ êµìœ¡ ê³¼ì •

### ë¸”ë¡œê·¸ ë° íŠœí† ë¦¬ì–¼

- **[Building AI Applications with MongoDB](https://www.mongodb.com/developer/products/atlas/building-ai-applications-mongodb/)**: AI ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶• ê°€ì´ë“œ
- **[RAG with MongoDB Atlas Vector Search](https://www.mongodb.com/developer/products/atlas/rag-with-atlas-vector-search-langchain-openai/)**: LangChain í†µí•© ì˜ˆì œ
- **[Vector Search Best Practices](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-best-practices/)**: ì„±ëŠ¥ ìµœì í™” íŒ

### GitHub ì €ì¥ì†Œ

- **[mongodb-labs/pymongo-ai](https://github.com/mongodb-labs/pymongo-ai)**: MongoDB AI í†µí•© ë„êµ¬
- **[MongoDB Developer Hub](https://github.com/mongodb-developer)**: ê³µì‹ ìƒ˜í”Œ ì½”ë“œ ë° íŠœí† ë¦¬ì–¼

### ì»¤ë®¤ë‹ˆí‹°

- **[MongoDB Community Forums](https://www.mongodb.com/community/forums/)**: ê°œë°œì ì»¤ë®¤ë‹ˆí‹°
- **[MongoDB Developer Hub](https://www.mongodb.com/developer/)**: ê¸°ìˆ  ë¸”ë¡œê·¸ ë° ë¦¬ì†ŒìŠ¤
- **[Stack Overflow - mongodb](https://stackoverflow.com/questions/tagged/mongodb)**: Q&A ì»¤ë®¤ë‹ˆí‹°

### ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- **[Vector Search Pricing](https://www.mongodb.com/pricing)**: ìµœì‹  ê°€ê²© ì •ë³´
- **[MongoDB Atlas Free Tier](https://www.mongodb.com/cloud/atlas/register)**: ë¬´ë£Œ ê³„ì • ì‹œì‘
- **[OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)**: ì„ë² ë”© ëª¨ë¸ ê°€ì´ë“œ
